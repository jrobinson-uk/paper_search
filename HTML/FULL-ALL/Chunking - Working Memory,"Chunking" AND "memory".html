
<!doctype html>
<head><script type="text/javascript">/* <![CDATA[ */_cf_loadingtexthtml="<img alt=' ' src='/cf_scripts/scripts/ajax/resources/cf/images/loading.gif'/>";
_cf_contextpath="";
_cf_ajaxscriptsrc="/cf_scripts/scripts/ajax";
_cf_jsonprefix='//';
_cf_websocket_port=0;
_cf_flash_policy_port=0;
_cf_clientid='75CF2A408A08FA0D79AFB9FB427EF4E3';/* ]]> */</script><script type="text/javascript" src="/cf_scripts/scripts/ajax/messages/cfmessage.js"></script>
<script type="text/javascript" src="/cf_scripts/scripts/ajax/package/cfajax.js"></script>
<script type="text/javascript" src="/cf_scripts/scripts/cfform.js"></script>
<script type="text/javascript" src="/cf_scripts/scripts/masks.js"></script>
<script type="text/javascript" src="/cf_scripts/scripts/cfformhistory.js"></script>
<script type="text/javascript" src="/cf_scripts/scripts/ajax/ckeditor/ckeditor.js"></script>
<script type="text/javascript" src="/cf_scripts/scripts/ajax/package/cfrichtexteditor.js"></script>
<script type="text/javascript" src="/cf_scripts/scripts/ajax/yui/yahoo-dom-event/yahoo-dom-event.js"></script>
<script type="text/javascript" src="/cf_scripts/scripts/ajax/yui/animation/animation-min.js"></script>
<script type="text/javascript" src="/cf_scripts/scripts/ajax/ext/ext-all.js"></script>
<script type="text/javascript" src="/cf_scripts/scripts/ajax/package/cfwindow.js"></script>
<link rel="stylesheet" type="text/css" href="/cf_scripts/scripts/ajax/resources/ext/css/ext-all.css" />
<link rel="stylesheet" type="text/css" href="/cf_scripts/scripts/ajax/resources/cf/cf.css" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="css/dl.css" />
<style type="text/css"><!--
.gsc-search-button input.gsc-search-button-v2, input.gsc-search-button-v2 {
    height: 9px;
    margin-top: 2px;
    min-width: 9px;
    padding: 6px 20px;
    width: 9px;
}
#newsearch {
	height:200px;
	margin-top:100px;
	margin-left: auto;
    margin-right: auto;
    width: 700px;
}

#newsearch div {
	color: #87888c;
    font-size: 18px;
    margin-bottom: 10px;
    text-align: left
}
.c600 {
   width:600px;
   margin-left:auto;
   margin-right:auto;
}


@-webkit-keyframes fadeIn { from { opacity:0; } to { opacity:1; } }
@-moz-keyframes fadeIn { from { opacity:0; } to { opacity:1; } }
@keyframes fadeIn { from { opacity:0; } to { opacity:1; } }
.fade-in {
    opacity:0;
    -webkit-animation:fadeIn ease-in 1;
    -moz-animation:fadeIn ease-in 1;
    animation:fadeIn ease-in 1;

    -webkit-animation-fill-mode:forwards; 
    -moz-animation-fill-mode:forwards;
    animation-fill-mode:forwards;

    -webkit-animation-duration:1s;
    -moz-animation-duration:1s;
    animation-duration:1s;
	
	-webkit-animation-delay: 1s;
	-moz-animation-delay: 1s;
	animation-delay: 1s;
}
  --></style>
<title>Results ACM DL :&nbsp;content.ftsec:( &quot;Chunking&quot; AND &quot;memory&quot;)</title>
<style type="text/css"><!--
    body {margin-left: 0em; margin-top: 0}
    a:link {text-decoration: underline; 	Color: #1d4d0f;}
    a:visited  { color: #990033; text-decoration: underline;}
    a:hover {color: red; text-decoration: none}
    a.dLink1:link {color:#336699}
    a.dLink1:visited {color:#666666}
	a.isblack:link {text-decoration: underline; 	Color: #000000;}
    a.isblack:visited  { color: #000000; text-decoration: underline;}
    a.isblack:hover {color: #000000; text-decoration: none}
    h1 {font-size: 140%; margin-bottom: 0}
	ul {margin-top: .25em; list-style-type: disc}
	ol {margin-top: .25em;}
	li {padding-bottom: .25em;}
    h2 {color: white; background-color: #069; 
        font-size: 100%; padding-left: 1em;
		margin: 0}
	h3 {color: black; background-color: yellow; 
    	font-size: 100%;
		margin: 0}
	 h4 {color: black; background-color: #99c5e8; 
        font-size: 100%;
		margin: 0}
    hr {color: #39176d;}
    form {margin-top: 10}
    form.xrs {margin-top: 0}
	
	a {text-decoration: none; }
	
	input {font-size: 1em;}
	.chevron {color: #ff0000;}
	.light-blue {color:#336699;}
	.black {color:#000000;}
	
	
	.mono-text {font-size: 14px; font-family: Consolas, Menlo, Monaco, Lucida Console, Liberation Mono, DejaVu Sans Mono, Bitstream Vera Sans Mono, Courier New, monospace, serif;}
	
	/* ### standard text styles, smallest to largest ### */
	
	.footer-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .75em; line-height: 1.33em;
		text-indent: -.75 em; margin-left: 2em; margin-right: .75em;}
		
	.footer-copy-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em; line-height: 1.3em;
		margin-left: .75em; margin-right: .75em;}
		
	.small-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; padding-bottom : 2px;
	  	padding-top : 2px;}
		
	.small-link-text2 {font-size: .83em !important; 
	}

	.smallerer-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .65em;}
	.smaller-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .75em;}		
	.small-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em;}
	.small-textb {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; font-weight: bold;}
	.medium-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em;}
	.mediumb-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1em; font-weight: bold;}
	.large-text {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 1.3em;}		
	.instr-text {font-family: Arial, Helvetica, sans-serif;
		color:#666666; font-size: .83em;}
		
	.list-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#336699; font-size: .83em; line-height: 1.3em;}
	.list-link-btext {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: .83em; line-height: 1.3em;}
	
	.searchbox-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;}
	.footer-header-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold;
		margin-left: .75em; margin-right: .75em;}
	.medium-link-text {font-family: Arial, Helvetica, sans-serif;
		color:#000066; font-size: 1em; font-weight: bold; line-height: 1em;
		text-indent: -1.25em; margin-left: 2em; margin-right: .75em;}
	
	.text16 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 16px;}
		
	.text14 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 14px;}
	
	.text12 {font-family: Arial, Helvetica, sans-serif;
		color:#000000; font-size: 12px;}
		
	.text10 {font-family: Arial, Helvetica, sans-serif;
	    color:#000000; font-size: 12px;}
		
	.text9 {font-family: Arial, Helvetica, sans-serif;
	   color:#000000; font-size: 12px;}
	
	.error-text {color:red;}
	
	.small-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: .75em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}

	.medium-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1em; line-height: 1.2em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-copy-text {font-family: Times, Times New Roman, serif;
		color:#000066; font-size: 1.3em; line-height: 1.5em;
		margin-left: .75em; margin-right: .75em;}
	
	.medium-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1em;
		margin-left: .75em; margin-right: .75em;}
	
	.large-header-text {font-family: Times, Times New Roman, serif;
		color:#ff0000; font-size: 1.5em;
		margin-left: .75em; margin-right: .75em;}

		#side {
			width: 10px;
			float: left;
			margin-left: -1px;
			padding: 2px;
			}
							
		#content {
			padding: 2px;
			margin-left: 25px;
			
		        
		        }
	 .fulltext_lnk {border:0px;
	 				 margin-right: 2px;
					 vertical-align:baseline;
	 				}
	 
	  .leftcoltab { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:530px;  /* for IE5/WIN */
		  width:520px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	  .rightcoltab {
    float: right;
    margin: 0;
    padding: 5px;
    position: relative;
    right: 50px;
    top: 25px;
    width: 350px;
    z-index: 99;
}
	  .centercoltab {
		  position:absolute;
		  padding:0 0px;
		  }
	  .alt {
		background: #ece9d8;
		margin: 0;
		padding: 1px;
		}
		.leftcolc { 
	position:relative;
	top:5px;
	left:5px;
	float:left;
	width:420px;  /* for IE5/WIN */
	width:400px; /* actual value */
	margin:0 0 0px 0;
	padding:5px;
	z-index:100;
	}
.rightcolc {
	position:relative;
	top:0px;
	right:0px;
	float:right;
	margin:0 0px;
	padding:0px;
	width:500px;
	z-index:99;
	}
.centercolc {
	position:absolute;
	padding:0 0px;
	}
	
	.leftcoltabv { 
		  position:relative;
		  top:5px;
		  left:5px;
		  float:left;
		  width:460px;  /* for IE5/WIN */
		  width:350px; /* actual value */
		  margin:0 0 0px 0;
		  padding:5px;
		  z-index:100;
		  }
	.rightcoltabv {
		position:relative;
		top:5px;
		right:0px;
		float:right;
		margin:0 0px 0 0;
		padding:15px;
		width:480px;
		z-index:99;
		}
		
.x-tabs-strip-wrap {
	overflow-y: hidden !important;
}
  --></style>
<script type="text/javascript">/* <![CDATA[ */
	ColdFusion.Ajax.importTag('CFAJAXPROXY');
/* ]]> */</script>
<script type="text/javascript">/* <![CDATA[ */
	ColdFusion.Ajax.importTag('CFFORM');
/* ]]> */</script>
<script type="text/javascript">/* <![CDATA[ */
	ColdFusion.Ajax.importTag('CFDIV');
/* ]]> */</script>
<script type="text/javascript">/* <![CDATA[ */
	ColdFusion.Ajax.importTag('CFTEXTAREA');
/* ]]> */</script>
<script type="text/javascript">/* <![CDATA[ */
	_cf_bind_init_28317634333418940=function()
	{
		ColdFusion.Bind.register([],{'bindTo':'Events','bindExpr':['upcomingconfs.cfm?ids=2019-55400,2019-318640,2017-8371,2019-318220,2019-612620,2019-219520,2019-220320,2019-87880,2019-710020,2018-54400,2017-44383,2017-511080,2018-9371,2017-37680,2019-10382,2019-416900,2019-312220,2019-513280,2019-7260,2020-613280']},ColdFusion.Bind.urlBindHandler,true);
	};ColdFusion.Event.registerOnLoad(_cf_bind_init_28317634333418940);
/* ]]> */</script>
<script type="text/javascript">/* <![CDATA[ */
	ColdFusion.Ajax.importTag('CFWINDOW');
/* ]]> */</script>
<script type="text/javascript">/* <![CDATA[ */
	Ext.onReady(function(){var _cf_window_init_28317634333418942=function()
	{
		var _cf_window=ColdFusion.Window.create('theexplaination','','',{ modal:false, closable:true, divid:'cf_window28317634333418941', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:300, minheight:250, initshow:false, destroyonclose:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_28317634333418942);});
/* ]]> */</script>
<script type="text/javascript">/* <![CDATA[ */
	Ext.onReady(function(){var _cf_window_init_28317634333418944=function()
	{
		var _cf_window=ColdFusion.Window.create('theformats','Export Formats','',{ modal:false, closable:true, divid:'cf_window28317634333418943', draggable:true, resizable:true, fixedcenter:false, width:500, height:300, shadow:true, bodystyle:'text-align:left', callfromtag:true, minwidth:250, minheight:250, initshow:false, destroyonclose:false});
	};ColdFusion.Event.registerOnLoad(_cf_window_init_28317634333418944);});
/* ]]> */</script>
</head>
<body style="text-align:center; font-size: 100%" onLoad="window.focus();">
<script type="text/javascript">
setTimeout(function(){
document.getElementById('DLnext').style.display = "block";
},1500);
</script>
<div style="width:940px; margin-left: auto; margin-right: auto; text-align:left">
<a id="CIT"></a>

<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-NFGCMX"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-NFGCMX');</script>

<div id="header">
<table style="table-layout:fixed; margin-top: 5px; margin-bottom: 10px; border:0px; width:100%; border-collapse:collapse;">
<tr id="trMessage" style="vertical-align:top">
<td colspan="3" style="padding-top: 5px; padding-left: 10px; padding-bottom: 10px; padding-right: 10px; text-align:left; background-color:#d8e4f2; border: solid 2px #0f5ea9;" class="small-link-text2">
<div id="cfp" style="margin-top:5px; margin-bottom:5px;">
<div>
<strong>Help Design Your New ACM Digital Library</strong>
</div>
<div style="margin-top:10px;">
We're upgrading the ACM DL, and would like your input.&nbsp;&nbsp;Please sign up to review new features, functionality and page designs.
</div>
<div style="margin-top:10px;">
<form id="cfp_form" style="display:inline" action="#" method="post"><label id="cfp_email" title="email address">Leave an email address: <input id="cfp_email" type="email" name="cfp_email" /></label><input type="image" src="images/ok-button-20x20.jpg" alt="submit email address" style="vertical-align:middle; margin-left: 5px;" /><span style="padding-left:10px; padding-right:10px;">or</span><div style="display:inline-block; vertical-align:middle" onmouseover="javascript: document.cookie = 'CFP=1; expires=Thu, 31 Dec 2048 12:00:00 UTC; path=/';"><a href="https://twitter.com/ACMDL?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @ACMDL</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
<span style="padding-left:10px; padding-right:10px;">or</span><div style="display:inline-block; vertical-align: middle;">[<a href="#" onclick="javascript: document.getElementById('cfp_form').submit();">Not interested</a>]</form></div>
</div>
</div>
</td>
</tr>
<tr style="vertical-align:top">
<td style="padding-left: 5px; padding-right:10px; padding-bottom:0px; width:300px" class="small-link-text2"><img src="/images/ACMDL_Logo.jpg" alt="ACM DL" style="border:0px" usemap="#port" />
</td>
<td style="padding-left: 5px; padding-right:10px; padding-bottom:0px; vertical-align:middle;" class="small-link-text2">
<table style="width:100%; border-collapse:collapse; padding:0px">
<tr><td style="text-align:center">
<div style="margin:0px auto;color:#356b20;font-size:10pt;line-height:10%;"> </div>
</td>
</tr>
</table>
</td>
<td style="padding-top: 0px; padding-left: 0px; padding-bottom:0px; text-align:right;" class="small-link-text2">
<p style="margin-top:0px; margin-bottom:10px;">
<a href="https://dl.acm.org/signin.cfm" class="small-link-text2" title="Sign in to personalize your Digital Library experience">SIGN IN</a>
&nbsp;&nbsp;<a href="https://dl.acm.org/signin.cfm" class="small-link-text2" title="Sign up to personalize your Digital Library experience">SIGN UP</a>
</p>
<table style="padding: 5px; border-collapse:collapse; float:right">
<tr>
<td class="small-link-text2" style="text-align:right">
<script type="text/javascript">
								function encodeInput(form){
								    	var cleanQuery = form.elements['query'].value.replace(new RegExp( "\\+", "g" ),"%2B");
										cleanQuery = cleanQuery.replace(/#/g, "%23");
										cleanQuery = cleanQuery.replace(/(\n)/g, " ");
										cleanQuery = cleanQuery.trim();
										
										
										var ascii = /^[ -~]+$/;
										if( !ascii.test( cleanQuery ) ) {
											var fixedUseQuery = "";
											for (var i = 0, len = cleanQuery.length; i < len; i++) {
												var str = "";
												if( !ascii.test(cleanQuery[i]) ) {
										 			str = "%26%23" + cleanQuery[i].charCodeAt(0) + ";";
												} else {
										 			str = cleanQuery[i];
												}
												fixedUseQuery = fixedUseQuery + str;
											}
											cleanQuery = fixedUseQuery;
										}
										

										form.elements['query'].value = cleanQuery;
								}
							</script>
<form name="qiksearch" action="/results.cfm" onsubmit='encodeInput(this)'>
<input type="hidden" name="within" value="owners.owner=HOSTED">
<input type="hidden" name="srt" value="_score">
<span style="margin-left:0px"><label><input type="text" name="query" size="30" value="content.ftsec:(+&quot;Chunking&quot; AND &quot;memory&quot;)" /></label>&nbsp;
<input style="vertical-align:top;" type="image" alt="Search" name="Go" src="/images/search_small.jpg" />
</span>
</form>
</td>
</tr>
</table>
</td>
</tr>
<tr><td colspan="3" class="small-link-text2" style="padding-bottom:5px; padding-top:0px; text-align:center">
<div style="margin:0px auto;color:#356b20;line-height:10%;"> </div>
</td>
</tr>
</table>
<map name="port" id="port">
<area shape="rect" coords="1,1,60,50" href="https://www.acm.org/" alt="ACM Home Page" />
<area shape="rect" coords="65,1,275,68" href="https://dl.acm.org/dl.cfm" alt="ACM Digital Library Home Page" />
</map>
</div>
</div>
<div class="layout" style="width:940px; margin-left: auto; margin-right: auto; padding-left:5px; text-align:left">
<style>
	#resultstats2 {
    width:100%;
	padding: 10px;
	background-color:#ECE9D8;
    /*background:#9c9;*/
    }
	
	#resultstats {
    width:100%;
	/*background-color:#ECE9D8;*/
	font-size: 12px;
    /*background:#9c9;*/
    }
	
	#resultstats a:link {
		text-decoration: none;
	}
	
	#resultstats div {
		padding-bottom: 10px;
		padding-top: 5px;
	}
	
	#resfound {
		background-color: #ece9d8;
		padding-left:5px
	}
	
	#searchtots {
		display:inline;
		width:20%;
		padding-right: 10px;
	}
	
	#searchtools {
		display:inline;
		float:right;
		padding-right: 10px;
	}
	
	#refinements {
		padding-top: 5px;
	}
	
	#refinements table {
		margin-left: 10px;
	}
	
	#refinements tr {
		vertical-align:top;
	}
	
	#refinements span {
		font-size: 12px;
	}
	
	.rectots {
		font-size:12px;
	}
	
	.problem {
		font-size:12px;
		color: red;
	}

	div.problem  {
		height: 400px;
	}
	
    #results {
    float:right;
    width:80%;
    color: #000000;
    font-family: Verdana,Arial,Helvetica,sans-serif;
    font-size: 12px;
	padding-top: 10px;
    /*background:#9c9;*/
    }
    #aggs {
    float:left;
    width:20%;
	font-family: Verdana,Arial,Helvetica,sans-serif;
	font-size:12px;
    
    }
	
	.pagelogic {
	font-family: Verdana,Arial,Helvetica,sans-serif;
	font-size:12px;
	float:right;
	 padding-bottom: 10px;
    }
	
	.pagerange {
	font-family: Verdana,Arial,Helvetica,sans-serif;
	font-size:12px;
	float:left;
	 padding-bottom: 10px;
    }
	
	#selmenu {
	display: inline;
	font-family: Verdana,Arial,Helvetica,sans-serif;
	font-size:12px;
	
    padding-bottom: 10px;
    }
	
	#selmenu input {
	    vertical-align: text-top;
	}
	
	#sortmenu {
	
	font-family: Verdana,Arial,Helvetica,sans-serif;
	font-size:12px;
	float:right;
    padding-bottom: 10px;
    }
	
	#sortmenu label {
		margin-right: 0px;
	    vertical-align:bottom;
	}
	
	#sortmenu input {
		margin-right: 0px;
	    vertical-align:bottom;
	}
	
	#sortmenu select {
	   margin-right: 0px;
	   background-color: #aff;
	   border: 0;
	   border-radius: 0;
	   font-size: 12px;
	}
	
	#sortmenu option {
		font-size: 12px;
		background-color: white;
	}
	
	.aggHead {
	 font-weight: bold;
	 padding-bottom: 0;
     padding-top: 10px;
	}
	
	.vidHead {
	 font-weight: normal;
	 padding-bottom: 5px;
     padding-top: 0px;
	}
	
	.vidHead img {
		vertical-align: middle;
	}
	
	#aggs ul{
	list-style-type: none;
    margin-top: 0.25em;
	padding-left: 0;
	font-size: 1em;	
	}
	
	#upcevents li{
	padding-bottom: 1.25em;	
	}
	
	#upcevents div{
	margin-top: 25px;
	}
	
	a.showhide:link {
		text-decoration: none;
	}
	
	#results .numbering{
		font-size: 12px;
		font-weight:bold;
		width:30px;
		float:left;
		text-align: right;
		padding-top: 2px;
	}
	
	#results .details{
		font-size: 12px;
		width:92%;
		float:right;
		padding-bottom: 20px;
	}
	
	#results .title{
		font-size: 14px;
		padding-bottom:5px;
	}
	
	#results .vids{
		display:inline;
		float: left;
		padding-right:10px;
	}
	
	#results .media{
		padding-right:10px;
		clear:left;
	}
	
	#results .stream{
		display:inline-block;
		padding-top:10px;
		
	}
	
	#results .available{
		padding-left: 10px;
		
	}
	
	
	#results .authors{
		font-size: 12px;
		padding-bottom:5px;
	}
	
	#results .source{
		font-size: 12px;
		padding-bottom:5px;
	}
	
	#results .publisher{
		font-size: 12px;
		padding-bottom:5px;
	}
	
	#results .metrics{
		font-size: 12px;
		padding-bottom:5px;
	}

	#results .metricsCol1{
		float: left;
		display:inline;
		padding-bottom:5px;
	}

	#results .metricsCol2{
		float: right;
		display: inline;
		width: 590px;
		padding-bottom:5px;
	}

	#results .ft{
		font-size: 12px;
		padding-bottom:5px;
	}
	
	#results .abstract{
		font-size: 12px;
		padding-bottom:5px;
	}
	
	#results .kw{
		font-size: 12px;
		padding-bottom:5px;
	}
	
	#results .pubother{
		font-size: 12px;
		padding-bottom:5px;
	}

	.highlights {
	 margin-top: 10px;
	}
	
	.highlights em{
	  background-color: #FFFF00;
	  font-style: normal;
	}
	
	.publicationDate {
		
	}
	.citedCount {
		
	}
	.download6Weeks {
		
	}
	.download12Months {
		
	}
	.downloadAll {
		
	}
</style>
<script src="chart.js/Chart.js"></script>
<script type="text/javascript">
function expand(divID) { 
			if (document.getElementById(divID).style.display == "none") {document.getElementById(divID).style.display = "block";}
			 else {document.getElementById(divID).style.display = "none"}
		}
function toggle(theagg) {
	var theimg  = theagg + "_img"; 
	var thelist = theagg + "_list"; 
	if (document.getElementById(theimg).src.indexOf("arrow-right") > 0){
		document.getElementById(theimg).src="gifs/arrow-down.gif";
		document.getElementById(thelist).style.display = "block";
	}
	else{
		document.getElementById(theimg).src="gifs/arrow-right.gif";
		document.getElementById(thelist).style.display = "none";
	}
}


function sortres(howsort) {
	window.location = "results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=" + howsort;
}

function submitrange(theyear) {
	window.location = "results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=&within=owners%2Eowner%3DHOSTED&dte=" + theyear + "&bfr=" + "&srt=%5Fscore";
}

function updateTextInput(val) {
  document.getElementById('textInput').value=val; 
}


		
</script>
<div id="resultstats">
<div>Searched for <em>content.ftsec:(+&quot;Chunking&quot; AND &quot;memory&quot;)</em>&nbsp;&nbsp;[<a href="results.cfm?query=" title="start a new search">new search</a>]&nbsp;&nbsp;[<a href="advsearch.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&within=owners.owner=HOSTED" title="edit or save this query">edit/save query</a>]&nbsp;&nbsp;<span style="float:right">[<a href="advsearch.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&within=owners.owner=HOSTED" title="advanced search: query builder">advanced search</a>]</span></div>
<div> Searched The ACM Full-Text Collection: <span class="rectots">562,562 records</span>&nbsp;&nbsp;&nbsp;[<a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=&within=owners.owner=GUIDE&dte=&bfr=&srt=%5Fscore">Expand your search to The ACM Guide to Computing Literature</a>: <span class="rectots">2,859,660 records</span>]
<a href="javascript:ColdFusion.Window.show('theexplaination');ColdFusion.navigate('explain.cfm?expid=10','theexplaination');" title="Help: Search The ACM Full-Text Collection or The ACM Guide to Computing Literature"><img src="images/help.jpg" width="20" height="18" alt="Help: ACM vs. Guide" border="0" hspace="0" style="vertical-align:text-bottom;"></a>
</div>
<div id="resfound">
<div id="searchtots"><strong>10,142</strong> results found</div>
<span id="searchtools">Export Results:
<a href="exportformats_search.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore&expformat=bibtex">bibtex</a>
|&nbsp;<a href="exportformats_search.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore&expformat=endnote">endnote</a>
|&nbsp;<a href="exportformats_search.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore&expformat=acmref">acmref</a>
|&nbsp;<a href="exportformats_search.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore&expformat=csv">csv</a>
</span>
</div>
</div>
<hr />
<div id="aggs">
<div class="vidHead">
<a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat%3DVideo&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">
<img src="images/vids.jpg" border="0" width="40px" height="40px" alt="video content"></a>
<a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat%3DVideo&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">287 videos found</a>
</div>
<div>
<div class="aggHead">Refine by People</div>
<div>
<a title="show/hide" class="showhide" id="Names_link" href="javascript: void(0);" onclick="toggle('Names');">Names&nbsp;<img src="gifs/arrow-right.gif" id="Names_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Names_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Arpaci%2DDusseau%2C%20Remzi%20H%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Arpaci-Dusseau, Remzi H.&nbsp;(31)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Arpaci%2DDusseau%2C%20Andrea%20C%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Arpaci-Dusseau, Andrea C.&nbsp;(29)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Benini%2C%20Luca&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Benini, Luca&nbsp;(25)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Berger%2C%20Emery%20D%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Berger, Emery D.&nbsp;(23)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Torrellas%2C%20Josep&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Torrellas, Josep&nbsp;(23)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=McKinley%2C%20Kathryn%20S%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">McKinley, Kathryn S.&nbsp;(22)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Agrawal%2C%20Gagan&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Agrawal, Gagan&nbsp;(19)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Ailamaki%2C%20Anastasia&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Ailamaki, Anastasia&nbsp;(19)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Kandemir%2C%20Mahmut&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Kandemir, Mahmut&nbsp;(19)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Sarkar%2C%20Vivek&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Sarkar, Vivek&nbsp;(18)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Mahlke%2C%20Scott&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Mahlke, Scott&nbsp;(17)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Dubey%2C%20Pradeep&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Dubey, Pradeep&nbsp;(16)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Neumann%2C%20Thomas&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Neumann, Thomas&nbsp;(15)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Daelemans%2C%20Walter&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Daelemans, Walter&nbsp;(14)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Kozyrakis%2C%20Christos&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Kozyrakis, Christos&nbsp;(14)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Kulkarni%2C%20Milind&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Kulkarni, Milind&nbsp;(14)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Burtscher%2C%20Martin&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Burtscher, Martin&nbsp;(13)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Lehner%2C%20Wolfgang&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Lehner, Wolfgang&nbsp;(13)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Mutlu%2C%20Onur&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Mutlu, Onur&nbsp;(13)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPersonsSearchDspName=Pingali%2C%20Keshav&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Pingali, Keshav&nbsp;(13)</a></li>
</ul>
<div>
<a title="show/hide" class="showhide" id="Institutions_link" href="javascript: void(0);" onclick="toggle('Institutions');">Institutions&nbsp;<img src="gifs/arrow-right.gif" id="Institutions_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Institutions_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=Carnegie%20Mellon%20University&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Carnegie Mellon University&nbsp;(264)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=Microsoft%20Research&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Microsoft Research&nbsp;(219)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=Intel%20Corporation&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Intel Corporation&nbsp;(217)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=Stanford%20University&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Stanford University&nbsp;(194)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=University%20of%20Illinois%20at%20Urbana%2DChampaign&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">University of Illinois at Urbana-Champaign&nbsp;(182)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=University%20of%20Wisconsin%20Madison&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">University of Wisconsin Madison&nbsp;(165)</a></li>

<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=IBM%20Thomas%20J%2E%20Watson%20Research%20Center&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">IBM Thomas J. Watson Research Center&nbsp;(153)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=University%20of%20California%2C%20Berkeley&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">University of California, Berkeley&nbsp;(146)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=Georgia%20Institute%20of%20Technology&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Georgia Institute of Technology&nbsp;(138)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=Massachusetts%20Institute%20of%20Technology&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Massachusetts Institute of Technology&nbsp;(134)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=University%20of%20Texas%20at%20Austin&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">University of Texas at Austin&nbsp;(131)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=Ohio%20State%20University&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Ohio State University&nbsp;(119)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=Purdue%20University&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Purdue University&nbsp;(114)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=University%20of%20Toronto&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">University of Toronto&nbsp;(107)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=University%20Michigan%20Ann%20Arbor&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">University Michigan Ann Arbor&nbsp;(106)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=Swiss%20Federal%20Institute%20of%20Technology%2C%20Zurich&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Swiss Federal Institute of Technology, Zurich&nbsp;(103)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=Princeton%20University&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Princeton University&nbsp;(99)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=University%20of%20Maryland&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">University of Maryland&nbsp;(98)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=University%20of%20Washington%2C%20Seattle&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">University of Washington, Seattle&nbsp;(97)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlInstName=University%20of%20California%2C%20San%20Diego&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">University of California, San Diego&nbsp;(95)</a></li>
</ul>
<div>
<a title="show/hide" class="showhide" id="Authors_link" href="javascript: void(0);" onclick="toggle('Authors');">Authors&nbsp;<img src="gifs/arrow-right.gif" id="Authors_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Authors_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Arpaci%2DDusseau%2C%20Remzi%20H%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Arpaci-Dusseau, Remzi H.&nbsp;(31)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Arpaci%2DDusseau%2C%20Andrea%20C%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Arpaci-Dusseau, Andrea C.&nbsp;(29)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Benini%2C%20Luca&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Benini, Luca&nbsp;(25)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Berger%2C%20Emery%20D%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Berger, Emery D.&nbsp;(23)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Torrellas%2C%20Josep&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Torrellas, Josep&nbsp;(23)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=McKinley%2C%20Kathryn%20S%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">McKinley, Kathryn S.&nbsp;(22)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Agrawal%2C%20Gagan&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Agrawal, Gagan&nbsp;(19)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Ailamaki%2C%20Anastasia&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Ailamaki, Anastasia&nbsp;(19)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Kandemir%2C%20Mahmut&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Kandemir, Mahmut&nbsp;(19)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Sarkar%2C%20Vivek&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Sarkar, Vivek&nbsp;(18)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Mahlke%2C%20Scott&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Mahlke, Scott&nbsp;(17)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Dubey%2C%20Pradeep&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Dubey, Pradeep&nbsp;(16)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Mutlu%2C%20Onur&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Mutlu, Onur&nbsp;(15)</a></li>

<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Neumann%2C%20Thomas&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Neumann, Thomas&nbsp;(15)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Daelemans%2C%20Walter&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Daelemans, Walter&nbsp;(14)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Kozyrakis%2C%20Christos&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Kozyrakis, Christos&nbsp;(14)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Kulkarni%2C%20Milind&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Kulkarni, Milind&nbsp;(14)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Burtscher%2C%20Martin&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Burtscher, Martin&nbsp;(13)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Lehner%2C%20Wolfgang&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Lehner, Wolfgang&nbsp;(13)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eauthors%2EsearchDspName=Pingali%2C%20Keshav&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Pingali, Keshav&nbsp;(13)</a></li>
</ul>
<div>
<a title="show/hide" class="showhide" id="Editors_link" href="javascript: void(0);" onclick="toggle('Editors');">Editors&nbsp;<img src="gifs/arrow-right.gif" id="Editors_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Editors_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Humphrey%2C%20Susanne%20M%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Humphrey, Susanne M.&nbsp;(4)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Krovetz%2C%20Bob&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Krovetz, Bob&nbsp;(4)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Cohen%2C%20Philip%20R%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Cohen, Philip R.&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Cunningham%2C%20Steve&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Cunningham, Steve&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=DeGroot%2C%20Doug&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">DeGroot, Doug&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Kr%26%23252%3Bger%2C%20Antonio&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Kr&#252;ger, Antonio&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Oviatt%2C%20Sharon&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Oviatt, Sharon&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Potamianos%2C%20Gerasimos&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Potamianos, Gerasimos&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Schuller%2C%20Bj%26%23246%3Brn&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Schuller, Bj&#246;rn&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Sonntag%2C%20Daniel&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Sonntag, Daniel&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Aguilera%2C%20Marcos%20K%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Aguilera, Marcos K.&nbsp;(1)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Borland%2C%20Russell&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Borland, Russell&nbsp;(1)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Buxton%2C%20William&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Buxton, William&nbsp;(1)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Donaldson%2C%20Cammie&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Donaldson, Cammie&nbsp;(1)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Eich%2C%20Margaret&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Eich, Margaret&nbsp;(1)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Girill%2C%20T%2E%20R%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Girill, T. R.&nbsp;(1)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Impagliazzo%2C%20John&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Impagliazzo, John&nbsp;(1)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Jewett%2C%20Tom&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Jewett, Tom&nbsp;(1)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Johnson%2C%20Lewis&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Johnson, Lewis&nbsp;(1)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Eeditors%2EsearchDspName=Kim%2C%20W%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Kim, W.&nbsp;(1)</a></li>
</ul>
<div>
<a title="show/hide" class="showhide" id="Reviewers_link" href="javascript: void(0);" onclick="toggle('Reviewers');">Reviewers&nbsp;<img src="gifs/arrow-right.gif" id="Reviewers_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Reviewers_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Jaffe%2C%20Elliot&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Jaffe, Elliot&nbsp;(4)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Brooks%2C%20Andrew&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Brooks, Andrew&nbsp;(3)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Hopkins%2C%20Timothy%20R%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Hopkins, Timothy R.&nbsp;(3)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Lin%2C%20Hua%2DYi&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Lin, Hua-Yi&nbsp;(3)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Mayer%2C%20Herbert%20G%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Mayer, Herbert G.&nbsp;(3)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Arul%2C%20Joseph%20M%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Arul, Joseph M.&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Chang%2C%20Ruay%2DShiung&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Chang, Ruay-Shiung&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Dave%2C%20Maulik%20A&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Dave, Maulik A&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Fleisch%2C%20Brett%20D%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Fleisch, Brett D.&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Gait%2C%20Jason&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Gait, Jason&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Hill%2C%20David%20Gary&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Hill, David Gary&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Jouvelot%2C%20Pierre&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Jouvelot, Pierre&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Kuc%2C%20Bernard&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Kuc, Bernard&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Larson%2C%20Arvid%20G%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Larson, Arvid G.&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Lecarme%2C%20Olivier%20Louis%20Marie&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Lecarme, Olivier Louis Marie&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Lupo%2C%20Chris&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Lupo, Chris&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Narayanaswamy%2C%20Naga%20R&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Narayanaswamy, Naga R&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Olagunju%2C%20Amos%20O&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Olagunju, Amos O&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Popescu%2C%20Claudiu&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Popescu, Claudiu&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=persons%2Ereviewers%2EsearchDspName=Ravinder%2C%20Rajat&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Ravinder, Rajat&nbsp;(2)</a></li>
</ul>
</div>
<div>
<div class="aggHead">Refine by Publications</div>
<div>
<a title="show/hide" class="showhide" id="Publication_Names_link" href="javascript: void(0);" onclick="toggle('Publication_Names');">Publication Names&nbsp;<img src="gifs/arrow-right.gif" id="Publication_Names_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Publication_Names_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20SIGPLAN%20Notices&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM SIGPLAN Notices&nbsp;(635)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20SIGARCH%20Computer%20Architecture%20News&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM SIGARCH Computer Architecture News&nbsp;(299)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=Proceedings%20of%20the%20VLDB%20Endowment&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Proceedings of the VLDB Endowment&nbsp;(179)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20SIGOPS%20Operating%20Systems%20Review&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM SIGOPS Operating Systems Review&nbsp;(151)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=Communications%20of%20the%20ACM&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Communications of the ACM&nbsp;(151)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20Computing%20Surveys%20%28CSUR%29&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM Computing Surveys (CSUR)&nbsp;(118)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20Transactions%20on%20Architecture%20and%20Code%20Optimization%20%28TACO%29&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM Transactions on Architecture and Code Optimization (TACO)&nbsp;(106)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20Transactions%20on%20Storage%20%28TOS%29&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM Transactions on Storage (TOS)&nbsp;(90)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20SIGCOMM%20Computer%20Communication%20Review&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM SIGCOMM Computer Communication Review&nbsp;(82)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20SIGMOD%20Record&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM SIGMOD Record&nbsp;(72)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=IEEE%2FACM%20Transactions%20on%20Networking%20%28TON%29&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">IEEE/ACM Transactions on Networking (TON)&nbsp;(72)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20Transactions%20on%20Embedded%20Computing%20Systems%20%28TECS%29&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM Transactions on Embedded Computing Systems (TECS)&nbsp;(71)</a></li>

<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=Computational%20Linguistics&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Computational Linguistics&nbsp;(68)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=Linux%20Journal&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Linux Journal&nbsp;(63)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=The%20VLDB%20Journal%20%26%238212%3B%20The%20International%20Journal%20on%20Very%20Large%20Data%20Bases&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">The VLDB Journal &#8212; The International Journal on Very Large Data Bases&nbsp;(58)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20Transactions%20on%20Graphics%20%28TOG%29&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM Transactions on Graphics (TOG)&nbsp;(56)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20SIGMETRICS%20Performance%20Evaluation%20Review&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM SIGMETRICS Performance Evaluation Review&nbsp;(54)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=ACM%20Transactions%20on%20Computer%20Systems%20%28TOCS%29&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM Transactions on Computer Systems (TOCS)&nbsp;(52)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=Queue&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Queue&nbsp;(49)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublicationTitle%2Eraw=The%20Journal%20of%20Machine%20Learning%20Research&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">The Journal of Machine Learning Research&nbsp;(45)</a></li>
</ul>
<div>
<a title="show/hide" class="showhide" id="ACM_Publications_link" href="javascript: void(0);" onclick="toggle('ACM_Publications');">ACM Publications&nbsp;<img src="gifs/arrow-right.gif" id="ACM_Publications_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="ACM_Publications_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmPubGroups%2EacmPubGroup=Proceeding&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Proceeding&nbsp;(6213)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmPubGroups%2EacmPubGroup=Newsletter&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Newsletter&nbsp;(1473)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmPubGroups%2EacmPubGroup=Journal&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Journal&nbsp;(1049)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmPubGroups%2EacmPubGroup=Magazine&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Magazine&nbsp;(252)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmPubGroups%2EacmPubGroup=Book&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Book&nbsp;(9)</a></li>
</ul>
<div>
<a title="show/hide" class="showhide" id="All_Publications_link" href="javascript: void(0);" onclick="toggle('All_Publications');">All Publications&nbsp;<img src="gifs/arrow-right.gif" id="All_Publications_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="All_Publications_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=allPubGroups%2EallPubGroup=Proceeding&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Proceeding&nbsp;(7776)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=allPubGroups%2EallPubGroup=Periodical&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Periodical&nbsp;(3356)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=allPubGroups%2EallPubGroup=Book&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Book&nbsp;(48)</a></li>
</ul>
<div>
<a title="show/hide" class="showhide" id="Content_Formats_link" href="javascript: void(0);" onclick="toggle('Content_Formats');">Content Formats&nbsp;<img src="gifs/arrow-right.gif" id="Content_Formats_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Content_Formats_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat=PDF&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">PDF&nbsp;(9786)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat=Html&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Html&nbsp;(378)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat=Video&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Video&nbsp;(287)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat=ePub&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ePub&nbsp;(35)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat=Audio&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Audio&nbsp;(20)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat=Prc&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Prc&nbsp;(14)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat=Ps&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Ps&nbsp;(5)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat=Txt&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Txt&nbsp;(3)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat=Mobi&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Mobi&nbsp;(2)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=resources%2Eft%2EresourceFormat=DivX&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">DivX&nbsp;(1)</a></li>
</ul>
<div>
<a title="show/hide" class="showhide" id="Publishers_link" href="javascript: void(0);" onclick="toggle('Publishers');">Publishers&nbsp;<img src="gifs/arrow-right.gif" id="Publishers_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Publishers_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=ACM&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM&nbsp;(8012)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=Association%20for%20Computational%20Linguistics&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Association for Computational Linguistics&nbsp;(431)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=IEEE%20Press&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">IEEE Press&nbsp;(365)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=IEEE%20Computer%20Society&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">IEEE Computer Society&nbsp;(276)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=VLDB%20Endowment&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">VLDB Endowment&nbsp;(207)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=USENIX%20Association&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">USENIX Association&nbsp;(134)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=IEEE%20Computer%20Society%20Press&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">IEEE Computer Society Press&nbsp;(103)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=MIT%20Press&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">MIT Press&nbsp;(78)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=Springer%2DVerlag&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Springer-Verlag&nbsp;(65)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=Belltown%20Media&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Belltown Media&nbsp;(63)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=JMLR%2Eorg&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">JMLR.org&nbsp;(45)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=Springer%2DVerlag%20New%20York%2C%20Inc%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Springer-Verlag New York, Inc.&nbsp;(41)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=Association%20for%20Computing%20Machinery%20and%20Morgan%20%26%2338%3B%20Claypool&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Association for Computing Machinery and Morgan &#38; Claypool&nbsp;(39)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=Eurographics%20Association&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Eurographics Association&nbsp;(37)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=Society%20for%20Computer%20Simulation%20International&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Society for Computer Simulation International&nbsp;(33)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=Australian%20Computer%20Society%2C%20Inc%2E&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Australian Computer Society, Inc.&nbsp;(32)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=EDA%20Consortium&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">EDA Consortium&nbsp;(28)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=Society%20for%20Industrial%20and%20Applied%20Mathematics&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Society for Industrial and Applied Mathematics&nbsp;(27)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=International%20World%20Wide%20Web%20Conferences%20Steering%20Committee&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">International World Wide Web Conferences Steering Committee&nbsp;(22)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlPublisherName%2Eraw=Consortium%20for%20Computing%20Sciences%20in%20Colleges&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">Consortium for Computing Sciences in Colleges&nbsp;(20)</a></li>
</ul>
</div>
<div>
<div class="aggHead">Refine by Conferences</div>
<div>
<a title="show/hide" class="showhide" id="Sponsors_link" href="javascript: void(0);" onclick="toggle('Sponsors');">Sponsors&nbsp;<img src="gifs/arrow-right.gif" id="Sponsors_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Sponsors_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGARCH&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGARCH&nbsp;(1293)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGPLAN&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGPLAN&nbsp;(1102)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=ACM&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACM&nbsp;(994)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGOPS&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGOPS&nbsp;(774)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGCHI&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGCHI&nbsp;(536)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGMOD&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMOD&nbsp;(503)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=IEEE%2DCS&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">IEEE-CS&nbsp;(430)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGGRAPH&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGGRAPH&nbsp;(404)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGCOMM&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGCOMM&nbsp;(376)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGDA&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGDA&nbsp;(371)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGSOFT&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGSOFT&nbsp;(359)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGMICRO&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMICRO&nbsp;(317)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGHPC&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGHPC&nbsp;(314)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGBED&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGBED&nbsp;(293)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGWEB&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGWEB&nbsp;(282)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGIR&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGIR&nbsp;(258)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGACT&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGACT&nbsp;(224)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGSAC&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGSAC&nbsp;(213)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=SIGAI&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGAI&nbsp;(199)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=sponsors%2EsponsorAbbr=USENIX%20Assoc&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">USENIX Assoc&nbsp;(183)</a></li>
</ul>
<div>
<a title="show/hide" class="showhide" id="Events_link" href="javascript: void(0);" onclick="toggle('Events');">Events&nbsp;<img src="gifs/arrow-right.gif" id="Events_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Events_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SC15&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SC15&nbsp;(43)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=ACSAC%20%2718&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACSAC '18&nbsp;(40)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SC13&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SC13&nbsp;(39)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SC16&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SC16&nbsp;(35)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SC17&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SC17&nbsp;(34)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SIGMOD%2FPODS%2716&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMOD/PODS'16&nbsp;(29)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SC11&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SC11&nbsp;(28)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SC14&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SC14&nbsp;(28)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SIGMOD%2FPODS%20%2718&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMOD/PODS '18&nbsp;(24)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SC12&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SC12&nbsp;(23)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SIGMOD%2FPODS%2715&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMOD/PODS'15&nbsp;(23)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SIGMOD%2FPODS%2714&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMOD/PODS'14&nbsp;(22)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SIGMOD%2FPODS%2717&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMOD/PODS'17&nbsp;(22)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=CCS%20%2717&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">CCS '17&nbsp;(21)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SIGMOD%2FPODS%2713&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMOD/PODS'13&nbsp;(21)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SIGMOD%2FPODS%20%2712&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMOD/PODS '12&nbsp;(20)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=ASPLOS%20%2719&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ASPLOS '19&nbsp;(18)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=ICSE%20%2718&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ICSE '18&nbsp;(18)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=SPLASH%20%2715&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SPLASH '15&nbsp;(18)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=acmdlConferenceAcronym=CCGrid%20%2717&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">CCGrid '17&nbsp;(16)</a></li>
</ul>
<div>
<a title="show/hide" class="showhide" id="Proceeding_Series_link" href="javascript: void(0);" onclick="toggle('Proceeding_Series');">Proceeding Series&nbsp;<img src="gifs/arrow-right.gif" id="Proceeding_Series_img" border="0" width="7" height="7" alt="show/hide"></a>
</div>
<ul id="Proceeding_Series_list" style="display:none">
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=AICPS&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">AICPS&nbsp;(867)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=SC&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SC&nbsp;(405)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=CHI&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">CHI&nbsp;(189)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=ICS&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ICS&nbsp;(185)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=PPoPP&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">PPoPP&nbsp;(163)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=ASPLOS&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ASPLOS&nbsp;(158)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=ACL&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACL&nbsp;(152)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=ISCA&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ISCA&nbsp;(152)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=SIGMOD%2FPODS&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMOD/PODS&nbsp;(148)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=OOPSLA%2FSPLASH&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">OOPSLA/SPLASH&nbsp;(139)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=PLDI&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">PLDI&nbsp;(134)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=SIGMOD&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SIGMOD&nbsp;(134)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=ACL%20Workshops&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ACL Workshops&nbsp;(128)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=CCS&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">CCS&nbsp;(128)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=ICSE&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">ICSE&nbsp;(114)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=CIKM&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">CIKM&nbsp;(111)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=SAC&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">SAC&nbsp;(111)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=MICRO&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">MICRO&nbsp;(109)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=EuroSys&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">EuroSys&nbsp;(98)</a></li>
<li><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&filtered=series%2EseriesAbbr=HPDC&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">HPDC&nbsp;(95)</a></li>
</ul>
</div>
<div>
<div class="aggHead">Refine by Publication Year</div>
<canvas id="canvas" height="250"></canvas>
<script>
          var theChartData = {
              labels : ['1950s','1960s','1970s','1980s','1990s','2000s','2010s'],
              datasets : [
                  {
                      label: "Years",
                      fillColor : "rgba(220,220,220,0.2)",
                      stSrokeColor : "rgba(220,220,220,1)",
                      pointColor : "rgba(220,220,220,1)",
                      pointStrokeColor : "#fff",
                      pointHighlightFill : "#fff",
                      pointHighlightStroke : "rgba(220,220,220,1)",
                      data : [3,17,95,322,890,2673,6142]
                  },
              ]
          }
  
      window.onload = function(){
          var ctx = document.getElementById("canvas").getContext("2d");
          window.myChart = new Chart(ctx).Line(theChartData, {
			  scaleShowLabels : false,
			  responsive: true,
             
              
          });
      }
      </script>
<label for="yearSlide">Published Since</label>
<output for="yearSlide" id="whichYear">1956</output>
<input style="padding-top:10px; width:175px;" type="range" min="1956" max="2019" value="1956" id="yearSlide" oninput="outputUpdate(value)" onmouseup="submitrange(value)">
<datalist id="yearVals">
<option>thelabels</option>
</datalist>
<script>
      
      function outputUpdate(yr) {
      
      document.querySelector('#whichYear').value = yr;
      
      }
      
      </script>
</div>
<div id="Events"></div>
</div>
<div id="results">
<div class="pagerange">
Result 1 &ndash; 20 of 10,142
</div>
<div class="pagelogic">
Result page:
<span><strong>1</strong></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=20&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">2</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=40&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">3</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=60&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">4</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=80&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">5</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=100&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">6</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=120&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">7</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=140&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">8</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=160&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">9</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=180&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">10</a></span>
<span style="padding-left:10px;"></span>
<a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=10140&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">&gt;&gt;</a>
</div>
<br clear="all" />
<div id="resultmenu">
<div id="sortmenu">
Sort by:
<select name="selsort" onchange="sortres(this.options[this.selectedIndex].value);">
<option value="_score">relevance</option>
<option value="publicationDate">publication date</option>
<option value="citedCount">citation count</option>
<option value="download6Weeks">downloads (6 Weeks)</option>
<option value="download12Months">downloads (12 months)</option>
<option value="downloadAll">downloads (overall)</option>
</select>
</div>
</div>
<br clear="all" />
<div class="numbering">
1
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=1118597" target="_self">Efficient file storage using content-based indexing</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81490680804">Jo&#227;o Barreto</a>,
<a href="author_page.cfm?id=81406600883">Paulo Ferreira</a>
</div>
<div class="source">
<span class="publicationDate">October 2005</span>
<span style="padding-left:10px">SOSP '05: Proceedings of the twentieth ACM symposium on Operating systems principles</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 1</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;1</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;2</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;281</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1118597&ftid=353200&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Content-based indexing [MCM01] is a technique of proven effectiveness for efficient transference of file contents over low bandwidth network links. Departing from this context, the natural step of extending the application of this technique to local file storage has been proposed by a number of storage solutions [CN02, QD02, BF04]. ...
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high1118597');">result highlights</a>]</div>
<div class="highlights" id="high1118597" style="display:none">
<strong>Full Text</strong>:<br />
... share a core storage model.File contents are divided into disjoint <em>chunks</em> of data, eachof which is individually stored, along with a ... with a unique hashof its contents, in a repository of <em>chunks</em>. . The actual filesare then stored as sequences of possibly ... actual filesare then stored as sequences of possibly shared referencesto <em>chunks</em> in the repository.Dividing files into smaller <em>chunks</em> implies a higher sim-ilarity probability, which intuitively may suggest a ... probability, which intuitively may suggest a betterstorage efficiency. However, the <em>chunk</em> repository model en-tails higher storage penalties as <em>chunk</em> size is decreased: (a)increased <em>chunk</em> meta-data overhead; (b) increased internalfragmentation, if the <em>chunk</em> ... repository is stored on a block-based device; and (c) lower <em>chunk</em> data compression ratiosare achievable. This trade-off restricts the choice of ... ratiosare achievable. This trade-off restricts the choice of the ex-pected <em>chunk</em> size to relatively high values; hence, existingsolutions do not fully ... similarity that may existin a file system. Furthermore, by storing <em>chunks</em> in a ran-domly organized repository, sequential read performance ispenalized, even ... versioningfile systems and for resource-limited embedded file systems.Storage Architecture. Our <em>chunk</em> storage file system isstacked on top of a regular file ... regular file system, which stores theactual file contents in secondary <em>memory</em>. . Our architecturefollows a simple principle: if a file shares ... Our architecturefollows a simple principle: if a file shares no <em>chunks</em> withthe remaining file system, it should be directly stored in ... stored in theunderlying file system without modification. The portionwhere each <em>chunk</em> is stored in such file is designated as itscontent location.On ... the underlying file system;instead, the file’s metadata will include a <em>chunk</em> pointerfor each such shared <em>chunk</em> referencing its content loca-tion (where its actual contents may be ... awhole unshared file. In order to ease the maintenance ofeach <em>chunk</em> pointer when the content location of a chunkchanges as result ... write access, a level of indirectionis provided by a disk-stored <em>chunk</em> pointer table.Hence, in case of no similarity, no storage overhead ... of each file as a whole,rather than to individual smaller <em>chunks</em>, , thus achievinghigher compression ratios.Since <em>chunk</em> hashes are not stored along with their con-tents, the file ... the file system must be divided and hashed each timesimilar <em>chunk</em> detection needs to be made for new contents.This phase is ... sessions, executed dur-ing idle system periods.The organization of files into <em>chunks</em> employs a <em>chunk</em> coa-lescing step, which optimizes cases where consecutive point-ers to contiguous ... step, which optimizes cases where consecutive point-ers to contiguous shared <em>chunks</em> are detected. Such pointersare replaced by a simple multiple-<em>chunk</em> pointer, thus reduc-ing the storage overhead and allowing faster access ... this is comparable (though not alwaysequivalent) to considering a higher <em>chunk</em> size whenever re-sorting to a lower size would yield no ... <br /> ... de Sistemas e Computadores Investiga o e Desenvolvimento em LisboaExisting Solutions: <em>Chunk</em> Repository Storage Model• To some extent, all existing file storage ... [CN02, QD02, BF04]. – File contents are divided into disjoint <em>chunks</em> of data, each individually stored with a unique hash of ... a unique hash of its contents in a repository of <em>chunks</em>. . – The actual files are then stored as sequences ... are then stored as sequences of possibly shared references to <em>chunks</em> in the repository.Example using <em>Chunk</em> Repository Model:Chunk Repository...`hn cnh1 c1hk ckh1 c1h2 c2`h3 c3h1 c1h4 ... c1h4 c4h5 c5...r5 r2 rkr3 rnr3 rn r4 r1file1file2file3Legendci – <em>chunk</em> contentshi – <em>chunk</em> hashri – <em>chunk</em> reference4Instituto de Engenharia de Sistemas e Computadores Investiga o e Desenvolvimento ... de Sistemas e Computadores Investiga o e Desenvolvimento em LisboaProblems of <em>Chunk</em> Repository Storage Model• Higher storage penalties as <em>chunk</em> size is decreased: 1. Increased <em>chunk</em> meta-data overhead (mainly with <em>chunk</em> hashes); 2. Increased internal fragmentation, if the <em>chunk</em> repository is stored on a block-based device;3. Lower <em>chunk</em> compression ratios are achieved. – Trade-off restricts the choice of ... are achieved. – Trade-off restricts the choice of the expected <em>chunk</em> size to relatively high values, hence existing solutions do not ... even if the file being accessed does not share any <em>chunk</em> with other files– Since <em>chunks</em> are stored in a randomly organized repository.5Instituto de Engenharia de ... Proposed Storage ModelTwo distinguishing principles:1. If a file shares no <em>chunks</em> with the remaining file system, it should be stored in ... stored in a plain form.• Succeeding files that share any <em>chunks</em> with that file will reference those portions of its plain ... will reference those portions of its plain contents2. Hashes of <em>chunks</em> are not stored permanently along with contents of the file ... backgroundPrevious Example using the Proposed Model:file1file2file3c3c4c5 c2 ckcnc1r3 rnLegendci – <em>chunk</em> contentsri – <em>chunk</em> reference6Instituto de Engenharia de Sistemas e Computadores Investiga o e Desenvolvimento ... LisboaChunk Coalescing• Optimises cases where consecutive pointers to contiguous shared <em>chunks</em> are detected.• Such pointers are replaced by a simple multiple-<em>chunk</em> pointer, thus reducing the storage overhead and allowing faster access ... is comparable (though not always equivalent) to considering a higher <em>chunk</em> size whenever resorting to a lower size would yield no ... yield no additional similarity gains.file2file3 c3c4 cnc1r3 rnfile3 c4 c1r3,n(before <em>chunk</em> coalescing)(after <em>chunk</em> coalescing)Example of <em>Chunk</em> Coalescing7Instituto de Engenharia de Sistemas e Computadores Investiga o e Desenvolvimento ... • Storage penalties that resulted from dividing files into smaller <em>chunks</em> are eliminated:– In case of no sharing of a <em>chunk</em>, , no <em>chunk</em> storage overhead;– In case of sharing, storage overhead is negligible ... and always compensated by the gains resulting from the increased <em>chunk</em> sharing:• Hash values are not stored along with contents;• Update ... values are not stored along with contents;• Update coalescing optimises <em>chunk</em> <br /> ... whole, thus achieving higher compression ratios than to individual smaller <em>chunks</em>, , ;8Instituto de Engenharia de Sistemas e Computadores Investiga o e ... Using Content-based IndexingWhy Using Content-based Indexing for File Storage?Existing Solutions: <em>Chunk</em> Repository Storage ModelProblems of <em>Chunk</em> <br />
<br />
<strong>Abstract</strong>:<br />
... a core storage model. File contents are divided into disjoint <em>chunks</em> of data, each of which is individually stored, along with ... a unique hash of its contents, in a repository of <em>chunks</em>. . The actual files are then stored as sequences of ... are then stored as sequences of possibly shared references to <em>chunks</em> <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
2
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=1855529" target="_self">Bimodal content defined chunking for backup streams</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81442615982">Erik Kruus</a>,
<a href="author_page.cfm?id=81100061329">Cristian Ungureanu</a>,
<a href="author_page.cfm?id=81100022312">Cezary Dubnicki</a>
</div>
<div class="source">
<span class="publicationDate">February 2010</span>
<span style="padding-left:10px">FAST'10: Proceedings of the 8th USENIX conference on File and storage technologies</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;USENIX Association
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 32</span></div>
<div></div>
</div>
</div>
<br clear="all" />
<div class="abstract">
Data deduplication has become a popular technology for reducing the amount of storage space necessary for backup and archival data. Content defined chunking (CDC) techniques are well established methods of separating a data stream into variable-size chunks such that duplicate content has a good chance of being discovered irrespective of ...
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high1855529');">result highlights</a>]</div>
<div class="highlights" id="high1855529" style="display:none">
<strong>Full Text</strong>:<br />
also stored local compression estimates,generated by running every fixed-size <em>chunks</em> (ex. 4k, 8k,16k, 32k) through LZO and storing a single ... LZO and storing a single byte with thepercent of original <em>chunk</em> size. Then, given the currentfile offset and <em>chunk</em> size, we could estimate the com-pression at arbitrary points in ... piece-wise constant or linear approximations for the estimatedsize of compressed <em>chunks</em> yielded under 1% errors incompressed DER for our large dataset. ... GB set of summary information (a sequenceof several billion summary <em>chunks</em>, , involving over 400million distinct <em>chunks</em>) ). Such re-analyses took hoursinstead of days. We also stored, ... and duplicatesegments of input data, as well as efficiently ascertainingwhich small-<em>chunk</em> decisions would later generate dupli-cate chunks.To answer existence queries we ... Bloom filters allowed us to quicklysimulate a large number of <em>chunking</em> algorithms on upto 1.5 Terabytes of original raw data using ... We were also interested in knowing the limitsof coalescing small <em>chunks</em> into large <em>chunks</em>. . Since anexact calculation is prohibitive, a simple approximationwas obtained ... simple approximationwas obtained by coalescing all always-together chunksequences into single <em>chunks</em>. . Other tools allowed usto consult an oracle in order ... boxcar functions and CRC-32c hashes al-lowing input streams to be <em>chunked</em> at <em>memory</em> band-width and represented a considerable time savings whengenerating <em>chunking</em> summaries. We verified that usinga faster rolling window (operating essentially ... uponDER measurements for our 1.16 TB dataset.3.3 DER of different <em>chunking</em> algorithmsWithin a given algorithm, there are several parameters,such as minimum ... there are several parameters,such as minimum m and maximum M <em>chunk</em> size, andtrigger level ?, which can generate different behavior.Breaking-apart and ... such as k (the number of small chunksin a big <em>chunk</em>) ... ) and an optional resynchronization pa-rameter r (defining a coarser-grained <em>chunking</em> level 2?+racross which no big <em>chunk</em> may extend). When an algo-rithm was run over the entire ... as the ratio of in-put bytes to bytes within stored <em>chunks</em>. . Bytes withinstored <em>chunks</em> could be reported raw, or as compressedsize estimates. We used ... a wide space of parametersfor amalgamation (fixed- and variable-size big <em>chunks</em>) )and breaking-apart algorithms on this data set. We showplots assuming ... 4 4.5 5 5.5 6 6.5 7 1000 10000 100000DERAverage <em>Chunk</em> Size / bytesk-var comprk-fixed comprBase comprk-vark-fixedBaseFigure 5: Performance of two ... compared to a baselinechunking algorithm “Base”, over a range of <em>chunk</em> sizes.The top 3 “compr” curves are the same data as ... the same data as the lowerthree traces, but DER and <em>chunk</em> sizes are reported as-suming compressed <em>chunk</em> storage.Performance of bimodal amalgamation chunkingFigure 5 compares two bimodal amalgamation ... with standard baselinechunking algorithms “Base”. For each of these 3 <em>chunk</em>- -ing algorithms, raw DER values and <em>chunk</em> sizes arein the bottom 3 traces, while corresponding DER usingstored ... arein the bottom 3 traces, while corresponding DER usingstored compressed <em>chunk</em> sizes appears in the upper 3traces. Comparing the two sets ... sloped,which reflects the rapid initial rise in compression effi-ciency as <em>chunk</em> size is increased. Linearity in the rawDER traces indicate some ... <br /> ... describe should be viewed as examplesof reasonable settings.The “Base” baseline <em>chunking</em> traces shown in Fig.5 varied the minimum, nominal average and ... We consulted b = 3 levels of backupcut-points if maximum <em>chunk</em> size was encountered.The “k-fixed” traces of Fig. 5 use an ... of Fig. 5 use an amalgamationalgorithm, running with fixed-size big <em>chunks</em> (i.e. a bigchunk consists always of k small <em>chunks</em>) ). Half theseruns maintained a 1:2:3 ratio for min:avg:max, with ... useresynchronization points. Investigating more parametersettings showed that minor variations in <em>chunking</em> param-eters typically lay along the same curve: the algorithmwas robust ... allows variable-sized big chunksthat use any number 1–k of small <em>chunks</em>. . It also usedBloom Filter queries for small <em>chunks</em> which were previ-ously encountered but emitted only as part of ... previ-ously encountered but emitted only as part of a previousbig <em>chunk</em> as finer-grained delineators of change regions.In spirit the “k-var” traces ... be viewedas a lower bound for what more sophisticated algorithmsusing sub-<em>chunk</em> information (such as fingerdiff [5]) orchunk rewriting approaches could achieve.Later, ... the most important algorithmic differ-ence between fixed- and variably-sized big <em>chunks</em> layin the increased flexibility of generating and recognizinglarge <em>chunks</em>. . Nevertheless, algorithms in this “k-var”class require more existence queries ... the “k-fixed” algorithm of Fig. 5 can alreadymaintain average compressed <em>chunk</em> sizes up to 3–4 as large as a baseline chunker at ... up to 3–4 as large as a baseline chunker at small <em>chunk</em> sizes (e.g.DER 6.1 at 16100 bytes using k = 4 ... increase in average uncompressedchunk size, even at the largest (96k) <em>chunk</em> sizes pre-sented.Our implementation used a look-ahead buffer of 2ksmall <em>chunks</em> and in-<em>memory</em> Bloom filters for speed.As noted before, a lookahead buffer of ... positives.For the “k-fixed” amalgamation algorithm, we foundall benefits of bimodal <em>chunking</em> over the baseline werenegated by ?2.5% false positives. Falsely identified ... 4 4.5 5 5.5 6 6.5 7 1000 10000 100000DERAverage <em>Chunk</em> ... Size / bytesBase compr16k compr32k compr64k compr96k comprBase16k32k64k96kFigure 6: Breaking-apart <em>chunking</em> algorithms comparedwith baseline performance.we have adapted efficient hash table implementations[19, ... to existencequeries.Variants of amalgamation algorithms, that prioritizeequivalent choices of big <em>chunk</em> if they occurred, werefound to offer no significant performance improvement.In ... badly when run onactual data, often for rather subtle reasons.Small <em>chunk</em> statistics, using an oracleUsing knowledge of the full set of ... using an oracleUsing knowledge of the full set of small <em>chunk</em> emissionswe investigated the statistics of the smaller transition re-gion <em>chunks</em>, , which bore out premise P2 for an amalga-mation algorithm ... out premise P2 for an amalga-mation algorithm using fixed-size big <em>chunks</em>. . For exam-ple (not shown in figures), for k = ... exam-ple (not shown in figures), for k = 8 small <em>chunks</em> in atransition region between two duplicate big <em>chunks</em>, , thebordering small <em>chunks</em> have around 88% chance of be-ing encountered subsequently, dipping to ... of be-ing encountered subsequently, dipping to 86% for cen-tral small <em>chunks</em>. . For one-sided duplication transitions,we found that the small-<em>chunk</em> duplication chance de-cayed from ~75% to ~67%. Bimodal <em>chunking</em> withk = 32 showed small-<em>chunk</em> duplication probability de-clining from 86% adjacent to the duplicate big ... to the duplicate big chunkto 65% at the furthest small <em>chunk</em>. . These experimen-tal results agree with earlier expectations based on ... <br /> DERlimits.epsBimodal Content Defined <em>Chunking</em> for Backup StreamsErik KruusNEC Laboratories <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="6829050d1a010b09031a1d1d1b28060d0b4504090a1b460b07052b1a011b1c010906">[email&#160;protected]</a> UngureanuNEC Laboratories <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="e5a48880978c868486978c96918c848ba58b8086c889848796cb868a88a6809f84979c">[email&#160;protected]</a> Dubnicki9LivesData, ... of storage space necessary forbackup and archival data. Content defined <em>chunking</em>( (CDC) techniques are well established methods of sep-arating a data ... well established methods of sep-arating a data stream into variable-size <em>chunks</em> such thatduplicate content has a good chance of being discov-ered ... good duplicate elimination. Whilethe latter can be achieved by using <em>chunks</em> of small av-erage size, this also increases the amount of ... the amount of metadatanecessary to store the relatively more numerous <em>chunks</em>, ,and impacts negatively the system’s performance. Wepropose a new approach ... a new approach that achieves comparable du-plicate elimination while using <em>chunks</em> of larger averagesize. It involves using two <em>chunk</em> size targets, and mech-anisms that dynamically switch between the two ... from duplicate to non-duplicate data, and elsewhere we use large <em>chunks</em>. . Thealgorithms rely on the block store’s ability to quickly ... a high-quality reply to existence queries for already-stored blocks. A <em>chunking</em> decision is made with limitedlookahead and number of queries. We ... algorithms typ-ically achieve similar duplicate elimination to standardalgorithms while using <em>chunks</em> 2–4 times as large. Suchapproaches may be particularly interesting to ... systems that use redundancy techniques (suchas error-correcting codes) requiring multiple <em>chunk</em> frag-ments, for which metadata overheads per stored chunkare high. We ... algorithm variants with more flex-ibility in location and size of <em>chunks</em> yield better dupli-cate elimination, at a cost of a higher ... long) into data to reproducibly separate thedata stream into variable-size <em>chunks</em> that have good du-plicate elimination properties. Such <em>chunking</em> is proba-bilistic in the sense that one has some control ... the sense that one has some control over theaverage output <em>chunk</em> size given random data input. A“baseline” CDC algorithm has as ... set of minimum, average and maximum chunklengths, and it generates <em>chunks</em> of the desired size rangeby inspecting only the input stream. ... abackup cut-point policy to deal with the situations whenthe maximum <em>chunk</em> size has been reached without en-countering a good cut point. ... that are identical to a previously emitted chunk.As the average <em>chunk</em> size of such baseline CDCschemes is reduced, the efficiency of ... reduced, the efficiency of deduplication in-creases. CDC schemes with average <em>chunk</em> sizes ofaround 8k have been used [25] and shown to ... and shown to result inreasonable deduplication. However, in storage systems,smaller <em>chunk</em> sizes come with costs:• higher metadata overheads, as each <em>chunk</em> needs tobe indexed;• higher processing cost, which is proportional to ... of data packets processed;• and lower compression ratio for each <em>chunk</em>, , ascompression algorithms tend to perform better onlarger input.For distributed ... Metadata needs to be associated with each ECCcomponent of a <em>chunk</em>, , and the indexing informationused to find a block given ... hash needs to bestored redundantly; this results in higher per <em>chunk</em> ... over-head than other systems. Additionally, network costs in-crease as more <em>chunks</em> are processed. Thus, it is desirableto produce large <em>chunks</em> without unduly lowering the du-plicate elimination ratio (DER), which we ... that the DER as defined takes into account bothdeduplication among <em>chunks</em> and individual <em>chunk</em> com-pression, but excludes metadata storage costs. The effectof the metadata ... <br /> ... exis-tence query operation that allows one to check whethera tentative <em>chunk</em> has been encountered in the past. Bya “better” duplicate elimination ... duplicate elimination algorithm, we mean onethat produces a larger average <em>chunk</em> size than a baselineCDC algorithm while obtaining comparable DER.P1 is ... high rollover of content. P1 implies that an algorithmshould produce <em>chunks</em> of large average size when in anextended region of previously ... region if in some vicinity of it there ex-ist both <em>chunks</em> that were encountered in the past, andchunks that were not. ... P2 is somewhat counter-intuitive, since it involvesspeculatively injecting undesirable small <em>chunks</em> into thestorage system while providing no guarantee of an even-tual ... storingmany versions of an evolving data set.Note that our bimodal <em>chunking</em> algorithms avoidproblems with historical approaches that use resem-blance detection [10, ... [4] in which first a similar set of al-ready stored <em>chunks</em> can be quickly selected, and thendeduplication is performed within that ... set-ting, since both the fast querying algorithm and our bi-modal <em>chunking</em> algorithms are exploiting assumptionsabout stream locality.The paper is structured as ... we de-scribe baseline CDC algorithms and introduce two typesof bimodal <em>chunking</em> improvements: splitting-apart andamalgamation algorithms. In Section 3 we begin by ... not quite hold for our data set, yet the algorithmsproduced <em>chunk</em> sizes 2–4 times larger than those pro-duced by a baseline ... work and Section 5 presentsconclusions and future work.2 Method2.1 Using <em>chunk</em> ... existence informationTwo approaches exist. In one, a breaking-apart algo-rithm first <em>chunks</em> everything with large <em>chunks</em>, , identi-fies change regions of new content, and then re-chunksdata ... small insertion/modification of aninput stream likely renders an entire large <em>chunk</em> non-duplicate. Were this large <em>chunk</em> re-<em>chunked</em> smaller,later occurrences of a short region of repeated changecould be ... a slightly more flexible approach, a building-up al-gorithm can initially <em>chunk</em> at a fine level, and combinesmall <em>chunks</em> into larger ones. A building-up chunkingalgorithm can query for candidate ... larger ones. A building-up chunkingalgorithm can query for candidate big <em>chunks</em> ... at morepositions, and more finely bracket such a single insert-ed/modified <em>chunk</em>. . In both cases, at any point in theinput stream, ... <br /> to emita small <em>chunk</em> or a big <em>chunk</em>, , so we refer to these al-gorithms as bimodal <em>chunking</em> algorithms, as opposed tothe (unimodal) baseline CDC approaches.In either approach, ... approach, it is always advantageous to emitan already existing big <em>chunk</em>. . If several big <em>chunk</em> emis-sions are possible, we emit the first-most one. Smallchunks are ... non-duplicate bigchunks near (adjacent to, in measurements below) du-plicate big <em>chunks</em>. . Note that in both schemes, some datamay be stored ... both schemes, some datamay be stored in both small- and large-<em>chunk</em> ... format. Inprinciple, this loss may be mitigated by rewriting suchlarge <em>chunks</em> as two (or more) smaller <em>chunks</em>. . However,for systems with in-line deduplication, rewriting an al-ready emitted ... However,for systems with in-line deduplication, rewriting an al-ready emitted big <em>chunk</em> as two or more <em>chunks</em> may beimpractical, so we will not consider <em>chunk</em>- -rewriting ap-proaches. Nevertheless, this might be possible to imple-ment as ... store can be efficiently queried for existence ofchunks given a <em>chunk</em> content hash. Our algorithms oper-ate in constant time per unit ... time per unit input, regardless of the num-ber of stored <em>chunks</em>, , since they require only a boundednumber of <em>chunk</em> existence queries per <em>chunking</em> deci-sion. Implementations of bimodal <em>chunking</em> can vary inthe number and type of existence queries required ... inthe number and type of existence queries required beforemaking a <em>chunking</em> decision. In general, we will find thatthe more flexibility one ... bracketing change regionsand in what boundaries are allowed for large <em>chunks</em>, , thebetter one’s performance can be in terms of increasingchunk ... does not require storing in-formation about finer-grained blocks (e.g. non-emittedsmall <em>chunks</em>) ), and thus works well with any block storecapable of ... works well with any block storecapable of answering whether a <em>chunk</em> with a givenhashkey has already been stored or not. More ... an indirect addressing method, the first timea largely unmodified big <em>chunk</em> is re-<em>chunked</em> ... as smallchunks, one pays the price of speculatively storing manysmall <em>chunks</em> that have no guarantee of ever being en-countered again. If ... no guarantee of ever being en-countered again. If the small <em>chunks</em> re-occur sufficientlyfrequently in later backups (i.e. a finer grained delimitingof ... our data set, the algorithms workedwell, resulting in an average <em>chunk</em> size 2–4 times higherthan baseline CDC for comparable DER.2.2 Baseline ... baseline CDC for comparable DER.2.2 Baseline rolling window cut-point se-lection.Content-defined <em>chunking</em> works by selecting a set of lo-cations, called cut-points, to ... lo-cations, called cut-points, to break apart an input stream,where the <em>chunking</em> decision is based on the contents ofthe data itself. Typically ... of thewindow is considered a cut-point. This generates an av-erage <em>chunk</em> size of 2?, following a geometric distribu-tion. For terseness, we ... maximized when the region searched is ofsize 2?.Backup cut-pointsFor minimum <em>chunk</em> size m, the nominal average chunksize is m + 2?. ... nominal average chunksize is m + 2?. For a maximum <em>chunk</em> size M, a plainlevel-2? chunker (i.e. <em>chunking</em> algorithm) will hit themaximum with probability approximately e?(M?m)/2? ,which can ... with probability approximately e?(M?m)/2? ,which can be quite frequent. Since <em>chunking</em> at M is nolonger content-defined, the deduplication of two similarstreams ... adopted a simple approach of choosinga best content-defined “backup” cut-point, <em>chunked</em> ata level 2??b, to decrease the use of these non ... thehighest of b =2–3 backup levels; otherwise, we emit anon-content-defined <em>chunk</em> of maximal length. In prac-tice, if one adopts the earliest ... cut-point, other pa-rameters can be varied to increase the average <em>chunk</em> sizeagain. This may result in a small performance improve-ment. More ... possible [15].1 f o r ( each b i g <em>chunk</em> ) {2 i f ( isBigDup )3 { em i ... <br /> example of a simple breaking-apart algorithm that re-<em>chunks</em> a nonduplicate big <em>chunk</em> either before or after aduplicate big <em>chunk</em> is detected is shown in Figure 1.Here the primary pass ... primary pass over the data is done with alarge average <em>chunk</em> size, emitting big duplicates in line2–3. Otherwise, in lines 4–5, ... a single nonduplicate datachunk after or before a duplicate big <em>chunk</em> is re-chunkedat smaller average block size and emitted. Remainingchunks are ... average block size and emitted. Remainingchunks are emitted as big <em>chunks</em> in line 6. One can mod-ify such an algorithm to ... duplicate/nonduplicate transitions; e.g., when Nnon-duplicates are adjacent to D duplicates, re-<em>chunk</em> Rbig <em>chunks</em> with smaller average size. Here we presentresults for N = ... When we variedR we found that similar results for average <em>chunk</em> size andDER could be obtained by simply varying the chunkingparameters ... is-NextBigDup predicate. Querying work is bounded byone query per large <em>chunk</em>. . This is the fastest of theproposed algorithms. In Fig. ... illustrate the opera-tion on a simple example input 2(a). Big <em>chunks</em> (b) arequeried for existence (c) and we assume duplicate andnon-duplicate ... assume duplicate andnon-duplicate tags are assigned as shown. All duplicatebig <em>chunks</em> should be stored. Of the remaining <em>chunks</em>, ,the transition regions (d) are re-<em>chunked</em> at smaller av-erage <em>chunk</em> size. The remaining non-duplicate chunksare re-emitted as big <em>chunks</em> (e). In the final (f) bimodalchunking, <em>chunks</em> 2–6 and 9–11 are of small length. Ofthese, note that ... the byte-level duplica-tion boundaries of the input stream (a), small <em>chunks</em> 2, 3and 11 are entirely within the duplicate bytes area, ... enhanced probabilities of recurring later.In essence, the small transition region <em>chunks</em> can allowthe extent of duplicate bytes to be more faithfully ... to be more faithfully repre-sented.(Non?duplicate bytes)(a) Input byte stream(b) Big <em>chunk</em> locations identified(c) Duplicate/Nonduplicate label(dup bytes)(dup bytes)D N N N N ... 5 6 7 8 129 102 3 11(f) Final bimodal <em>chunking</em>: : 1,2,3,...Figure 2: Breaking-apart algorithm steps.2.4 <em>Chunk</em> amalgamation algorithmsConsiderably more flexibility in generating variably-sized <em>chunks</em> is afforded by running a smaller chunkerfirst, followed by <em>chunk</em> amalgamation into big chunks.Consider a simple case where big <em>chunks</em> are only gen-erated by concatenation of a fixed number k ... they are formed from a constant num-ber of variably-sized small <em>chunks</em> during the initial for-ward search for big duplicates (lines 3–6). ... duplicates (lines 3–6). Their lengthin bytes is variable and their <em>chunk</em> endpoints are content-defined. We will call the above algorithms with ... content-defined. We will call the above algorithms with fixed-size big <em>chunks</em> “k-fixed” algorithms. When the forwardsearch for duplicates fails, lines 7–8 ... When the forwardsearch for duplicates fails, lines 7–8 emit k <em>chunks</em> fol-lowing a duplicate as small <em>chunks</em> when following a du-plication region. Otherwise, those k <em>chunks</em> are amalga-mated and emitted as a single big <em>chunk</em> in line 9.A simple extension modifies lines 3–6 to allowvariably-sized ... line 9.A simple extension modifies lines 3–6 to allowvariably-sized big <em>chunks</em> (1–k or 2–k small <em>chunks</em>) ) tobe queried at every possible small <em>chunk</em> position duringthis decision-making process. We will label such exten-sions as ... fixed-size big chunkswe make at most 1 query per small <em>chunk</em>, , while forvariable-size big <em>chunks</em> we can make up to k? 1 (or k)queries per ... introduce resynchronization cut-points: when-ever the cut-point level of a small <em>chunk</em> exceeds somethreshold (r higher than the normal <em>chunking</em> threshold?), a big <em>chunk</em> can terminate there, but may never con-tain the resynchronization point ... c e s s ( s m a l l <em>chunks</em> buf [0 t o 2k?1] ) {2 f o r ... revDupBig = t r u e10 }Figure 3: A simple <em>chunk</em> amalgamation algorithm, inwhich k contiguous small <em>chunks</em> constitute a big chunk.Big duplicate <em>chunks</em> are always desirable (lines 2–6).Small <em>chunks</em> can only be emitted either in line 4, upondetecting an ... <br /> ... protect against certain ma-licious inputs, but will lower the average <em>chunk</em> size. Asecond means to favor spontaneous resynchronization isto use a ... theoretical interest. We maintained Bloom filters formany different types of <em>chunk</em> emission separately: smallchunks and big <em>chunks</em>, , both emitted and non-emitted.One benefit (for example) is to ... concept of ‘du-plicate’ data region to include both previously emittedsmall <em>chunks</em> as well as non-emitted small <em>chunks</em> (thatwere emitted as part of some previous big <em>chunk</em> emis-sion). An algorithm modified to query non-emitted smallchunks (i.e. the ... An algorithm modified to query non-emitted smallchunks (i.e. the small <em>chunks</em> that were not emitted be-cause they were part of some ... were not emitted be-cause they were part of some big <em>chunk</em>) ) can detect du-plicate data at a more fine-grained level, ... more fine-grained level, at the cost ofadditional storage for such sub-<em>chunk</em> metadata. Never-theless, when resources are more plentiful, implementa-tions such as ... that transition regions are nevercovered by more than k small <em>chunks</em>. . It is also quitereasonable to extend the lookahead to ... It is also quitereasonable to extend the lookahead to 3k?1 <em>chunks</em>, , andallow up to 2k?1 small <em>chunks</em> to precede an upcomingduplicate big <em>chunk</em>, , as depicted in Fig. 4The logic of breaking apart ... and 4) is highly similar. For amalgama-tion input 4(a), small <em>chunks</em> (b) are used to form bigchunks that are defined here ... are defined here as exactly 3 consecutive(dup bytes)(dup bytes)(b) Small <em>chunk</em> locations identified(d) Transition regions remain small(e) non?duplicate interior big chunk3 ... N NN N N N NNND DN8 9(f) Final bimodal <em>chunking</em>: : 1,2,3,...(a) Input byte streamFigure 4: “k-fixed” amalgamation algorithm steps. ... byte streamFigure 4: “k-fixed” amalgamation algorithm steps. Weassume fixed-size big <em>chunks</em> are constituted of preciselythree small <em>chunks</em> in this example.small <em>chunks</em>. . Big <em>chunks</em> are queried in 2/4(c) and first-most-occurring duplicate big <em>chunks</em> are emitted. Of theremaining <em>chunks</em>, , transition regions 2/4(d) are emittedas small <em>chunks</em>. . The remaining non-duplicate interiorchunks are re-emitted as a series ... remaining non-duplicate interiorchunks are re-emitted as a series of big <em>chunks</em> inasmuchas possible 2/4(e), with one straggling small <em>chunk</em> leftover at the end in 4(e). The final <em>chunk</em> emission 4(f)has small <em>chunks</em> 2–4 and 6–9. With the byte-level du-plication points as in ... 6–9. With the byte-level du-plication points as in 4(a), small <em>chunks</em> 2 and 9 lie en-tirely within the span of duplicate ... amalgamation algorithmsthan for breaking-apart. Breaking apart uses one queryper big <em>chunk</em>, ... , whereas k-fixed amalgamation uses up tok queries per big <em>chunk</em> (one per small), and k-var amal-gamation for big <em>chunks</em> consisting of 2–k small chunksuses up to k(k?1) queries per ... of 2–k small chunksuses up to k(k?1) queries per big <em>chunk</em>. . The increasednumber of existence queries for k-var amalgamation maybe ... releases ofseveral large projects. Their work targeted improvementsfor very small <em>chunk</em> sizes (&lt; 1KB), while we target largechunk sizes.3.2 Simulation toolsWe ... binary “summary” of theinput data, storing fine-grained information about poten-tial <em>chunk</em>- -points that could later be reused to generateany coarser-grained re-<em>chunking</em>. . For every small chunkgenerated with expected size 512 bytes, ... expected size 512 bytes, we stored theSHA-1 hash of the <em>chunk</em>, , as well as the <em>chunk</em> sizeand actual cut-point level ? (# of terminal zeroes in ... window hash). The summary data was obtainedby running with minimum <em>chunk</em> size 1 byte and max-imum <em>chunk</em> size 100k, with expected <em>chunk</em> size 512bytes. This <em>chunk</em> data was sufficient to re-<em>chunk</em> our in-put data sets. Data sets that generate no <em>chunk</em>- -points atall (e.g. all-zero inputs) are better handled by reducingthe ... atall (e.g. all-zero inputs) are better handled by reducingthe maximum <em>chunk</em> <br /> ... ofthe byte-level non-duplicate region in 4(a) with respectto the small <em>chunk</em> transition region 4(d).Performance of bimodal breaking-apart chunkingIn Figure 6 we ... with a breaking-apart al-gorithm, which uses one query per large <em>chunk</em>, , com-pared to the baseline algorithm. Most runs retain base-line ... additional points vary R, the size of transitionregion that gets re-<em>chunked</em>, , but do not depart substan-tially from the breaking-apart curves ... reasonable performance is obtainable by choosing asmall chunker with average <em>chunk</em> size about 4–8 timessmaller than the original baseline chunker.Comparing Figs. ... can be competitive with theperformance of amalgamation algorithms with fixed-sizebig <em>chunks</em>, , particularly in the regime of <em>chunk</em> sizes&amp;40k. The practical benefit of breaking-apart over the“k-fixed” amalgamations of ... values. For example, with a metadataoverhead of 800 bytes per <em>chunk</em>, , we can use the knowntotal amount of input bytes ... chunksizes where metadata overhead is a substantial fractionof the stored <em>chunk</em> size. We see that including metadatamagnifies the DER improvement relative ... the DER improvement relative to a baselinechunker of equivalent average <em>chunk</em> size. The figuremotivates maintaining average <em>chunk</em> sizes much larger(preferably &amp; 20 ) than the per-<em>chunk</em> metadata over-head.Data # ofversionsBaselinechunk size /bytesBaselineDERAmalgamationchunk size /bytesAmalgamationDERCompressedsize of 16krecords ... LZO) achieved by baseline chunkers and amalgamation algorithms. The averageinput <em>chunk</em> size of the baseline chunker was 16k with allowed sizes ... allowed sizes 8k–24k and two backup levels. The amalgamationused large <em>chunks</em> composed of exactly k = 8 small <em>chunks</em>. . Values of <em>chunk</em> size and DER reflect <em>chunks</em> stored incompressed LZO format. The average compressibility of fixed-length 16k ... 4 4.5 5 5.5 6 6.5 7 1000 10000 100000DERAverage <em>Chunk</em> Size / bytesk-fixed comprk-fixed+800 comprBase comprBase+800 comprBaseBase+800Figure 7: Two baseline ... files for con-secutive releases of several large projects. The com-pressed <em>chunk</em> size and DER under one set of baselineconditions and an ... set of baselineconditions and an amalgamation algorithm based uponthese small <em>chunks</em> is shown in Table 1. We see thatamalgamation has increased ... in Table 1. We see thatamalgamation has increased the average <em>chunk</em> size ofstored <em>chunks</em> by a factor of around 2.5, with a worstcase decrease ... a reasonable value for thelarge dataset. Improvements in DER and <em>chunk</em> size aremuch worse for these small archive datasets, when com-pared ... baseline chunkers all display uncompressed DERthat approaches 1.0 as average <em>chunk</em> size rises, showingthat at large <em>chunk</em> sizes, DER can be obtained primarilyby using compression. These data ... <br /> ... at 4k averagechunk size, 4.12 compressed) and least compressibility(fixed-size 16k <em>chunks</em> were compressed to 46% of theiroriginal length).Even though there is ... a small subset of files, amalgamation still showsmodest DER vs. <em>chunk</em> size improvement with respectto baseline CDC <em>chunking</em>. . Lightly degraded DER wasachieved with average <em>chunk</em> sizes larger by factors of2.5 (see Table 1) in these ... A simple set of optimization moves is toalways amalgamate consecutive <em>chunks</em> that always oc-curred together. This will not affect the DER ... not affect the DER at all, butwill increase the average <em>chunk</em> size. Iterating this pro- 1 2 3 4 5 6 ... 1 2 3 4 5 6 1000 10000 100000 1e+06DERAverage <em>Chunk</em> Size / bytesBase comprBasecompr 2,4,8,16 x 4k2,4,8,16 x 4k4,8,12,16,20 x ... x 16k4,8 x 16k2,3,4 x 32k2,3,4 x 32k4k6k8k16k32k4k6k8k16k32k4k8k16k32k48k64k128k256k512k4k16k64k(a) DER vs. <em>chunk</em> size: gcc dataset 1 2 3 4 5 6 1000 ... 1 2 3 4 5 6 1000 10000 100000 1e+06DERAverage <em>Chunk</em> Size / bytesBase comprBasecompr 2,4,8,16 x 4k2,4,8,16 x 4k4,8,12,16,20 x ... x 16k2,3,4 x 32k2,3,4 x 32k4k6k8k16k32k4k6k 8k16k 32k4k16k64k4k16k64k(b) DER vs. <em>chunk</em> size: gdb dataset 1 2 3 4 5 6 1000 ... 1 2 3 4 5 6 1000 10000 100000 1e+06DERAverage <em>Chunk</em> Size / bytesBase comprBasecompr 2,4,8,16 x 4k2,4,8,16 x 4k4,8,12,16,20 x ... 16k4,8 x 16k2,3,4 x 32k2,3,4 x 32k4k6k8k16k32k4k6k 8k16k32k4k16k64k4k16k64k(c) DER vs. <em>chunk</em> size: linux dataset 1 2 3 4 5 6 1000 ... 1 2 3 4 5 6 1000 10000 100000 1e+06DERAverage <em>Chunk</em> Size / bytesBase comprBasecompr 2,4,8,16 x 4k2,4,8,16 x 4k4,8,12,16,20 x ... x 16k2,3,4 x 32k2,3,4 x 32k4k6k8k16k32k4k6k 8k16k 32k4k16k64k4k16k64k(d) DER vs. <em>chunk</em> size: emacs datasetFigure 8: Duplicate elimination versus stored <em>chunk</em> ... size measurements on consecutive source code releases. Baselineand bimodal k-fixed <em>chunking</em> were performed, yielding results for uncompressed storage (lower traces, open ... (lower traces, open symbols)and compressed storage (upper traces, solid symbols). <em>Chunk</em> compression used the default LZO settings. Bimodalseries denoted in the ... “k1,k2, ... x Nk” amalgamate a fixed number, k, of <em>chunks</em> output from the baselinechunker with Nk average <em>chunk</em> length. 3 3.5 4 4.5 5 5.5 6 1000 10000 ... 3 3.5 4 4.5 5 5.5 6 1000 10000 100000DERAverage <em>Chunk</em> Size / bytesBaselineAmalgamations (withvariably sized big <em>chunks</em>) )A theoretical limit512-byte smalls, amalgamatealways-together chunks8k smallsFigure 9: Baseline and ... chunks8k smallsFigure 9: Baseline and k-var amalgamation are comparedwith theoretical <em>chunk</em> size limits determined by amalga-mating every set of <em>chunks</em> which always co-occurred inour 1.16 Terabyte data set. k-var amalgamation ... are included here for com-parison.duces that longest possible strings of <em>chunks</em> that alwaysco-occurred and increases the average <em>chunk</em> size. Thisparallelized calculation is lengthy and non-scalable.Using “future knowledge” to ... is lengthy and non-scalable.Using “future knowledge” to amalgamate all always-together <em>chunks</em> was done for input <em>chunk</em> sequences of512 and 8192 average size to produce two isolated ... withchunks 512 bytes long on average, increased the averageuncompressed stored <em>chunk</em> size from 576 to 5855 bytes(i.e. the average number of ... bytes, once again nearly afactor of 10 improvement in uncompressed <em>chunk</em> size.In practice, amalgamating often- or always-togetherchunks opportunistically may be a ... 9 also presents a number ofamalgamation results with variable-size big <em>chunks</em> (k-1queries per small <em>chunk</em>) ... ). Such amalgamation algorithmsContiguous Dup-Nondup ImpactCount density * # of <em>chunks</em> 1e+06 1e+05 1e+04 1e+03 1 10 100 1000 10000# dup ... number of contiguous duplicatechunks vs. number of subsequent contiguous nondupli-cate <em>chunks</em> at the 512-byte expected <em>chunk</em> <br /> scaled by the number of <em>chunks</em> to pro-duce histogram values representing the total amount ofinput data. ... regardto total amount of input data involved) occurrence is oneduplicate <em>chunk</em> followed by one nonduplicate chunk.come almost half-way from the baseline ... runs had a haphazardselection of m, ? and M small <em>chunk</em> size settings, use0–4 resynchronization cut-points (usually zero or 4), andmostly ... as solidtriangles). This indicates that the additional complica-tion of using sub-<em>chunk</em> information to delineate changeregions was not particularly useful.3.4 Data characteristicsSize-of-modification ... interrogated the anonymized summary stream, aschunked at the 512-byte expected <em>chunk</em> size, using a bit-stream summary of the “current” duplication status ... status of thechunk. The actual histograms of number of contiguousnonduplicate <em>chunks</em> vs. number of contiguous dupli-cate following <em>chunks</em> (and vice-versa) showed an over-whelming and smoothly varying preference to ... an over-whelming and smoothly varying preference to having asingle nonduplicate <em>chunk</em> followed by a single duplicatechunk. A 2-dimensional histogram of the ... A 2-dimensional histogram of the final contigu-ous numbers of duplicate/nonduplicate <em>chunks</em> (after 14full backup sessions) is in Figure 10. The histograms ... provided direct evidence for P2: smallchunks close to duplicate big <em>chunks</em> did indeed have sig-nificantly augmented re-emission probabilities. This ef-fect can ... transition region from duplicate to nondupli-cate bytes within the large <em>chunk</em> being stored as smallerchunks in Figs. 2(d) and 4(d), and ... 2(d) and 4(d), and may be the dominantreason why bimodal <em>chunking</em> works for archival data.This suggests that for input data sets ... input data sets showing suchhigh interspersal of duplicate with nonduplicate <em>chunks</em>, ,alternate approaches may be able to come closer to thetheoretical ... this pa-per. Nevertheless, even for such data, even simple bi-modal <em>chunking</em> heuristics were able to increase averagechunk size by a factor ... or more.4 Related WorkFor our purposes, the speed of blocking (<em>chunking</em>) ) wasa consideration because we target throughputs of severalhundred MB/s. ... fastest approach is tobreak apart the input stream into fixed-size <em>chunks</em>. . Thisis the approach taken in the rsync file synchronizationtool ... is made near that beginning ofa file: after a single <em>chunk</em> is changed, the entire subse-quent <em>chunking</em> will be changed. A new version of a filewill likely ... new version of a filewill likely have very few duplicate <em>chunks</em>. . Pratt [26]provides good comparison of fixed- and variable-sizedchunking for ... to options such as gzip, delta-encoding, fixed-size blocking and variable-size <em>chunking</em>. . For filesys-tems, You et al. [36] compares <em>chunking</em> and delta-encoding. Delta-encoding is particularly good for thingslike log files ... and email, which are characterized by fre-quent small changes.CDC produces <em>chunks</em> of variable size that are bet-ter able to restrain changes ... restrain changes from a localized edit to alimited number of <em>chunks</em>. . Applications of CDC in-clude network filesystems of several types ... in establishing CDC as a widelyused technique. Usually, the basic <em>chunking</em> algorithmis typically only augmented with limits on the mini-mum and ... typically only augmented with limits on the mini-mum and maximum <em>chunk</em> size. More complex deci-sions can be made if one reaches ... <br /> ... detect near-similarity, and has been shown toachieve near-optimal deduplication at small-<em>chunk</em> level[4]. Another recent approach describes a sparse indexingapproach to determining ... a sparse indexingapproach to determining similar segments of an stream[21].Bimodal <em>chunking</em> presumes only an existence queryfor already-stored <em>chunks</em>, , and has the potential to pro-vide system improvements of ... to pro-vide system improvements of several types. The increasein average <em>chunk</em> size (roughly 2.5 in these data sets,and 3–4 in the ... archival data set) decreases thestorage cost for metadata describing these <em>chunks</em>. . Byreducing the number of disk accesses, there are potentialincreases ... WorkIn this paper, we proposed bimodal algorithms that varythe expected <em>chunk</em>- -size dynamically. They are able toperform content-defined <em>chunking</em> in a scalable manner,involving a constant number of <em>chunk</em> existence queriesper unit of input. Significantly, these algorithms re-quire no ... metadata to be stored. We showthat these algorithms increased average <em>chunk</em> size whilemaintaining a reasonable duplication elimination ratio.We demonstrated the benefits ... eval-uate them for other data sets.Under a wide variety of <em>chunking</em> parameters, chunkamalgamation algorithms performed well. They presentmore flexibility in querying ... algorithms performed well. They presentmore flexibility in querying for duplicate <em>chunks</em> than al-gorithms involving breaking apart <em>chunks</em> within a pre-liminary large <em>chunking</em>. . We also plan to investigate al-gorithms that use compressibility ... also plan to investigate al-gorithms that use compressibility to govern <em>chunking</em> de-cisions based on fast entropy estimation.This work has targeted evaluating ... fast entropy estimation.This work has targeted evaluating a prospective bi-modal <em>chunking</em> algorithm that has potential to addressreal issues in the HYDRAstor ... in the HYDRAstor storage system and othersystems that require large per-<em>chunk</em> storage overhead.The simple algorithms of Figs. 1 and 3 used ... data structures, or even new hardware (partic-ularly SSDs) before bimodal <em>chunking</em> becomes a com-mercial offering.6 AcknowledgmentsWe would like to thank our ... <br /> ... D. E., AND LILLIB-RIDGE, M. Extreme binning: Scalable, parallel deduplicationfor <em>chunk</em>- -based file backup. In Proceedings of the 17th IEEEInternational Symposium ... AND TANG, H. K. A framework for analyzing andimproving content-based <em>chunking</em> algorithms. Technical reportHPL-2005-30R1, HP Laboratories, 10 2005.[14] FORMAN, G., ESHGHI, ... <br />
<br />
<strong>Abstract</strong>:<br />
... storage space necessary for backup and archival data. Content defined <em>chunking</em> (CDC) techniques are well established methods of separating a data ... well established methods of separating a data stream into variable-size <em>chunks</em> such that duplicate content has a good chance of being ... duplicate elimination. While the latter can be achieved by using <em>chunks</em> of small average size, this also increases the amount of ... amount of metadata necessary to store the relatively more numerous <em>chunks</em>, , and impacts negatively the system's performance. We propose a ... a new approach that achieves comparable duplicate elimination while using <em>chunks</em> of larger average size. It involves using two <em>chunk</em> size targets, and mechanisms that dynamically switch between the two ... two based on querying data already stored; we use small <em>chunks</em> in limited regions of transition from duplicate to nonduplicate data, ... from duplicate to nonduplicate data, and elsewhere we use large <em>chunks</em>. . The algorithms rely on the block store's ability to ... a high-quality reply to existence queries for already-stored blocks. A <em>chunking</em> decision is made with limited lookahead and number of queries. ... typically achieve similar duplicate elimination to standard algorithms while using <em>chunks</em> 2-4 times as large. Such approaches may be particularly interesting ... that use redundancy techniques (such as error-correcting codes) requiring multiple <em>chunk</em> fragments, for which metadata overheads per stored <em>chunk</em> are high. We find that algorithm variants with more flexibility ... algorithm variants with more flexibility in location and size of <em>chunks</em> yield better duplicate elimination, at a cost of a higher ... <br />
<br />
<strong>References</strong>:<br />
BHAGWAT, D., ESHGHI, K., LONG, D. D. E., AND LILLIBRIDGE, M. Extreme binning: Scalable, parallel deduplication for <em>chunk</em>-based file backup. In <i>Proceedings of the 17th IEEE International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS 2009)</i> (Sept. 2009). <br /> ESHGHI, K., AND TANG, H. K. A framework for analyzing and improving content-based <em>chunking</em> algorithms. Technical report HPL-2005-30R1, HP Laboratories, 10 2005. <br /> GUREVICH, Y., BJORNER, N. S., AND TEODOSIU, D. Efficient <em>chunking</em> algorithm. United States Patent 20060047855, March 2006. <br />
<br />
<strong>Title</strong>:<br />
Bimodal content defined <em>chunking</em> for backup streams <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
3
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=1117631" target="_self">Introduction to the CoNLL-2000 shared task: chunking</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81310493636">Erik F. Tjong Kim Sang</a>,
<a href="author_page.cfm?id=81100033802">Sabine Buchholz</a>
</div>
<div class="source">
<span class="publicationDate">September 2000</span>
<span style="padding-left:10px">ConLL '00: Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning - Volume 7</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;Association for Computational Linguistics
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 175</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;9</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;190</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;1,409</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1117631&ftid=565488&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
We describe the CoNLL-2000 shared task: dividing text into syntactically related non-overlapping groups of words, so-called text chunking. We give background information on the data sets, present a general overview of the systems that have taken part in the shared task and briefly discuss their performance.
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high1117631');">result highlights</a>]</div>
<div class="highlights" id="high1117631" style="display:none">
<strong>Full Text</strong>:<br />
... training material and section 20 as test material 3. The <em>chunks</em> in the data were selected to match the descriptions in ... the descriptions in the previous section. An overview of the <em>chunk</em> types in the training data can be found in ta- ... about the lo- cation of sentence boundaries and information about <em>chunk</em> boundaries. Additionally, a part- of-speech (POS) tag was assigned to ... in section 2, we have used brackets for encoding text <em>chunks</em>. . In the data sets we have represented <em>chunks</em> with three types of tags: 3The text <em>chunking</em> data set is available at http://lcg- www.uia.ac.be/conll2000/chunking/ 129 count % ... (list marker) UCP (unlike coordinated phrase) Table 1: Number of <em>chunks</em> ... per phrase type in the training data (211727 tokens, 106978 <em>chunks</em>) ). B-X I-X 0 first word of a <em>chunk</em> of type X non-initial word in an X <em>chunk</em> word outside of any <em>chunk</em> This representation type is based on a repre- sentation proposed ... sentation proposed by Ramshaw and Marcus (1995) for noun phrase <em>chunks</em>. ... . The three tag groups are sufficient for encoding the <em>chunks</em> in the data since these are non-overlapping. Using these <em>chunk</em> tags makes it possible to approach the <em>chunking</em> task as a word classification task. We can use <em>chunk</em> tags for representing our ex- ample sentence in the following ... -NP 1.8/I-NP billion/B-NP in/B-PP September/B-NP ./O The output of a <em>chunk</em> recognizer may contain inconsistencies in the <em>chunk</em> tags in case a word tagged I-X follows a word ... resolved by assuming that such I-X tags start a new <em>chunk</em>. . The performance on this task is measured with three ... 1. Rule-based systems: Villain and Day; Jo- hansson; D6jean. 2. <em>Memory</em>- -based systems: Veenstra and Van den Bosch. 3. Statistical systems: ... context- free rules for transforming part-of-speech (POS) tag sequences to <em>chunk</em> tag sequences. D6jean (2000) has applied the theory refinement sys- ... den Bosch (2000) examined different parame- ter settings of a <em>memory</em>- -based learning algo- rithm. They found that modified value differ- ... information was used. Zhou, Tey and Su (2000) implemented a <em>chunk</em> tagger based on HMMs. The initial performance of the tag- ... <br /> the relation between tag accuracy and <em>chunk</em> precision and recall is not very strict, tagging accuracy is ... baseline results have been obtained by selecting the most frequent <em>chunk</em> tag for each part-of-speech tag. incorporating <em>chunk</em> probabilities generated by a <em>memory</em>- -based learning process. The two other statistical systems use maximum-entropy ... (2000) trained Ratna- parkhi's maximum-entropy POS tagger to out- put <em>chunk</em> tags. Koeling (2000) used a stan- dard maximum-entropy learner for ... Koeling (2000) used a stan- dard maximum-entropy learner for generating <em>chunk</em> tags from words and POS tags. Both have tested different ... system combination. Tjong Kim Sang (2000) trained and tested five <em>memory</em>- ... -based learning systems to produce dif- ferent representations of the <em>chunk</em> tags. A combination of the five by majority voting per- ... tribution Voting (WPDV) for combining the results of four WPDV <em>chunk</em> taggers and a <em>memory</em>- -based <em>chunk</em> tagger. Again the com- bination outperformed the individual systems. Kudoh ... port vector machine classifiers to predict the unique pairs of <em>chunk</em> tags. The results of the classifiers were combined by a ... 2. A baseline performance was ob- tained by selecting the <em>chunk</em> tag most fre- quently associated with a POS tag. All ... (1991) proposed to approach parsing by starting with finding related <em>chunks</em> of words. By then, Church (1988) had already reported on ... phrases with statistical meth- ods. Ramshaw and Marcus (1995) approached <em>chunking</em> by using a machine learning method. Their work has inspired ... to study the application of learning methods to noun phrase <em>chunking</em> 5. Other <em>chunk</em> types have not received the same attention as NP <em>chunks</em>. . The most complete work is Buchholz et al. (1999), ... which presents results for NP, VP, PP, ADJP and ADVP <em>chunks</em>. . Veenstra (1999) works with NP, VP and PP <em>chunks</em>. . Both he and Buchholz et al. use data generated ... CoNLL-2000 shared task data sets. Ratnaparkhi (1998) has recognized arbitrary <em>chunks</em> as part of a parsing task but did not re- ... a parsing task but did not re- port on the <em>chunking</em> performance. Part of the Sparkle project has concentrated on finding ... Sparkle project has concentrated on finding var- ious sorts of <em>chunks</em> for the different languages ~An elaborate overview of the work ... ~An elaborate overview of the work done on noun phrase <em>chunking</em> can be found on http://lcg-www.uia. ac.be/- erikt/reseaxch/np-chunking.html 131 (Carroll et ... text into syntactically related non-overlapping groups of words, so-called text <em>chunking</em>. . For this task we have generated training and test ... entific Research (NWO). Re ferences Steven Abney. 1991. Parsing by <em>chunks</em>. . In Principle-Based Parsing. Kluwer Academic Pub- lishers. Ann Bies, ... <br /> ... Johansson. 2000. A context sensitive max- imum likelihood approach to <em>chunking</em>. . In Pro- ceedings o] CoNLL-2000 and LLL-2000. Lisbon, Portugal. ... ceedings o] CoNLL-2000 and LLL-2000. Lisbon, Portugal. Rob Koeling. 2000. <em>Chunking</em> with maximum en- tropy models. In Proceedings o/ CoNLL-2000 and ... Yuji Matsumoto. 2000. Use of sup- port vector learning for <em>chunk</em> identification. In Proceedings o~ CoNLL-2000 and LLL-2000. Lis- bon, Portugal. ... Ferran Pla, Antonio Molina, and Natividad Pri- eto. 2000. Improving <em>chunking</em> by means of lexical-contextual information in statistical lan- guage models. ... Portugal. Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text <em>chunking</em> using transformation-based learn- ing. In Proceedings o] the Third A ... University of Pennsylvania. Erik F. Tjong Kim Sang. 2000. Text <em>chunking</em> by system combination. In Proceedings of CoNLL- 2000 and LLL-2000. ... CoNLL- 2000 and LLL-2000. Lisbon, Portugal. Hans van Halteren. 2000. <em>Chunking</em> with wpdv models. In Proceedings o/ CoNLL-2000 and LLL- 2000. ... Buttersworth. Jorn Veenstra and Antal van den Bosch. 2000. Single-classifier <em>memory</em>- -based phrase <em>chunking</em>. . In Proceedings o] CoNLL-2000 and LLL-2000. Lisbon, Portugal. Jorn ... Proceedings o] CoNLL-2000 and LLL-2000. Lisbon, Portugal. Jorn Veenstra. 1999. <em>Memory</em>- -based text <em>chunking</em>. . In Nikos Fakotakis, editor, Machine learning in human language ... GuoDong Zhou, Jian Su, and TongGuan Tey. 2000. Hybrid text <em>chunking</em>. <br /> ... 127-132, Lisbon, Portugal, 2000. Introduction to the CoNLL-2000 Shared Task: <em>Chunking</em> Erik F. Tjong Kim Sang CNTS - Language Technology Group ... into syntactically related non- overlapping groups of words, so-called text <em>chunking</em>. . We give background information on the data sets, present ... briefly discuss their performance. 1 In t roduct ion Text <em>chunking</em> is a useful preprocessing step for parsing. There has been ... fill this gap. 2 Task descr ip t ion Text <em>chunking</em> consists of dividing a text into phrases in such a ... that one word can only be a member of one <em>chunk</em>. . Here is an example sentence: [NP He ] [vP ... only 1.8 billion ] [pp in ][NP September ]. <em>Chunks</em> have been represented as groups of words between square brackets. ... next to the open bracket denotes the type of the <em>chunk</em>. . As far as we know, there are no annotated ... available which contain specific informa- tion about dividing sentences into <em>chunks</em> of words of arbitrary types. We have chosen to work ... II corpus (Marcus et al., 1993), and to ex- tract <em>chunk</em> information from the parse trees in this corpus. We will ... corpus. We will give a global description of the various <em>chunk</em> types in the next section. 3 <em>Chunk</em> Types The <em>chunk</em> types are based on the syntactic cat- egory part (i.e. ... label in the Treebank (cf. Bies (1995) p.35). Roughly, a <em>chunk</em> contains everything to the left of and including the syntactic ... same name. Some Tree- bank constituents do not have related <em>chunks</em>. . The head of S (simple declarative clause) for ex- ... but as the verb is already part of the VP <em>chunk</em>, , no S <em>chunk</em> exists in our example sentence. Besides the head, a <em>chunk</em> also contains pre- modifiers (like determiners and adjectives in NPs), ... but no postmodifiers or arguments. This is why the PP <em>chunk</em> only contains the preposi- tion, and not the argument NP, ... preposi- tion, and not the argument NP, and the SBAR <em>chunk</em> consists of only the complementizer. There are several difficulties when ... the complementizer. There are several difficulties when converting trees into <em>chunks</em>. . In the most simple case, a <em>chunk</em> is just a syntactic constituent without any further embedded constituents, ... like the NPs in our examples. In some cases, the <em>chunk</em> con- tains only what is left after other <em>chunks</em> have been removed from the constituent, cf. &quot; (VP loves ... special cases dur- ing the following description of the individual <em>chunk</em> types. 3.1 NP Our NP <em>chunks</em> are very similar to the ones of Ramshaw and Marcus ... inside an NP con- stituent becomes part of the NP <em>chunk</em>: : (NP The (ADJP most volatile) form) [NP the most ... con- tains four VP constituents. Following Ramshaw and Marcus' V-type <em>chunks</em>, , this sentence will only contain one VP <em>chunk</em>: : ((S (NP-SBJ-3 Mr. Icahn) (VP may not (VP want ... ... It is still possible however to have one VP <em>chunk</em> directly follow another: [NP The impression ] [NP I] [VP ... in the Treebank. Adverbs/adverbial phrases becorae part of the VP <em>chunk</em> (as long as they are in front of the main ... adjectives of the verb are not part of the VP <em>chunk</em>, , e.g. in &quot;[NP they ] [vP are ] [ADJP ... <br /> ... Treebank. Con- sequently it does not belong to any VP <em>chunk</em>: : ((S (SINV (CONJP Not only) does (NP-SBJ-1 your product) ... state that ' &quot;governor&quot; is not included in any baseNP <em>chunk</em>' '. (NP-SBJ *-1) (VP to (VP be (ADJP- PRD excellent)))))) ... cellent ] , but ... 3.3 ADVP and ADJP ADVP <em>chunks</em> mostly correspond to ADVP con- stituents in the Treebank. However, ... the main verb are assimilated into the ADJP respectively VP <em>chunk</em>. . On the other hand, ADVPs that contain an NP ... the other hand, ADVPs that contain an NP make two <em>chunks</em>: : (ADVP-TMP (NP a year) earlier) -+ [NP a year ... parallel to ADVPs, ADJPs that contain an NP make two <em>chunks</em>: : (ADJP-PRD (NP 68 years) old) [NP 68 years ] ... chang- ing these decisions (as can be done in the Treebank-to-<em>chunk</em> conversion script 2) infiu- ences the <em>chunking</em> task. 3.4 PP and SBAR Most PP <em>chunks</em> just consist of one word (the preposition) with the part-of-speech ... tag IN. This does not mean, though, that finding PP <em>chunks</em> ... is completely trivial. INs can also con- stitute an SBAR <em>chunk</em> (see below) and some PP <em>chunks</em> contain more than one word. This is the case with ... one class (as Ramshaw and Marcus did in their N-type <em>chunks</em>) ... ), and that on the other hand tagging all NP <em>chunks</em> inside a PP as I -PP would only confuse the ... handle the recognition of true PPs (prep.+NP) during this first <em>chunking</em> step. ~The Treebank-to-<em>chunk</em> conversion script is available from http://ilk.kub.nl/-sabine/chunklink/ 128 SBAR <em>Chunks</em> mostly consist of one word (the complementizer) with the part-of-speech ... CONJP in the Tree- bank, and are consequently no CONJP <em>chunks</em> in our data. The Treebank uses the PRT constituent to ... the PRT constituent to annotate verb particles, and our PRT <em>chunk</em> does the same. The only multi-word particle is on and ... same. The only multi-word particle is on and off. This <em>chunk</em> type should be easy to recognize as it should coincide ... assigned IN (preposition) or RB (adverb). INTJ is an interjection phrase/<em>chunk</em> like no, oh, hello, alas, good grief!. It is quite ... of two words: the number and the period. The UCP <em>chunk</em> is reminiscent of the UCP (unlike coordinated phrase) constituent in ... conjunction is the head of the UCP, so most UCP <em>chunks</em> consist of conjunctions like and and or. UCPs are the ... of conjunctions like and and or. UCPs are the rarest <em>chunks</em> and are probably not very useful for other NLP tasks. ... other NLP tasks. 3.6 Tokens outs ide Tokens outside any <em>chunk</em> are mostly punctua- tion signs and the conjunctions in ordinary ... The word not may also be out- side of any <em>chunk</em>. . This happens in two cases: Either not is not ... verb is a form of to be). As the right <em>chunk</em> boundary is defined by the chunk's head, i.e. the main ... fact a postmodifier and as such not included in the <em>chunk</em>: : &quot;... [SBAR that ] [NP there ] [vP were ... any major problems ] .&quot; 3.7 P rob lems All <em>chunks</em> were automatically extracted from the parsed version of the Treebank, ... <br />
<br />
<strong>Abstract</strong>:<br />
... text into syntactically related non-overlapping groups of words, so-called text <em>chunking</em>. . We give background information on the data sets, present ... <br />
<br />
<strong>References</strong>:<br />
Jorn Veenstra and Antal van den Bosch. 2000. Single-classifier <em>memory</em>-based phrase <em>chunking</em>. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal. <br /> Jorn Veenstra. 1999. <em>Memory</em>-based text <em>chunking</em>. In Nikos Fakotakis, editor, Machine learning in human language technology. workshop at ACAI 99. <br /> Steven Abney. 1991. Parsing by <em>chunks</em>. In Principle-Based Parsing. Kluwer Academic Publishers. <br /> Christer Johansson. 2000. A context sensitive maximum likelihood approach to <em>chunking</em>. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal. <br /> Rob Koeling. 2000. <em>Chunking</em> with maximum entropy models. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal. <br /> Taku Kudoh and Yuji Matsumoto. 2000. Use of support vector learning for <em>chunk</em> identification. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal. <br /> Ferran Pla, Antonio Molina, and Natividad Prieto. 2000. Improving <em>chunking</em> by means of lexical-contextual information in statistical language models. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal. <br /> Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text <em>chunking</em> using transformation-based learning. In Proceedings of the Third ACL Workshop on Very Large Corpora. Association for Computational Linguistics. <br /> Erik F. Tjong Kim Sang. 2000. Text <em>chunking</em> by system combination. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal. <br /> Hans van Halteren. 2000. <em>Chunking</em> with wpdv models. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal. <br /> GuoDong Zhou, Jian Su, and TongGuan Tey. 2000. Hybrid text <em>chunking</em>. In Proceedings of CoNLL-2000 and LLL-2000. Lisbon, Portugal. <br />
<br />
<strong>Title</strong>:<br />
Introduction to the CoNLL-2000 shared task: <em>chunking</em> <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
4
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=276328" target="_self">Caching multidimensional queries using chunks</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81100017221">Prasad M. Deshpande</a>,
<a href="author_page.cfm?id=81100302058">Karthikeyan Ramasamy</a>,
<a href="author_page.cfm?id=81100294595">Amit Shukla</a>,
<a href="author_page.cfm?id=81100509752">Jeffrey F. Naughton</a>
</div>
<div class="source">
<span class="publicationDate">June 1998</span>
<span style="padding-left:10px">SIGMOD '98: Proceedings of the 1998 ACM SIGMOD international conference on Management of data</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 85</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;4</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;13</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;735</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=276328&ftid=31650&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Caching has been proposed (and implemented) by OLAP systems in order to reduce response times for multidimensional queries. Previous work on such caching has considered table level caching and query level caching. Table level caching is more suitable for static schemes. On the other hand, query level caching can be ...
</div>
<div class="pubother">
Also published in:<br />
June 1998&nbsp;
ACM SIGMOD Record: Volume 27 Issue 2, June 1998
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high276328');">result highlights</a>]</div>
<div class="highlights" id="high276328" style="display:none">
<strong>Full Text</strong>:<br />
... = Product.pid GROUP BY pname, dmonth (Q.1) 1.2 Motivation for <em>Chunks</em> The fact table is usually much larger than the dimension ... common in current systems due to the large amounts of <em>memory</em> available. In this paper, we propose a <em>chunk</em> based scheme that ad- dresses these problems by dividing the ... these problems by dividing the multidimensional query space uniformly into <em>chunks</em> and caching these <em>chunks</em>. . The results of a query are contained in an ... of a query are contained in an integral number of <em>chunks</em>, , which form a “bounding envelop” around the query result. ... query result. (If the query boundaries do not match the <em>chunk</em> boundaries, the <em>chunks</em> in this bounding envelop will contain extra tuples, which need ... contain extra tuples, which need to be filtered out). Since <em>chunks</em> are at a lower granularity than query level caching, they ... queries. By using a fast mapping between query constants and <em>chunk</em> numbers, one can determine the set of <em>chunks</em> needed to completely answer a query. The set of <em>chunks</em> is partitioned into two disjoint sets, such that the <em>chunks</em> in one partition can be found in the cache while ... one partition can be found in the cache while the <em>chunks</em> in the second partition have to be computed using the ... query results can be encapsulated by an integral number of <em>chunks</em>, , the replacement policy can take advantage of the “hotness” ... replacement policy can take advantage of the “hotness” of a <em>chunk</em>, , which has more value than the hotness of a ... <br /> ... level of aggregation, and due to the static definition of <em>chunks</em>, , there is a very simple correspondence between <em>chunks</em> at different levels of aggregation. This defines a clo- sure ... levels of aggregation. This defines a clo- sure property on <em>chunks</em> which states that we can aggre- gate <em>chunks</em> at one level to obtain <em>chunks</em> at a different level of aggregation. This property can be ... aggregation. This property can be used to compute the missing <em>chunks</em>, , since only the corresponding <em>chunks</em> at the base level in the fact table have to ... two levels of aggrega- tion: - (Product,Time) and (Time), with <em>chunk</em>&amp; &amp;g applied at both levels. Thus <em>chunk</em> 0 of (Time) corresponds to <em>chunks</em> (O,l, 2,3) of (Product,Time). This means that <em>chunk</em> 0 of (Time) can be obtained by aggregating <em>chunks</em> (0, 1,2,3) of (Product, Time). This is a very useful ... which can be used to reduce the cost of a <em>chunk</em> miss. Product Figure 3: <em>Chunks</em> at different levels. 4. No redundant storage - If query ... other queries. Replication of such partial results reduce the effective <em>memory</em> available for caching. Hence, the hit ratio of the cache ... adversely affected, reducing the benefit of having a large cache. <em>Chunk</em> based caching eliminates this replication by sharing <em>chunks</em> containing overlapping results, thus allowing more queries to be cached. ... overlapping results, thus allowing more queries to be cached. 3.3 <em>Chunking</em> the Multi-dimensional Space We will now consider the details of ... consider the details of dividing the multi- dimensional space into <em>chunks</em>. . 3.3.1 Ordering the Dimensions To divide the multi-dimensional space ... 3.3.1 Ordering the Dimensions To divide the multi-dimensional space into <em>chunks</em>, , distinct values along each dimension have to be divided ... a common notion of ordering, according to the date. 3.4 <em>Chunk</em> Ranges Once the distinct values in each level of a ... a dimension are ordered, we have to divide them into <em>chunk</em> ranges, which identify the boundaries of <em>chunk</em> regions. Having the cor- rect <em>chunk</em> boundaries is very importarit in order to have a mapping ... is very importarit in order to have a mapping between <em>chunks</em> at different levels of the hierarchy. If dimensions do not ... then we can divide the entire dimension range into uniform <em>chunk</em> ranges. However, this does not work when the dimen- sions ... actual structure of the hierarchy should be considered while defining <em>chunk</em> ranges. Example 3.3 Figure 5 illustrates a problem that arises ... level 2, i.e. Rz,o and Rz,l. This means that a <em>chunk</em> ... which has a range Rz,o cannot be computed from the <em>chunks</em> with ranges R3,0 and R3,1 directly since R3,1 has some ... 3.1 3.2 Figure 6: Ranges according to hierarchy In our <em>chunk</em> based scheme, <em>chunk</em> ranges at one level should map to disjoint sets of ... ranges at a lower level. The following algorithm creates the <em>chunk</em> ranges for a dimension : Algorithm : CreateChunkRanges hiersize = ... For (I = 1 to hiersize - 1) For each <em>chunk</em> <br /> ... benefit is thus proportional to the cost of computing a <em>chunk</em>. . We combined the CLOCK scheme with the notion of ... notion of benefit. Let Benefit(C) denote the benefit of a <em>chunk</em>. ... . We associate one more quantity, called Weight(C) with each <em>chunk</em> C in the cache. The replacement algorithm is as follows: ... replacement algorithm is as follows: Algorithm : ClockBenefit Input : <em>chunk</em> N to be inserted in the cache While ( space ... space not available for N ) Let C be the <em>chunk</em> corresponding to current CLOCK position if (Weight(C) 5 0) Evict ... weight is reset to its initial benefit value whenever the <em>chunk</em> is reaccessed. Our performance results confirm that Algorithm ClockBenefit performs ... We implemented a middle tier cache manager that uses the <em>chunk</em> based scheme. The backend is the Paradise System that has ... is the Paradise System that has been enhanced with the <em>chunked</em> file. We performed several experiments to study how a <em>chunk</em> based caching scheme performs when compared with a query based ... experiments to study improve- ments in bitmap performance from a <em>chunked</em> file organiza- tion. 6.1 Caching Experiments 6.1.1 Experimental Setup The ... on a dual processor Pen- tium 133Mhz having 128MB of <em>memory</em>. . The cache manager and the database server were run ... total number of references to query 4; In case of <em>chunk</em> <br /> UnknownCaching Multidimensional Queries Using <em>Chunks</em> + Prasad M. Deshpande University of Wisconsin, Madison pmd @cs.wisc.edu ... pose caching small regions of the multidimensional space called ‘%hunks”. <em>Chunk</em>- -based caching allows fine granular- ity caching, and allows queries ... queries with which they overlap. To facilitate the computation of <em>chunks</em> required by a query but missing from the cache, we ... a new organization for relational tables, which we call a “<em>chunked</em> file.” Our experiments show that for workloads that exhibit query ... that exhibit query locality, chun- ked caching combined with the <em>chunked</em> file organization performs better than query level caching. An unexpected ... better than query level caching. An unexpected benefit of the <em>chunked</em> file organization is that, due to its multidimensional clustering properties, ... <br /> of the missing <em>chunks</em> from the backend. We introduce a “<em>chunked</em>” ” file organization for relational tables to achieve this goal. ... related work in this field. We explain the concept of <em>chunks</em> and introduce the idea of <em>chunk</em> based caching in Section 3. We describe the <em>chunked</em> file format in Section 4. In Section 5, we give ... detailed description of the issues involved in imple- menting a <em>chunk</em> based caching scheme. Finally, we present our performance results in ... In this paper, we propose a dynamic caching scheme using <em>chunks</em> as a unit of caching and demonstrate its feasibility under ... and should be given preference while caching. Product Figure 1: <em>Chunking</em> the multidimensional space Caching at a granularity smaller than a ... <br /> ... parts depending on how many semantic regions it intersects with. <em>Chunk</em> based caching can be considered as specialized semantic caching. Instead ... having variable semantic regions (in terms of size and shape), <em>chunks</em> divide the space into uniform regions statically. There are many ... There are many benefits due to the static definition of <em>chunk</em> regions, which are described in Section 3.2. It makes cache ... to reorganize data at the backend to correspond to these <em>chunks</em>. . The <em>chunked</em>- -file represen- tation, described in Section 4, reduces the cost ... the cost of a cache miss, since fetching the missing <em>chunks</em> is efficient. None of the previously proposed schemes consider similar ... nization of data to make cache misses less expensive. The <em>chunked</em>- -file organization can also be used for storing pre- computed ... used for storing pre- computed aggregates at the backend. 3 <em>Chunk</em> Based Caching The idea of <em>chunks</em> is motivated by MOLAP systems which use multi-dimensional arrays to ... or column ma- jor order, they are broken down into <em>chunks</em> and stored in a <em>chunked</em> format [SS94, ZDN97]. The distinct values for each dimension are ... distinct values for each dimension are divided into ranges, and <em>chunks</em> are created based on this division. Figure 1 shows how ... how the multidimen- sional space can be broken up into <em>chunks</em>. . Our observa- tion is that <em>chunks</em> are very suitable as a unit of caching, since they ... space into uniform semantic regions. 3.1 Caching Query Results Using <em>Chunks</em> In the <em>chunk</em>- -based caching scheme, query results to be stored in the ... to be stored in the cache are broken up into <em>chunks</em> and the <em>chunks</em> are cached. When a new query is issued, <em>chunks</em> needed to answer that query are determined (this process is ... Depending on the contents of the cache, the list of <em>chunks</em> is partitioned into two. One part is answered 261 from ... from the cache. The other part, consisting of the missing <em>chunks</em>, , has to be computed from the backend. In order ... the backend. In order to reduce the cost of a <em>chunk</em> miss, missing <em>chunks</em> should be computed efficiently at the backend. To achieve this, ... efficiently at the backend. To achieve this, we propose a <em>chunk</em> based organization of data in the backend. It can be ... multi-dimensional array if the database supports it or, as a <em>chunked</em> file (see Section 4) if the system is purely relational. ... pre- computed aggregate tables can also be organized on a <em>chunk</em> basis. To compute any <em>chunk</em>, , we aggregate the correspond- ing <em>chunks</em> of its parent relation according to the group-by hierarchy. Thus, ... relation according to the group-by hierarchy. Thus, only a few <em>chunks</em> of the parent are scanned rather than scanning the entire ... entire table. For example, in Fig- ure 3, to compute <em>chunk</em> 1 of the (Time) group-by, we only need scan <em>chunks</em> 4, 5, 6 and 7 of the (Product, Time) group- ... 7 of the (Product, Time) group- by. 3.2 Benefits of <em>Chunk</em> Based Caching We now discuss the advantages of using <em>chunks</em>: : 1. Granularity of caching - caching <em>chunks</em> rather than entire queries improves the granularity of caching. This ... utilization of the cache in two ways. First, frequently accessed <em>chunks</em> of a query get cached. <em>Chunks</em> which are not frequently accessed will be replaced eventually. The ... used much more effectively. For example, Figure 2 shows a <em>chunk</em> based cache, in which each query represents a portion of ... able to use Q.l and/or Q.2 to answer Q.3. With <em>chunk</em> based caching, Q.3 can use <em>chunks</em> it has in common with Q.l or Q.2. Only the ... has in common with Q.l or Q.2. Only the remaining <em>chunks</em>, , shown by shaded portion, have to be computed. The ... relational back end, discussed in Section 4, enables these remaining <em>chunks</em> to be computed in time proportional to their size (rather ... portional to the size of Q.3.) Figure 2: Reusing cached <em>chunks</em> 2. CJn$ormity - The notion of uniform semantic regions, which ... semantic regions, which are statically defined in the form of <em>chunks</em>, , makes query reuse less complex. By using a fast ... representing the query can be mapped into a set of <em>chunks</em>. . Unlike caching methods based on con- tainment, we don’t ... necessary in simple semantic based schemes. 3. Closure property of <em>chunks</em> - Since <em>chunking</em> <br /> ... R into uniform ranges Example 3.4 Figure 6 shows the <em>chunk</em> ranges obtained by using the above algorithm. Level 3 has ... by using the above algorithm. Level 3 has a desired <em>chunk</em> range of 3 whereas levels 1 and 2 have a ... of 3 whereas levels 1 and 2 have a desired <em>chunk</em> range of 2. The desired <em>chunk</em> range may not match the actual <em>chunk</em> range due to the hierarchy. Since the <em>chunk</em> ranges are no longer uniform, it is necessary to record ... it is necessary to record the range number (also called <em>chunk</em> index number) for each distinct value. This can be stored ... along with the ordinal number in the domain index. 4 <em>Chunked</em> File Organization As discussed previously, the cost of a <em>chunk</em> ... miss can be re- duced by organizing data on a <em>chunk</em>- -basis at the backend. One way to achieve this is ... the backend. One way to achieve this is to use <em>chunked</em> multi-dimensional arrays. However, significant effort is required to incorporate the ... access to the data. We show that the concept of <em>chunk</em>- - ing need not be restricted to arrays, and can ... arrays, and can be applied to relational tables using a <em>chunked</em>- -file organization. In a <em>chunked</em>- -file organization, the data is stored as tuples rearranged on ... organization, the data is stored as tuples rearranged on a <em>chunk</em> basis. Thus all tuples in a <em>chunk</em> are clustered together in the file. A <em>chunk</em> index is created so that given a <em>chunk</em> number it is possible to access all tuples corresponding to ... it is possible to access all tuples corresponding to that <em>chunk</em>. . The <em>chunk</em> index can be implemented using B+ Trees. The <em>chunked</em> file provides two interfaces: a relational interface, so that it ... table and can be used in SQL statements, and a <em>chunk</em> based interface, that allows direct access to individual <em>chunks</em>. . To compute a missing <em>chunk</em>, , we use the <em>chunk</em> index to access the corresponding <em>chunks</em> and aggregate them. The <em>chunked</em> file can be implemented in an existing relational system with ... options are explored in Section 5. 263 4.1 Benefits of <em>Chunked</em> File Organiza- tion The <em>chunked</em> file organization has the following benefits: 1. Reduce cost of ... organization has the following benefits: 1. Reduce cost of a <em>chunk</em> miss - cost of accessing a <em>chunk</em> is proportional to the size of the <em>chunk</em> rather than the size of the entire table. 2. Multi-dimensional ... the size of the entire table. 2. Multi-dimensional clustering - <em>chunked</em> organization achieves excellent multi-dimensional clustering of relational tables. This is ... next section. 4.2 Improving Bitmap Performance Although we developed the <em>chunked</em> file organization pri- marily so that missing <em>chunks</em> could be computed efficiently, a nice side effect of this ... to unordered files. This is independent of the value of <em>chunked</em> files for supporting <em>chunked</em> caching. In this section we explain this benefit and give ... as there are bits set. The clustering achieved by the <em>chunked</em>- -file organization re- duces the number of pages accessed, thus ... (x + k), since tuples will map to the same <em>chunks</em>. . Thus they are likely to cause the same number ... are likely to cause the same number of I/OS for <em>chunked</em> file, but more for a randomly ordered file. Using a ... issues that come up in the imple- mentation of the <em>chunked</em>- -file and the <em>chunked</em> based caching scheme. We will discuss them in this section. ... caching scheme. We will discuss them in this section. 5.1 <em>Chunk</em> Size To determine the <em>chunking</em> of the multi-dimensional space, distinct values along each dimension are ... ranges. The size of the ranges determines the number of <em>chunks</em> and their. Example 5.1 Consider two dimensions A and B ... <br /> use a <em>chunk</em> range of 5 along each dimension, the number of <em>chunks</em> becomes 400 and the average <em>chunk</em> size is s tuples. But if the <em>chunk</em> ran., is of size 10, we get 100 <em>chunks</em> with each <em>chunk</em> of size m. Having smaller <em>chunk</em> ... ranges is good for better granularity of caching. With the <em>chunk</em> based caching scheme, a query is computed in terms of ... caching scheme, a query is computed in terms of its <em>chunks</em>. . The <em>chunks</em> at the bound- ary of the query region have some ... base tuples and is expensive to compute. Thus, having small <em>chunk</em> ranges is important to reduce the extra computation. However, if ... is important to reduce the extra computation. However, if the <em>chunk</em> ranges are too small, then the total number of <em>chunks</em> increases. This, again increases the overhead since the query gets ... increases the overhead since the query gets split into many <em>chunks</em> and also the size of the <em>chunk</em> index at the backend increases. This suggests that the <em>chunk</em> range at any level in the hierarchy should be a ... by [SS94] in the context of multi-dimensional arrays, The missing <em>chunks</em> are computed by scanning the corresponding <em>chunks</em> at the backend. Since disk I/O is in units of ... Since disk I/O is in units of pages, the average <em>chunk</em> size should be a multiple of the page size to ... I/O. Section 6 describes some experiments to determine the optimal <em>chunk</em> range. 5.2 Query Processing 5.2.1 Query Analysis We assume a ... The selection predicates are analyzed to produce a list of <em>chunk</em> numbers required to answer the query. Then, the cache can ... cache can be interrogated to 264 ---J----L---J---- Product Figure 8: <em>Chunk</em> numbering see if any of the required <em>chunks</em> are present in it. For cached <em>chunks</em> to be used to answer a query, the following conditions ... is determined by the dimension-list in the group-by clause. Cached <em>chunks</em> can be used for a query when they are at ... lower level of aggregation than the query. If the cached <em>chunks</em> are at a lower level, they need to be aggre- ... query results. The problem of figuring out the set of <em>chunks</em> (different <em>chunks</em> may be at different lev- els), which can be aggregated ... lev- els), which can be aggregated to get a result <em>chunk</em> is quite complex. In our implementation we assume that all ... attributes of the query and that corresponding to the cached <em>chunk</em> match exactly. This is because, these selections have been factored ... selections on group-by attributes are mapped to a set of <em>chunk</em> num- bers, which are used to lookup in the cache. ... union of regions in the multi-dimensional space. The set of <em>chunks</em> forms a bound- ing envelop around the query region. Since ... post-processing is necessary to filter the extra tuples. 5.2.2 Computing <em>Chunk</em> Numbers Selection predicates on group-by attributes are converted into a ... predicates on group-by attributes are converted into a list of <em>chunk</em> ... numbers, which can be used to determine if the required <em>chunks</em> are present in the cache. We assume that selection predicates ... values along the dimensions or a single point. To calculate <em>chunk</em> numbers, we need a function which will compute the <em>chunk</em> number given a <em>chunk</em> ... index along each dimension. For example, in Figure 8, the <em>chunk</em> number corresponding to index values (0,O) is 0, <em>chunk</em> number for (1,2) is 6. This is computed using a ... selected for dimension i. These val- ues are converted into <em>chunk</em> indices, using the domain in- dex. Let RCi denote the ... the domain in- dex. Let RCi denote the set of <em>chunk</em> indices for dimension i. If there are k group-by dimensions, ... <br /> ... cross product, use the function getChNum() to get the corresponding <em>chunk</em> number. The algorithm is as follows: Algorithm : ComputeChunkNums CNums ... CNums = CNums U {num&gt; CNums is the list of <em>chunks</em> required to answer the query. 5.23 Query Splitting After determining ... the query. 5.23 Query Splitting After determining the list of <em>chunk</em> numbers, we can lookup the <em>chunk</em> cache to see if they have been cached. Depending on ... the list is split into two: (1) CNumsP- resent, of <em>chunks</em> ... present in the cache and (2) CNumsMissing of the missing <em>chunks</em>. . <em>Chunks</em> ... in CNumsPresent can be ob- tained from the cache, while <em>chunks</em> in CNumsMissing have to be computed from the backend. Then, ... the backend. Then, a modified form of SQL, qualified with <em>chunk</em> numbers, is used to compute these <em>chunks</em> from the backend database. For each miss- ing <em>chunk</em>, , it is necessary to determine which <em>chunks</em> of the base table (or some precomputed table) have to ... similar to the one de- scribed in Section 5.2.2. The <em>chunk</em> number is converted to a set of <em>chunk</em> indices (inverse of the getChNum() function). These <em>chunk</em> indices correspond to the aggregated level of the query. They ... of the query. They are converted to a range of <em>chunk</em> indices at the base level using the domain index. The ... at the base level using the domain index. The base <em>chunk</em> numbers are computed from this range of <em>chunk</em> indices using Algorithm ComputeChunkNums. Once the missing <em>chunks</em> are computed and fetched, we have all the <em>chunks</em> necessary to answer the query. It is necessary to do ... the query. It is necessary to do post-processing on the <em>chunks</em> ... which are not contained in the query region (the boundary <em>chunks</em>) ), since they will have more tuples than re- quired ... more tuples than re- quired by the query. The new <em>chunks</em> can be inserted into the cache using cache policies, which ... cache policies, which we discuss later in the paper. 5.3 <em>Chunked</em> File There are two alternatives in implementing a <em>chunked</em> file in the backend. 1. Comprehensive Implementation A new <em>chunked</em> ... file type is added to the backend database, providing a <em>chunk</em>- -based interface in addition to the normal relational interface. This ... relational interface. This can be done by making the backend “<em>chunk</em> aware”, so that it understands <em>chunk</em> based queries and sends back results on a <em>chunk</em> by <em>chunk</em> ... basis. 2. Simple Implementation It is possible to get the <em>chunked</em> file functionality without implementing a new file type. This is ... Add a new attribute to the relation to denote the <em>chunk</em> number (b) Sort the file on the <em>chunk</em> ... number attribute, so that it 265 gets clustered on a <em>chunk</em> basis. (c) Create an index such as the B-Tree on ... (c) Create an index such as the B-Tree on the <em>chunk</em> num- ber attribute. This gives a <em>chunk</em> based access to the file In this approach, the backend ... the file In this approach, the backend is not really <em>chunk</em> ... aware, i.c. it cannot return the results in terms of <em>chunks</em>, , and the middle tier has t,o separate the result ... middle tier has t,o separate the result tuples into different <em>chunks</em> in order to cache them. WC implemented the <em>chunked</em> file in the Par- adise [DKLP+94] Database System using option ... chunkcd file was implemented by using a B-Tree as a <em>chunk</em> index on a fact file. A Fact file [RJZN97] is ... a fast path for “skipped’ sequential access. To achieve a <em>chunk</em> based organization, tuples in the ,fact file are clustered based ... tuples in the ,fact file are clustered based on their <em>chunk</em> numbers. This can be done while bulk-loading the fact fifile. ... the fact fifile. The B-Tree holds one entry for each <em>chunk</em> and points to the start of the <em>chunk</em> in the fact file. Updates can be supported by reserving ... Updates can be supported by reserving extra space in each <em>chunk</em>. . When all the extra space is used up, we ... file. 5.4 Replacement Schemes Replacement schemes are required because old <em>chunks</em> have to be replaced to make room for new <em>chunks</em> in the cache. Simple LRU is one of the options, ... but, it is not very suitable for OLAP queries because <em>chunks</em> at different levels of ag- gregation have different costs of ... computation. For example, it is more expensive to compute a <em>chunk</em> at a high level of aggregation since it requires scanning ... it requires scanning and aggregating a lot of base level <em>chunks</em>. . This cost has to be incorporated into any cache ... a similar replacement scheme which considers the “benefit” of a <em>chunk</em>. . The notion of benefit of a group- by was ... tier, a group-by benefits only itself. The beuefit of a <em>chunk</em> is measured by the fraction of the base table that ... table that it represents. For example, if there are 71. <em>chunks</em> for group-by (A, B), then the benefit of each <em>chunk</em> is @! where JD] is the siz e of the ... siz e of the base table. Since the number 07 <em>chunks</em> <br /> ... compute the CSR using the same formula in terms of <em>chunks</em> instead of queries. However, this is not the exact CSR ... of queries. However, this is not the exact CSR for <em>chunks</em>, , since <em>chunks</em> on the boundary of the query region may fetch data ... by the query, and counting the entire savings of these <em>chunks</em> is not appropriate. The CSR calculated by the above formula ... close to the exact CSR, assuming that percentage of boundary <em>chunks</em> w.r.t. the total number of <em>chunks</em> is less. CSR is a more appropriate metric for OLAP ... Experimental Results We now describe the experimental evaluation of the <em>chunk</em> based caching scheme. comparison with Query Caching We implemented a ... is sim- ilar to the benefit based replacement policy for <em>chunks</em>. . A bitmap index is built on the fact table ... times as well as t,he CSR. In all these cases, <em>chunk</em> based caching does well because of two reasons. It avoids ... caching, where overlapping results are stored multiple times. In addition, <em>chunk</em> based caching exploits overlap between queries which query level caching ... in a higher CSR and lower average execution time for <em>chunk</em> based caching. The ratio of their performance increases as the ... an improvement, factor of about 2. This shows that the <em>chunk</em> based scheme can exploit locality better than query level carhing. ... there is some redundant storage in the cache. For the <em>chunk</em> based scheme, the CSR. was 0.98. Vurying the cache size ... size In this experiment, we varied the cache size for <em>chunk</em> based caching for the query stream QEqual. Figure 6.1.4 shows ... the cache size is increased, the CSR increases, since more <em>chunks</em> can be found in the cache. The execution times reduce ... in the cache. The execution times reduce as expected. Varying <em>chunk</em> dimension range Distinct values on each dimension are divided into ... on each dimension are divided into ranges in order to <em>chunk</em> the multi-dimensional space. As we have previously seen, size of ... multi-dimensional space. As we have previously seen, size of the <em>chunk</em> dimension range is critical to cache performance. In our experiments, ... range is critical to cache performance. In our experiments, the <em>chunk</em> dimen- sion range at any level is kept proportional to ... QEqual, we studied performance by varying the ratio of the <em>chunk</em> di- mension range to the total dimension range from 5% ... times and the CSR w.r.t. the base case of 10% <em>chunk</em> range. It can be seen that <em>chunk</em> range of 5% has a CSR slightly greater than that ... has a CSR slightly greater than that of t,he 10% <em>chunk</em> range, whereas 20% <em>chunk</em> range has a lower CSR. This is due to the ... lower CSR. This is due to the fact, that smaller <em>chunk</em> ranges lead to smaller <em>chunks</em> and better cache use. However, the re- sponse time graph ... CSR, the average response time in the case of 5% <em>chunk</em> range is higher than in the case of 10% <em>chunk</em> range. This is due to the overhead caused by the ... due to the overhead caused by the larger number of <em>chunks</em> when the <em>chunk</em> range is 5%. This shows t,hat, as <em>chunks</em> get smaller, eventually the overhead due to the large number ... smaller, eventually the overhead due to the large number of <em>chunks</em> overcomes the benefit achicvcd due to better cache utilization. he ... varying the cache size on execution time and CSR for <em>chunk</em>- -based caching 268 Figure 12: Effect of varying the <em>chunk</em> range on execution times and CSR L bun ___. - ... ___. - k Caching Schemes - Simple-LRU - Benefit-LRU ---- <em>Chunk</em> Caching Schemes cuery Figure 13: Effect of replacement policies on ... <br /> ... The difference is more pro- nounced in the case of <em>chunk</em> based caching, since <em>chunks</em> may compute more data than asked by the query. When ... more data than asked by the query. When such a <em>chunk</em> is evicted, the excess effort in computing the extra data ... in computing the extra data is wasted. Since, highly aggregated <em>chunks</em> are expensive to compute, this waste can be minimized by ... benefit based policy. 6.2 Bitmap Experiments As explained previously, a <em>chunked</em> file organization will im- prove the performance of bitmaps. The ... obtained in bitmap perfor- mance for a file ordered on <em>chunk</em> basis over a randomly ordered file. The speedup reduces as ... a scan of the entire file, in which case the <em>chunked</em> organization does not matter. 7 Conclusions and Future Work We ... 7 Conclusions and Future Work We have introduced a new <em>chunk</em> based scheme for caching queries that works very well in ... very well in the OLAP domain, where data is multi-dimensional. <em>Chunk</em>- -based caching allows line granularity caching, and allows queries to ... cache. We introduced a new organization for relational tables, called “<em>chunked</em> file”, that reduces the cost of a <em>chunk</em> miss. Our experiments show that for work- loads that exhibit ... experiments show that for work- loads that exhibit query locality <em>chunk</em> based caching com- bined with a <em>chunked</em> file organization performs better than traditional query caching. One of ... than traditional query caching. One of the important issues in <em>chunk</em> based caching is to choose an appropriate <em>chunk</em> range size. Smaller <em>chunk</em> ranges lead to smaller <em>chunks</em> and bet- 269 5 45 4. 35 - 3- i2.5 ... Figure 14: Comparing bitmap performance of a Ale ordered on <em>chunk</em> basis with a randomly ordered file ter caching, but the ... caching, but the overhead due to the larger number of <em>chunks</em> increases. The replacement policy is also very crit- ical for ... showed that it performs much better than simple LRU. The <em>chunked</em> file organization can be implemented with little effort in existing ... systems, while maintaining their relational nature. We showed that the <em>chunked</em> file organization also improves the performance of bitmap indices, since ... work, we are planning to explore the possibility of aggregating <em>chunks</em> in the cache to get a missing <em>chunk</em> rather than going to the backend. This implies that the ... going to the backend. This implies that the notion of <em>chunk</em> benefit has to be im- proved. Another possible enhancement is ... Finally we are planning to explore other applications of the <em>chunked</em> file organization. Since it also partitions data on all the ... <br />
<br />
<strong>Abstract</strong>:<br />
... we propose caching small regions of the multidimensional space called &lt;italic&gt;&amp;ldquo;<em>chunks</em>&amp; &amp;rdquo;&lt;/italic&gt;. <em>Chunk</em>- -based caching allows fine granularity caching, and allows queries to ... queries with which they overlap. To facilitate the computation of <em>chunks</em> required by a query but missing from the cache, we ... a new organization for relational tables, which we call a &amp;ldquo;<em>chunked</em> file.&amp;rdquo; Our experiments show that for workloads that exhibit query ... Our experiments show that for workloads that exhibit query locality, <em>chunked</em> caching combined with the <em>chunked</em> file organization performs better than query level caching. An unexpected ... better than query level caching. An unexpected benefit of the <em>chunked</em> file organization is that, due to its multidimensional clustering properties, ... <br />
<br />
<strong>Title</strong>:<br />
Caching multidimensional queries using <em>chunks</em> <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
5
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=3307523" target="_self">One size does not fit all: the case for chunking configuration in backup deduplication</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=99659259773">Huijun Wu</a>,
<a href="author_page.cfm?id=99659259684">Chen Wang</a>,
<a href="author_page.cfm?id=99659259749">Kai Lu</a>,
<a href="author_page.cfm?id=81548033072">Yinjin Fu</a>,
<a href="author_page.cfm?id=81100413984">Liming Zhu</a>
</div>
<div class="source">
<span class="publicationDate">May 2018</span>
<span style="padding-left:10px">CCGrid '18: Proceedings of the 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;IEEE Press
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 0</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;3</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;5</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;5</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3307523&ftid=2034886&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Data backup is regularly required by both enterprise and individual users to protect their data from unexpected loss. There are also various commercial data deduplication systems or software that help users to eliminate duplicates in their backup data to save storage space. In data deduplication systems, the data chunking process ...
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high3307523');">result highlights</a>]</div>
<div class="highlights" id="high3307523" style="display:none">
<strong>Full Text</strong>:<br />
<em>chunk</em> size, itdoes not ensure a higher physical deduplication ratio when ... are conducted on a serverwith Intel Xeon E5 CPU, 64GB <em>memory</em> and 2TB 7200RPMHDD. Traces are downloaded to the ?le server ... thevariance. The results are described as follows.1) Estimate the optimal <em>chunk</em> size for different users:We conduct experiments to show whether SmartChunker ... conduct experiments to show whether SmartChunker canaccurately estimate the optimal <em>chunk</em> size for the data ofeach user. We choose 9 active ... used.In order to evaluate how the estimated capacity savingunder different <em>chunk</em> sizes matches the situation of the wholedata, we compare the ... fact that we focuson the relative capacity savings for different <em>chunk</em> sizes ratherthan the speci?c values. Figure 4 shows the estimated ... toaccurately approximate the trend of the real deduplication ratiounder different <em>chunk</em> sizes. For different users, the capacitysavings under different <em>chunk</em> sizes vary signi?cantly. Someusers are not sensitive to the change ... vary signi?cantly. Someusers are not sensitive to the change of <em>chunk</em> sizes. Forexample, the amount of capacity saving variation is less ... User 3 and User 8. For User 12, when the <em>chunk</em> sizeincreases from 2KB to 128KB, the capacity saving drops morethan ... 2KB to 128KB, the capacity saving drops morethan 40%. Large <em>chunk</em> sizes improve the deduplication ratiosfor User 17 and User 18. ... user 18 under thechunk size of 128KB than under the <em>chunk</em> size of 2KB. Basedon the estimation given by SmartChunker, a ... the estimation given by SmartChunker, a user can choosea proper <em>chunk</em> size that ?ts their performance requirements.For example, if the performance ... for data restoreis high for user 8, choosing a large <em>chunk</em> size and sacri?ce2% of capacity saving is appropriate. As shown ... capacity saving is appropriate. As shown in the dataset,the optimal <em>chunk</em> sizes for different users vary from 2KBto 128KB. It demonstrates ... of user data accesspatterns so that estimating the impact of <em>chunk</em> size choices isimportant before applying deduplication.We also compare the deduplication ... ofSmartChunker and ALG-Dedup [17] (see Figure 5). ALG-Dedup sets the <em>chunk</em> size based on ?le types. There are?les without explicit ?le ... their storage usage. Forthese cases, ALG-Dedup and SmartChunker produce nearlyidentical <em>chunk</em> sizes. However, for user U12, U17, and U18,a large number ... not have ?le type information. ALG-Dedup fails to produce optimal <em>chunk</em> sizes to data of theseusers. Moreover, there are also some ... uncommon ?le types suchas svn-base ALG-Dedup fails to infer proper <em>chunk</em> sizes. Notethat the y-axis is log scaled so that the ... SmartChunker are signi?cant for some users.Essentially, the idea of application-aware <em>chunk</em> size settingis to differentiate the duplicate patterns of different ?lesbelonging ... It also givesusers better understanding of the performance implication ofdifferent <em>chunk</em> size choices so that a balance between storagespace saving and ... scan method: One objective ofusing estimation to infer the optimal <em>chunk</em> size is to reducethe cost of scanning the whole data ... of scanning the whole data on disks to obtain theoptimal <em>chunk</em> size value (called full scan method). We havealready shown that ... time.The FSL dataset is provided as the ?ngerprints of thedata <em>chunks</em> <br /> ... F. Huang, and Y. Zhou,“Ae: An asymmetric extremum content de?ned <em>chunking</em> algorithm forfast and bandwidth-ef?cient data deduplication,” in Computer Commu-nications (INFOCOM), ... Q. Liu, and Y. Zhang,“Fastcdc: a fast and ef?cient content-de?ned <em>chunking</em> approach for datadeduplication.” in USENIX Annual Technical Conference, 2016, pp. ... and J. Li, “Chunkstash: Speeding up inlinestorage deduplication using ?ash <em>memory</em>. .” in USENIX Annual TechnicalConference, 2010, pp. 1–16.[13] Y. Fu, ... G. Lu, N. Park, W. Xiao, and D. H. Du, “<em>Chunk</em> fragmenta-tion level: An effective indicator for read performance degradation indeduplication ... Fast, 2010, pp. 239–252.[27] B. Zhou and J. Wen, “Hysteresis re-<em>chunking</em> based metadata harnessingdeduplication of disk images,” in Parallel Processing (ICPP), ... <br /> One Size Does Not Fit All: The Case for <em>Chunking</em> Configuration in Backup DeduplicationOne Size Does Not Fit All: The ... data deduplication systems, the datachunking process splits data into small <em>chunks</em>. ... . Duplicate data isidenti?ed by comparing the ?ngerprints of the <em>chunks</em>. . The chunksize setting has signi?cant impact on deduplication performance.A ... chunksize setting has signi?cant impact on deduplication performance.A variety of <em>chunking</em> algorithms have been proposed in recentstudies. In practice, existing systems ... systems often set the chunkingcon?guration in an empirical manner. A <em>chunk</em> size of 4KBor 8KB is regarded as the sweet spot ... capacity planning.Moreover, it is dif?cult to make changes to the <em>chunking</em> settingsonce they are put into use as duplicates in data ... cannot be eliminated directly. In this paper,we propose a sampling-based <em>chunking</em> method and develop atool named SmartChunker to estimate the optimal ... In the process of data deduplication, one critical step isdata <em>chunking</em>. . Speci?cally, data are split into <em>chunks</em> and thehash values of these <em>chunks</em> are used as ?ngerprints. Duplicatechunks are detected if their ?ngerprints ... ?ngerprints. Duplicatechunks are detected if their ?ngerprints match with existingones.Existing <em>chunking</em> algorithms can be classi?ed into ?xed-sized <em>chunking</em> methods (FSC) and content-de?ned <em>chunking</em>( (CDC) algorithms. Fixed-sized <em>chunking</em> splits the data intochunks with the same size. Its limitation ... problem [5]. The boundary-shift problem can be addressed by content-de?ned <em>chunking</em>( (CDC) algorithms. CDC algorithms generate variable-sizeddata <em>chunks</em> by cutting the data based on the local content.Besides the ... classical rabin ?ngerprint algorithm [6], thereare many alternatives for CDC <em>chunking</em> [7], [8], [9]. Fordifferent workloads, different <em>chunking</em> algorithms or differentdata <em>chunking</em> ... settings may result in drastically differentdeduplication ef?ciency.In a typical content-de?ned <em>chunking</em> ... algorithm, one oftenneeds to set the max, min and average <em>chunk</em> size to avoid thehigh variation in <em>chunk</em> ... sizes [10]. According to existing studyon backup workloads [11], smaller <em>chunk</em> sizes (e.g.,4KBand 8KB) tend to produce higher deduplication ratio and ... (e.g.,4KBand 8KB) tend to produce higher deduplication ratio and anaverage <em>chunk</em> size of 8KB seems to be a sweet spot inmost ... [14]. Unfortunately, dueto the overhead incurred for storing deduplication metadata,smaller <em>chunk</em> sizes may not achieve good deduplication ratiosas one may think ... and I/O performance(i.e., fragmentation [16]) by setting to a larger <em>chunk</em> size. It isdif?cult to change the <em>chunk</em> size once set because the data arealready <em>chunked</em> based on the previous setting and changingthe <em>chunk</em> size requires re-<em>chunking</em> data using the new chunksize. The process is costly. Therefore, ... the new chunksize. The process is costly. Therefore, setting the <em>chunk</em> sizeproperly is important in a deduplication system.Some previous research proposes ... in a deduplication system.Some previous research proposes to set different <em>chunk</em> ... sizesfor data of different ?le types [17]. Although the empiricaloptimal <em>chunk</em> size values for the data of different applications(thus different types) ... <br /> approximations for theoptimal <em>chunk</em> sizes, this method faces the following obstaclesin practice. First, the ... real-world dataset (see Section II). A brute-force approach mayapply different <em>chunk</em> sizes on the data in a storage systemand calculate their ... amethod and develop a tool named SmartChunker to assistwith the <em>chunking</em> con?guration selection for deduplicationsystems. Without scanning the whole data, SmartChunkersamples ... whole data, SmartChunkersamples data on the disk and uses different <em>chunk</em> size settingsto estimate the potential capacity savings under different chunksizes. ... settingsto estimate the potential capacity savings under different chunksizes. The <em>chunk</em> size corresponding to the most capacitysavings is used in the ... thededuplication ratio of samples does not re?ect the distributionof duplicate <em>chunks</em> and it mostly underestimates the dedu-plication ratio. Statistically, for two ... have been investigated by existing work[18], [19], [20]. In the <em>chunk</em> size setting problem, the trade-off between the estimated deduplication ratio ... table, and auxiliary data structures.There are two main challenges for <em>chunk</em> size estimation.First, it requires a high estimation accuracy. Deciding thechunk ... ratio for evaluating the cost-effectiveness [19].Quantifying the impact of different <em>chunk</em> sizes is a challeng-ing problem. Second, it requires the estimator ... it requires the estimator to be able todeal with variable <em>chunk</em> sizes. The content-de?ned chunkingalgorithms generate <em>chunks</em> with different sizes and variablesizes add to the complexity of ... ?ngerprints to performthe estimation [19], [20]. This is infeasible for <em>chunking</em> sizeestimation as it would be time-consuming to compute the hashvalues ... to compute the hashvalues for all the data with different <em>chunk</em> size choices. Onthe other hand, the estimation error is not ... using the unseen method to estimate thecapacity savings of different <em>chunk</em> sizes is not as direct asone may think. In this ... Speci?cally, rather than directly sampling the datablocks according to the <em>chunk</em> sizes, we propose a ?le-packagebased sampling method. This is mainly ... longer time. Moreover,we perform the unseen method for each popular <em>chunk</em> sizefor accurate estimation. Meanwhile, we group the <em>chunks</em> fromunpopular <em>chunk</em> sizes to avoid the estimation error causedby insuf?cient samples. We ... We found out that we are able to choose thebest <em>chunking</em> con?guration among various choices by theestimation. SmartChunker uses signi?cantly shorter ... <br /> parameters for data <em>chunking</em> is criticalfor achieving high deduplication ratios with low overhead. Inexisting ... high deduplication ratios with low overhead. Inexisting deduplication systems, the <em>chunking</em> con?gurationsare often chosen empirically, which may result in uncertaintyin the ... overhead of deduplication metadata like ?ngerprinttable and recipe tables, small <em>chunk</em> sizes are always better asduplicates can be identi?ed in a ... ?ner granularity. However,the number of metadata entries increases as the <em>chunk</em> sizedecreases. When the storage overhead of the metadata is takeninto ... overhead of the metadata is takeninto account, choosing the optimal <em>chunk</em> size is, essentially,to ?nd the best balance point between the ... best balance point between the storage space of theeliminated duplicate <em>chunks</em> and the overhead introduced bystoring the deduplication metadata.For example, if ... the overhead introduced bystoring the deduplication metadata.For example, if the <em>chunk</em> size for a deduplication system isset to 8KB,a common con?guration ... redundanciesexist as large duplicate ?les. In this case, a larger <em>chunk</em> size isbetter since the system is still able to identify ... butthe overhead for storing the deduplication metadata shrinks.Moreover, a larger <em>chunk</em> size also leads to a faster data restoreprocess.Some previous study ... leads to a faster data restoreprocess.Some previous study proposes application-aware <em>chunk</em> set-tings [17] for ?les from different applications. Their rationaleis that ... types, it is common tosee new types unknown by the <em>chunking</em> method. In addition,214some ?le types may not be informative for ... In addition,214some ?le types may not be informative for the <em>chunk</em> sizesetting. Simple examples are “tar”/“iso” ?les that contain avariety of ... of ?les with different ?le types. In this case, theapplication-aware <em>chunk</em> size setting methods [17] do not workwell.NONE o pack out ... to accurately and ef?ciently predict thestorage space saving under different <em>chunking</em> con?gurations?III. DESIGN AND IMPLEMENTATION OF SMARTCHUNKERIn this section, we describe ... data is already stored on disks.A. Unseen Estimation for CDC <em>Chunking</em> MethodsSmartChunker extends the unseen estimation algorithm toaccurately estimate the storage ... to extend the algorithm to estimate storage spacesaving under different <em>chunk</em> size settings. Before describingthe algorithm, we de?ne two concepts as ... thenumber of ?ngerprints that appear exactly i times in thedataset.• <em>Chunk</em> ?ngerprint samples are a portion of ?ngerprintsfor data <em>chunks</em> uniformly sampled from a large dataset.The target of the unseen ... estimation algorithm is to usethe observed FFH of the sampled <em>chunks</em> to compute thenumber of unique <em>chunks</em> in the whole dataset. According tothe entropy estimation theory [22], ... Basic Unseen Estimation AlgorithmInput: Hos : The obeseved FFH for <em>chunk</em> ?ngerprintsamples s, H: FFH for the ?ngerprints of thewhole dataset. ... :total chunknumbers of the whole dataset.Output: Estimated number of unique <em>chunks</em>. .1 Subroutine Unseen Estimation Algorithm()2 Compute the transformation matrix T ... H , we can then obtain the number ofunique data <em>chunks</em> <br /> ... two main reasons. First, the original unseen algorithmconsiders that each <em>chunk</em> ... has the same size. Although it can beused for ?xed-sized <em>chunking</em> where all <em>chunks</em> have the samesize, SmartChunker focuses more on content-de?ned chunkingwhich is ... does not consider multiple roundsof sampling, each with a different <em>chunk</em> size setting.To enable variable-sized <em>chunk</em> ... support for the unseenestimation algorithm, SmartChunker performs the estimationfor the <em>chunk</em> sizes separately. The computational overhead isacceptable because the execution time ... fully paralleled in the implementation.However, the individual estimations on different <em>chunk</em> sizesdo not work well. The key reason is that not ... not work well. The key reason is that not all <em>chunk</em> sizes areequal in the estimation. We observed that the <em>chunk</em> size distri-bution for the data <em>chunks</em> after content-de?ned <em>chunking</em> areoften highly skewed. Figure 2 shows the distribution of chunkswith ... highly skewed. Figure 2 shows the distribution of chunkswith different <em>chunk</em> sizes before and after the deduplication,respectively. The gap between the ... the two lines in each ?gureindicates the duplicates of certain-sized <em>chunks</em>. ... . An interestingphenomenon is that for a certain range of <em>chunk</em> sizes, themore <em>chunks</em> exist before deduplication, the more duplicateswould be identi?ed during the ... 40 60 80 100 120Chunk Size (KB)050100150200250ChunkNumbers(K)user028user028-Dedupped(c) User028Fig. 2: The <em>chunk</em> size distribution for the traces of three users in FSL ... the average chunksizes are 8KB, 16KB and 64KB, respectively.redundant data <em>chunks</em> are often highly referenced.This skewness makes it improper to perform ... improper to perform the unseenestimation directly to estimate the unique <em>chunks</em> for eachchunk size. Furthermore, the major part of the capacity ... part of the capacity savingcan be estimated from the popular <em>chunk</em> sizes since capacitysaving mainly come from popular <em>chunk</em> sizes. On the otherhand, the estimation may work poorly on ... reason is that few samples can be drawn from theunpopular <em>chunks</em> so that the unseen estimation algorithm be-comes error-prone due to ... an accurate estimation requiresO( nlogn ) samples. For some unpopular <em>chunk</em> sizes, since theymay only have several <em>chunks</em>, , we may not even be able toget any samples ... chunksize to compute the capacity saving. For the unpopular portionof <em>chunk</em> sizes, we group the <em>chunks</em> of a range of <em>chunk</em> sizestogether to conduct the estimation. The potential inaccuracythat might be ... we get from unseen estimation is just the number ofduplicate <em>chunks</em>. . To estimate the capacity savings, we usethe mean of ... To estimate the capacity savings, we usethe mean of the <em>chunk</em> size in the unpopular <em>chunk</em> size groupCGu =?ki=1 pi Ci as the expected <em>chunk</em> size where k isthe number of different <em>chunk</em> sizes in a group. This inevitablyintroduces error in the unseen ... can beproved that the error is trivial as follows.The unpopular <em>chunk</em> sizes are mostly continuous due tothe skewness of the <em>chunk</em> size distribution. For an unpopularchunk group p, suppose the number ... For an unpopularchunk group p, suppose the number of duplicate <em>chunks</em> inthe group is D, the total number of <em>chunks</em> in a group is Nand the <em>chunk</em> sizes in the group are Ci(i = 1, 2, ..., ... Ci(i = 1, 2, ..., k). Nidenotes the number of <em>chunks</em> with size Ci. The estimatedcapacity saving S is therefore as ... worst case, the capacity saving may all come fromthe smallest <em>chunks</em>. . In the best case, the capacity saving allcomes from ... the best case, the capacity saving allcomes from the largest <em>chunks</em>. . As a result, the range of realcapacity saving is ... (3)Therefore, for a group, the largest error introduced by thegroup <em>chunk</em> size approximation is as below:E = max(|S ? Slow|, |S ... <br /> is symmetric.As each group has a sequence of contiguous <em>chunk</em> sizesand each sequence has a size of k, for all ... (k ? 1)Ng?p=1Dp(6)where Ng is the total number of unpopular <em>chunk</em> sizegroups and Dg is the number of duplicate <em>chunks</em> for the groupg.216Algorithm 2: Capacity Saving EstimationInput: Cmin: min <em>chunk</em> size, Cmax: max <em>chunk</em> size,s = sC1 , sC2 , ..., sCM are samples ... sC1 , sC2 , ..., sCM are samples drawn fromeach <em>chunk</em> size. n = nC1 , nC2 , ..., nCM are ... = nC1 , nC2 , ..., nCM are thenumbers of <em>chunks</em> in for samples with differentchunk sizes. t is the frequency ... = 0 //the capacity saving without consideringmetadata3 Gp is the <em>chunk</em> size group for popular <em>chunk</em> sizes4 Gu is the <em>chunk</em> size group for unpopular <em>chunk</em> sizes5 foreach nCi in n do6 if nCi &gt; t ... nCi &gt; t then7 Gp.add(Ci)8 else9 // group every k <em>chunk</em> sizes to be anunpopular group. Guc is the currentunpopular group.10 ... range k and the total number of duplicates in theunpopular <em>chunk</em> size groups. The parameter N depends onthe number of samples ... unseen estimation can work wellwhile k depends on how unpopular <em>chunk</em> sizes are de?ned.More intuitively, in our evaluation on FSL Home ... = 50/0.154 ? 83 is a reasonable value as eachunpopular <em>chunk</em> size is observed to have 4 <em>chunks</em> in average.Note that the threshold parameter t in Algorithm 2 ... Algorithm 2 is also setaccording to k. As the duplicate <em>chunk</em> numbers in unpopularchunk groups are very small (i.e., less than ... are very small (i.e., less than 10% of the totalduplicate <em>chunks</em> for the traces we evaluated). Therefore, theerror rate will be ... rate will be less than 83 0.1Ce 0.9+83 0.1 where we use theexpected <em>chunk</em> size Ce to approximate the capacity savingsfrom the popular <em>chunks</em>. . Obviously, the error rate will becomelarger for smaller <em>chunk</em> size settings. Even though, the extraerror introduced beyond the error ... of unseen estimation will beless than 0.45% for the expected <em>chunk</em> size of 2KB.B. The Sampling MethodThe accurate estimation of unseen ... However, direct sampling ondisk volumes is not suitable for content-de?ned <em>chunking</em>. . Thereason is that the sampled segment may cross ?le ... that the sampled segment may cross ?le boundarieswhile in practice <em>chunks</em> are cut from individual ?les. Toaddress this problem, we force ... not consider the metadata over-head. The main reason that smaller <em>chunk</em> sizes may performworse is the overhead introduced to store the ... often show strong locality andtend to appear as long sequences, <em>chunking</em> the ?les into smallchunks (e.g., the average <em>chunk</em> size is 4KB) does not improvethe deduplication ratio but increases ... relative size of the metadata for eachchunk compared to the <em>chunk</em> size. The deduplication ratiotaken into account of the metadata overhead ... overheadof metadata. Their relationships give very interesting hints forsetting the <em>chunk</em> size. Although a smaller <em>chunk</em> <br /> so that we cannotevaluate the time of sampling, <em>chunking</em>, , and hash compu-tations directly. Instead, we evaluate the execution ... use Rabin ?ngerprint as the chunkingalgorithm. Note, there are other <em>chunking</em> algorithms (e.g., [7])that are faster.The procedures of the baseline method ... to read all the data from the disk.Then ?les are <em>chunked</em> to different sizes and the ?ngerprints2182 4 8 16 32 ... sizes and the ?ngerprints2182 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)7580859095100NormalizedCapacitySaving(%)Corrected EstimationRaw EstimationReal (Evaluation Set)(a) User0032 4 8 16 ... EstimationReal (Evaluation Set)(a) User0032 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)9092949698100NormalizedCapacitySaving(%)Corrected EstimationRaw EstimationReal (Evaluation Set)(b) User0052 4 8 16 ... EstimationReal (Evaluation Set)(b) User0052 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)949596979899100NormalizedCapacitySaving(%)Corrected EstimationRaw EstimationReal (Evaluation Set)(c) User0082 4 8 16 ... EstimationReal (Evaluation Set)(c) User0082 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)60708090100NormalizedCapacitySaving(%)Corrected EstimationRaw EstimationReal (Evaluation Set)(d) User0122 4 8 16 ... EstimationReal (Evaluation Set)(d) User0122 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)7580859095100NormalizedCapacitySaving(%)Corrected EstimationRaw EstimationReal (Evaluation Set)(e) User0142 4 8 16 ... EstimationReal (Evaluation Set)(e) User0142 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)7580859095100NormalizedCapacitySaving(%)Corrected EstimationRaw EstimationReal (Evaluation Set)(f) User0152 4 8 16 ... EstimationReal (Evaluation Set)(f) User0152 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)707580859095100NormalizedCapacitySaving(%)Corrected EstimationRaw EstimationReal (Evaluation Set)(g) User0172 4 8 16 ... EstimationReal (Evaluation Set)(g) User0172 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)2030405060708090100NormalizedCapacitySaving(%)Corrected EstimationRaw EstimationReal (Evaluation Set)(h) User0182 4 8 16 ... EstimationReal (Evaluation Set)(h) User0182 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)80859095100NormalizedCapacitySaving(%)Corrected EstimationRaw EstimationReal (Evaluation Set)(i) User028Fig. 4: The storage ... lines demonstrate the ground truth.need to be computed for each <em>chunk</em>. . For each <em>chunk</em> ... sizesetting, the deduplication ratio is computed by the number ofduplicate <em>chunks</em> and the sizes of these chunks.Table I shows the comparison ... disk scan. Sampling alsoavoids a large amount of computing on <em>chunking</em> and hashing.The estimation time is longer as one may expect. ... as one may expect. The mainreason is that for each <em>chunk</em> size setting (i.e., a tuple of (max,min, avg)), SmartChunker computes ... the execution time,we use destor to perform deduplication under the <em>chunk</em> sizeof 8KB on the data and the total deduplication time ... method uses around twice thededuplication time to get the optimal <em>chunk</em> size while theoverhead introduced by SmartChunker is only around 20% ... method and SmartChunker. The sampling rate is set to 10%.Sampling <em>Chunking</em> Hash Computing Estimation TotalBaseline 946s 4091s 4379s 9416sSmartChunker 167s 397s ... U14 U15 U17 U18 U28Users0.00.51.01.52.02.5DeduplicationRatio(log10)ALG-DedupSmartChunkerFig. 5: The deduplication under the <em>chunk</em> size given by ALG-Dedup and SmartChunker for users.3) Sensitivity to ... our focus is the relative comparisons ofcapacity savings between different <em>chunk</em> sizes. Hence, whatwe are interested in is how does the ... does the sampling rate affectthe correct selection of the optimal <em>chunk</em> size. We presentthe result of three representative users to demonstrate ... <br /> ... SmartChunker can still relatively capture thetrend of the differences between <em>chunk</em> sizes very accurately(especially for User18). Nevertheless, it is noteworthy that ... Nevertheless, it is noteworthy that ifthe capacity savings corresponding two <em>chunk</em> sizes are quiteclose (e.g., 4KB, 8KB for User005), it is ... to the estimation error.V. RELATED WORKCDC algorithms normally have large <em>chunk</em> size variance.That means there exist many <em>chunks</em> with very large or smallchunk sizes. Some recent studies address ... sizes. Some recent studies address this by imposingminimum and maximum <em>chunk</em> size restrictions. Moreover,Rabin ?ngerprint algorithm also has a high computationaloverhead ... Some other works [26], [27]further improve the deduplication ratio by re-<em>chunking</em> non-duplicate <em>chunks</em> or reduce the metadata overhead by mergingconsecutive duplicate <em>chunks</em> [28].As a critical parameter for deduplicated storage systems,different <em>chunk</em> size settings have been recommended by prac-titioners. For example, Symantec ... 16KB or largerchunk sizes [29]. Commuvault suggests to use large <em>chunk</em> sizelike 128KB [30]. Some deduplication systems for dedicatedpurposes (e.g., virtual ... dedicatedpurposes (e.g., virtual machine images) even use 4096KB asthe default <em>chunk</em> ... size [31]. However, it is obvious that thereis no one <em>chunk</em> size con?guration which ?ts all scenarios.Hence, SmartChunker aims to provide ... ef?ciency and metadata overhead has also beenexplored by the hybrid ?le/<em>chunk</em> level deduplication in clouddeduplication [32] or using coarse/?ne-grained deduplicationfor inline/of?ine ... primary dedupli-cation scenario [34].VI. CONCLUSION AND FUTURE WORKWe proposed a <em>chunk</em> size estimation method and imple-mented a tool called SmartChunker in ... a tool called SmartChunker in this paper to obtainthe optimal <em>chunk</em> size con?guration for backup deduplicationsystems. SmartChunker only needed to use ... number ofsamples to learn the potential storage capacity saving underdifferent <em>chunk</em> con?gurations. Our experiments on real-worlddatasets demonstrated that SmartChunker clearly outperformsexisting ... real-worlddatasets demonstrated that SmartChunker clearly outperformsexisting methods that set the <em>chunk</em> ... size empirically or give2202 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)9596979899100NormalizedCapacitySaving(%)p = 0.05p = 0.1p = 0.15real(a) User0052 4 ... 0.1p = 0.15real(a) User0052 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)5060708090100NormalizedCapacitySaving(%)p = 0.05p = 0.1p = 0.15real(b) User0122 4 ... 0.1p = 0.15real(b) User0122 4 8 16 32 64 128Avg. <em>Chunk</em> Size (KB)2030405060708090100NormalizedCapacitySaving(%)p = 0.05p = 0.1p = 0.15real(c) User018Fig. 6: ... 6: Normalized capacity savings for users under different sampling rate.application-speci?c <em>chunk</em> con?gurations. We envision thatlearning based methods can be utilized to ... <br /> ... Storage(TOS), vol. 2, no. 4, pp. 424–448, 2006.[29] “About deduplication <em>chunk</em> size,” http://sort.symantec.com/public/documents/vif/7.0/aix/productguides/html/sf admin/ch29s01s01.htm,accessed: 2017-09-30.[30] “Deduplication building block guide,” http://documentation.commvault.com/commvault/v10/article?p=features/deduplication/deduplicationbuilding block.htm, ... <br />
<br />
<strong>Abstract</strong>:<br />
... to save storage space. In data deduplication systems, the data <em>chunking</em> process splits data into small <em>chunks</em>. . Duplicate data is identified by comparing the fingerprints of ... Duplicate data is identified by comparing the fingerprints of the <em>chunks</em>. . The <em>chunk</em> size setting has significant impact on deduplication performance. A variety ... setting has significant impact on deduplication performance. A variety of <em>chunking</em> algorithms have been proposed in recent studies. In practice, existing ... in recent studies. In practice, existing systems often set the <em>chunking</em> configuration in an empirical manner. A <em>chunk</em> size of 4KB or 8KB is regarded as the sweet ... vary and change along time, as a result, the empirical <em>chunk</em> size setting may not lead to a good deduplication ratio ... planning. Moreover, it is difficult to make changes to the <em>chunking</em> settings once they are put into use as duplicates in ... are put into use as duplicates in data with different <em>chunk</em> size settings cannot be eliminated directly. In this paper, we ... be eliminated directly. In this paper, we propose a sampling-based <em>chunking</em> method and develop a tool named SmartChunker to estimate the ... and develop a tool named SmartChunker to estimate the optimal <em>chunking</em> configuration for deduplication systems. Our evaluations on real-world datasets demonstrate ... <br />
<br />
<strong>References</strong>:<br />
Y. Zhang, H. Jiang, D. Feng, W. Xia, M. Fu, F. Huang, and Y. Zhou, "Ae: An asymmetric extremum content defined <em>chunking</em> algorithm for fast and bandwidth-efficient data deduplication," in <i>Computer Communications (INFOCOM), 2015 IEEE Conference on.</i> IEEE, 2015, pp. 1337--1345. <br /> W. Xia, Y. Zhou, H. Jiang, D. Feng, Y. Hua, Y. Hu, Q. Liu, and Y. Zhang, "Fastcdc: a fast and efficient content-defined <em>chunking</em> approach for data deduplication." in <i>USENIX Annual Technical Conference</i>, 2016, pp. 101--114. <br /> B. K. Debnath, S. Sengupta, and J. Li, "Chunkstash: Speeding up inline storage deduplication using flash <em>memory</em>." in <i>USENIX Annual Technical Conference</i>, 2010, pp. 1--16. <br /> Y. Nam, G. Lu, N. Park, W. Xiao, and D. H. Du, "<em>Chunk</em> fragmentation level: An effective indicator for read performance degradation in deduplication storage," in <i>High Performance Computing and Communications (HPCC), 2011 IEEE 13th International Conference on.</i> IEEE, 2011, pp. 581--586. <br /> E. Kruus, C. Ungureanu, and C. Dubnicki, "Bimodal content defined <em>chunking</em> for backup streams." in <i>Fast</i>, 2010, pp. 239--252. <br /> B. Zhou and J. Wen, "Hysteresis re-<em>chunking</em> based metadata harnessing deduplication of disk images," in <i>Parallel Processing (ICPP), 2013 42nd International Conference on.</i> IEEE, 2013, pp. 389--398. <br /> "About deduplication <em>chunk</em> size," http://sort.symantec.com/public/documents/vif/7.0/aix/productguides/html/sf_admin/ch29s01s01.htm, accessed: 2017-09-30. <br />
<br />
<strong>Title</strong>:<br />
One size does not fit all: the case for <em>chunking</em> configuration in backup deduplication <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
6
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=2391012" target="_self">Exploiting chunk-level features to improve phrase chunking</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81549407056">Junsheng Zhou</a>,
<a href="author_page.cfm?id=81453620066">Weiguang Qu</a>,
<a href="author_page.cfm?id=81548919656">Fen Zhang</a>
</div>
<div class="source">
<span class="publicationDate">July 2012</span>
<span style="padding-left:10px">EMNLP-CoNLL '12: Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;Association for Computational Linguistics
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 2</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;1</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;5</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;61</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=2391012&ftid=1304900&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Most existing systems solved the phrase chunking task with the sequence labeling approaches, in which the chunk candidates cannot be treated as a whole during parsing process so that the chunk-level features cannot be exploited in a natural way. In this paper, we formulate phrase chunking as a joint segmentation ...
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high2391012');">result highlights</a>]</div>
<div class="highlights" id="high2391012" style="display:none">
<strong>Full Text</strong>:<br />
(or POS) located in two adjacent <em>chunks</em> can also capture some correlations between adjacent <em>chunks</em>, , and templates 17-22 are designed to express this kind ... 6.1 Data Sets and Evaluation Following previous studies on Chinese <em>chunking</em> in (Chen et al., 2006), our experiments were performed on ... for this task are precision p (the fraction of output <em>chunks</em> matching the reference <em>chunks</em>) ), recall r (the fraction of reference <em>chunks</em> returned), and the F-measure given by F = 2pr/(p + ... we were interested in finding an effective feature representation at <em>chunk</em>- -level for phrase <em>chunking</em>, , we fixed N = 10 and k = 5 ... the sequence labeling approach based on CRFs. 6.2 Chinese NP <em>chunking</em> NP is the most important phrase in Chinese <em>chunking</em> and about 47% phrases in the CTB4 Corpus are NPs. ... 92.03 90.98 91.50 Table 2: Experimental results on Chinese NP <em>chunking</em>. . 6.3 Chinese Text <em>Chunking</em> There are 12 different types of phrases in the <em>chunking</em> corpus. Table 3 shows the results from 563 two different ... 92.30 91.20 91.75 Table 3: Experimental results on Chinese text <em>chunking</em>. . 6.4 Comparison with Other Models Chen et al. (2006) ... the performance of the state-of-the-art machine learning models for Chinese <em>chunking</em>, , and found that the SVMs approach yields higher accuracy ... accuracy than respective CRFs, Transformation-based Learning (TBL) (Megyesi, 2002), and <em>Memory</em>- -based Learning (MBL) (Sang, 2002) approaches. In this section, we ... model and other state-of-the-art machine learning models for Chinese NP <em>chunking</em> and text <em>chunking</em> tasks. Performance of our model and some of the best ... in Table 4, we can see that for both NP <em>chunking</em> and text <em>chunking</em> <br /> of-the-art for the text <em>chunking</em> task. Moreover, the performance should be further improved if some ... be further improved if some additional features tailored for English <em>chunking</em> are employed in our model. For example, we can introduce ... in (Wu et al., 2006). Method Precision Recall F1 NP <em>chunking</em> Ours 94.79 94.65 94.72LDCRF 94.65 94.03 94.34Text <em>chunking</em> Ours 94.31 94.12 94.22SVMs 94.12 94.13 94.12Table 6: Performance on ... this paper we have presented a novel approach to phrase <em>chunking</em> by formulating it as a joint segmentation and labeling problem. ... approach is that it provides a natural formulation to exploit <em>chunk</em>- -level features. The experimental results on both Chinese <em>chunking</em> and English <em>chunking</em> tasks show that the use of <em>chunk</em>- -level features can lead to significant performance improvement and that ... applying external information, such as semantic knowledge, to represent the <em>chunk</em>- -level features, and then incorporate them into our model to ... three anonymous reviewers. References Steven P. Abney. 1991. Parsing by <em>chunks</em>. . In Robert C. Berwick, Steven P. Abney, and Carol ... Zhang, and Hitoshi Isahara. 2006. An empirical study of Chinese <em>chunking</em>. . In Proceedings of the COLING/ACL 2006 Main Conference Poster ... of Jerusalem, PhD Thesis. Taku Kudo and Yuji Matsumoto. 2001. <em>Chunking</em> with support vector machines. In Proceedings of NAACL01. Koby Crammer, ... Kit, and Tianshun Yao. 2003. Transductive hmm based chinese text <em>chunking</em>. . In Proceedings of IEEE NLPKE2003, pages 257-262, Beijing, China. ... and S. Buchholz. 2000. Introduction to the CoNLL-2000 shared task: <em>Chunking</em>. . In Proceedings CoNLL-00, pages 127-132. Sunita Sarawagi and W. ... Tan, Tianshun Yao, Qing Chen, and Jingbo Zhu. 2004. Chinese <em>chunk</em> identification using svms plus sigmoid. In IJCNLP, pages 527-536. Yongmei ... of CICLing-2005, pages 167-176. Erik F. Tjong Kim Sang. 2002. <em>Memory</em>- -based shallow parsing. JMLR, 2(3):559-594. Yu-Chieh Wu, Chia-Hui Chang, and ... Chang, and Yue-Shi Lee. 2006. A general and multi-lingual phrase <em>chunking</em> <br /> Exploiting <em>Chunk</em>- -level Features to Improve Phrase ChunkingProceedings of the 2012 Joint ... Korea, 12–14 July 2012. c 2012 Association for Computational Linguistics Exploiting <em>Chunk</em>- -level Features to Improve Phrase <em>Chunking</em> Junsheng Zhou Weiguang Qu Fen Zhang Jiangsu Research Center of ... 210046 Email:{zhoujs,wgqu}@njnu.edu.cn <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="265c401f101210661714100845494b">[email&#160;protected]</a> Abstract Most existing systems solved the phrase <em>chunking</em> task with the sequence labeling approaches, in which the <em>chunk</em> candidates cannot be treated as a whole during parsing process ... treated as a whole during parsing process so that the <em>chunk</em>- -level features cannot be exploited in a natural way. In ... in a natural way. In this paper, we formulate phrase <em>chunking</em> as a joint segmentation and labeling task. We propose an ... direct use of the features describing the internal characteristics of <em>chunk</em> and the features capturing the correlations between adjacent <em>chunks</em>. . A relaxed, online maximum margin training algorithm is used ... explored a variety of effective feature representations for Chinese phrase <em>chunking</em>. . The experimental results show that the use of <em>chunk</em>- -level features can lead to significant performance improvement, and that ... better at recognizing long and complicated phrases. 1 Introduction Phrase <em>chunking</em> is a Natural Language Processing task that consists in dividing ... i.e., a word can only be a member of one <em>chunk</em> (Abney, 1991). Generally speaking, there are two phrase <em>chunking</em> tasks, including text <em>chunking</em> (shallow parsing), and noun phrase (NP) <em>chunking</em>. . Phrase <em>chunking</em> provides a key feature that helps on more elaborated NLP ... There is a wide range of research work on phrase <em>chunking</em> based on machine learning approaches. However, most of the previous ... learning approaches. However, most of the previous work reduced phrase <em>chunking</em> to sequence labeling problems either by using the classification models, ... Pereira, 2003). When applying the sequence labeling approaches to phrase <em>chunking</em>, , there exist two major problems. Firstly, these models cannot ... cannot treat globally a sequence of continuous words as a <em>chunk</em> candidate, and thus cannot inspect the internal structure of the ... which is an important aspect of information in modeling phrase <em>chunking</em>. . In particular, it makes impossible the use of local ... use of local indicator function features of the type &quot;the <em>chunk</em> consists of POS tag sequence p1...,pk&quot;. For example, the Chinese ... and describe the formation pattern of POS tags of this <em>chunk</em> with a regular expression-like form &quot;[NN]+[CC][NN]+&quot;, then it is more ... punctuations appearing at the starting and ending positions of a <em>chunk</em>. . For instance, the <em>chunk</em> candidate &quot;? ??(Life) ??(Forbidden Zone)” is considered to be an ... &quot;? ??(Life) ??(Forbidden Zone)” is considered to be an invalid <em>chunk</em>. . But it is easy to check this kind of ... to check this kind of punctuation matching in a single <em>chunk</em> by introducing a <em>chunk</em>- -level feature. Secondly, the sequence labeling models cannot capture the ... the sequence labeling models cannot capture the correlations between adjacent <em>chunks</em>, , which should be informative for the identification of <em>chunk</em> boundaries and types. In particular, we find that some headwords ... a stronger dependency relation with their preceding headwords in preceding <em>chunks</em> than with their immediately preceding words within the same <em>chunk</em>. . For example, in the following sentence: &quot; [??/PN(Bilateral)]_NP [??/NN(economic ... <br /> and &quot;??&quot; located in the three adjacent <em>chunks</em> with some head-finding rules, then the headword dependency expressed by ... headword bigrams or trigrams should be helpful to recognize these <em>chunks</em> in this sentence. In summary, the inherent deficiency in applying ... inherent deficiency in applying the sequence labeling approaches to phrase <em>chunking</em> is that the <em>chunk</em>- -level features one would expect to be very informative cannot ... in a natural way. In this paper, we formulate phrase <em>chunking</em> as a joint segmentation and labeling problem, which offers advantages ... to exploit the features describing the internal structure of a <em>chunk</em> and the features capturing the correlations between the adjacent <em>chunks</em>. . Within this framework, we explored a variety of effective ... explored a variety of effective feature representations for Chinese phrase <em>chunking</em>. . The experimental results on Chinese <em>chunking</em> corpus as well as English <em>chunking</em> corpus show that the use of <em>chunk</em>- -level features can lead to significant performance improvement, and that ... sequence labeling models. 2 Related Work In recent years, many <em>chunking</em> systems based on machine learning approaches have been presented. Some ... overlapping features on observations, some other approaches view the phrase <em>chunking</em> as a sequence of classification problems, including support vector machines ... of multiple classifiers. Recently, CRFs were widely employed for phrase <em>chunking</em>, , and presented comparable or better performance than other state-of-the-art ... hidden substructure of shallow phrases, achieving state-of-the-art performance over the NP-<em>chunking</em> task on the CoNLL data. Some similar approaches based on ... classifiers or sequence labeling models were also used for Chinese <em>chunking</em> (Li et al., 2003; Tan et al., 2004; Tan et ... Chen et al. (2006) conducted an empirical study of Chinese <em>chunking</em> on a corpus, which was extracted from UPENN Chinese Treebank-4 ... the performances of the state-of-the-art machine learning models for Chinese <em>chunking</em>, , and proposed some Tag-Extension and novel voting methods to ... methods to improve performance. In this paper, we model phrase <em>chunking</em> with a joint segmentation and labeling approach, which offer advantages ... the internal structural feature and the correlations between the adjacent <em>chunks</em>. . To some extent, our model is similar to Semi-Markov ... label dependency, and it cannot capture more correlations between adjacent <em>chunks</em>, , as is done in our approach. The limitation of ... leads to its relatively low performance. 3 Problem Formulation 3.1 <em>Chunk</em> Types Unlike English <em>chunking</em>, , there is not a benchmarking corpus for Chinese <em>chunking</em>. . We follow the studies in (Chen et al. 2006) ... that a more direct comparison with state-of-the-art systems for Chinese <em>chunking</em> would be possible. There are 12 types of <em>chunks</em>: : ADJP, ADVP, CLP, DNP, DP, DVP, LCP, LST, NP, ... DVP, LCP, LST, NP, PP, QP and VP in the <em>chunking</em> corpus (Xue et al., 2000). The training and test corpus ... (Chen et al. 2006). 3.2 Sequence Labeling Approaches to Phrase <em>Chunking</em> The standard approach to phrase <em>chunking</em> is to use tagging techniques with a BIO tag set. ... ?/O Here S1 denotes that the sentence is tagged with <em>chunk</em> ... types, and S2 denotes that the sentence is tagged with <em>chunk</em> tags based on the BIO-based model. With the data representation ... the data representation like the S2, the problem of phrase <em>chunking</em> ... can be reduced to a sequence labeling task. 3.3 Phrase <em>Chunking</em> <br /> ... tackle the problems with the sequence labeling approaches to phrase <em>chunking</em>, , we formulate it as a joint problem, which maps ... words and POS tags to an output y with tagged <em>chunk</em> types, like the S1 in Example 1. The joint model ... S1 in Example 1. The joint model considers all possible <em>chunk</em> boundaries and corresponding <em>chunk</em> types in the sentence, and chooses the overall best output. ... whether current segment of continuous words is some type of <em>chunk</em>. . After one <em>chunk</em> ... is found, parser move on and search for next possible <em>chunk</em>. . Given a sentence x, let y denote an output ... a sentence x, let y denote an output tagged with <em>chunk</em> types, and GEN a function that enumerates a set of ... seen as the confidence score of whether yi is a <em>chunk</em>. ... . The parser takes into account confidence score of each <em>chunk</em>, , by using the sum of local scores as its ... advantage of the joint segmentation and labeling approach to phrase <em>chunking</em> is to allow for integrating both the internal structural features ... the internal structural features and the correlations between the adjacent <em>chunks</em> for prediction. The two basic components of our model are ... the decoding algorithm searches for the highest-scored output with recognized <em>chunks</em>. . The search space of combined candidates in the joint ... length of the sentence and T is the number of <em>chunk</em> types. It is natural to use some greedy heuristic search ... in our model. In other words, we assume that the <em>chunk</em> ci and the corresponding label ti are only associated with ... the corresponding label ti are only associated with the preceding <em>chunk</em> ci-1 and the label ti-1. Suppose that the input sentence ... has n words and the constant M is the maximum <em>chunk</em> length in the training corpus. Let V(b,e,t) denote the highest-scored ... V(b,e,t) denote the highest-scored segmentation and labeling with the last <em>chunk</em> starting at word index b, ending at word index e ... index b, ending at word index e and the last <em>chunk</em> type being t. One way to find the highest-scored segmentation ... V(b,n-1,t) for all possible start position b?(n-M)..n-1, and all possible <em>chunk</em> type t, respectively, and then pick the highest-scored one from ... from these candidates. In order to compute V(b,n-1,t), the last <em>chunk</em> needs to be combined with all possible different segmentations of ... possible different segmentations of words (b-M)..b-1 and all possible different <em>chunk</em> types so that the highest-scored can be selected. According to ... highest-scored among the segmentations of words (b-M)..b-1 and all possible <em>chunk</em> types with the last <em>chunk</em> being word b ..b-1 and the last <em>chunk</em> type being t will also give the highest score ... base case the subproblems V(0,e,t) for e?0..M-1, and each possible <em>chunk</em> type t, are solved in straightforward manner. And the final ... the input sentence sent, and T is the number of <em>chunk</em> types. chart[b,e,t] records the value of subproblem V(b,e,t). chart[0, e, ... can be computed directly for e = 0..M-1 and for <em>chunk</em> type t=1..T. The final output is the best among chart[b,n-1,t], ... <br /> ... POS tagged) Variables: word index b for the start of <em>chunk</em>; ; word index e for the end of <em>chunk</em>; ... ; word index p for the start of the previous <em>chunk</em>. . <em>chunk</em> type index t for the current <em>chunk</em>; ; <em>chunk</em> type index t for the previous <em>chunk</em>; ; Initialization: for e = 0.. M-1: for t =1..T: ... for e = 0.. M-1: for t =1..T: chart[0,e,t] ?single <em>chunk</em> sent[0,e] and type t Algorithm: for e = 0..n-1: for ... derived by combining chart[p,b-1, t ] with sent[b,e] and <em>chunk</em> type t, for p = (b-M)..b-1, t =1..T. Outputs: ... b=n-M..n-1, t =1..T. Figure 1: A dynamic-programming algorithm for phrase <em>chunking</em>. . 4.2 Pruning The time complexity of the above algorithm ... the above algorithm is O(M2T2n), where M is the maximum <em>chunk</em> size. It is linear in the length of sentence. However, ... helpful in speeding up the algorithm. 560 Firstly, we collect <em>chunk</em> type transition information between <em>chunk</em> types by observing every pair of adjacent <em>chunks</em> in the training corpus, and record a <em>chunk</em> type transition matrix. For example, from the Chinese Treebank that ... Treebank that we used for our experiments, a transition from <em>chunk</em> type ADJP to ADVP does not occur in the training ... element is set to false, true otherwise. During decoding, the <em>chunk</em> type transition information is used to prune unlikely combinations between ... transition information is used to prune unlikely combinations between current <em>chunk</em> and the preceding <em>chunk</em> by their <em>chunk</em> types. Secondly, a POS tag dictionary is used to record ... dictionary is used to record POS tags associated with each <em>chunk</em> type. Specifically, for each <em>chunk</em> type, we record all POS tags appearing in this type ... we record all POS tags appearing in this type of <em>chunk</em> in the training corpus. During decoding, a segment of continuous ... POS tag dictionary will be considered to be a valid <em>chunk</em> candidate. Finally, the system records the maximum number of words ... records the maximum number of words for each type of <em>chunk</em> in the training corpus. For example, in the Chinese Treebank, ... corpus. For example, in the Chinese Treebank, most types of <em>chunks</em> have one to three words. The few <em>chunk</em> types that are seen with length bigger than ten are ... than ten are NP, QP and ADJP. During decoding, the <em>chunk</em> candidate whose length is greater than the maximum <em>chunk</em> length associated with its <em>chunk</em> type will be discarded. For the above pruning schemes, development ... <br /> ... for joint segmentation and labeling problems is F1 measure over <em>chunks</em>. . This is the geometric mean of precision and recall ... the geometric mean of precision and recall over the (properly-labeled) <em>chunk</em> identification task, defined as follows. 2 | |?( , ) ... where the cardinality of y is simply the number of <em>chunks</em> ... identified. The cardinality of the intersection is the number of <em>chunks</em> in common. As can be seen in the definition, one ... the definition, one is penalized both for identifying too many <em>chunks</em> (penalty in the denominator) and for identifying too few (penalty ... c, t, w and p are used to represent a <em>chunk</em>, , a <em>chunk</em> type, a word and a POS tag, respectively. And c0 ... POS tag, respectively. And c0 and c?1 represent the current <em>chunk</em> and the previous <em>chunk</em> respectively. Similarly, w?1, w0 and w1 represent the previous word, ... (called SL-type features), the features describing internal structure of a <em>chunk</em> (called Internal-type features), and the features capturing the correlations between ... features), and the features capturing the correlations between the adjacent <em>chunks</em> (called Correlation-type features). Firstly, some features associated with a single ... indicating the position of the word w in the current <em>chunk</em>; ; len(c) denotes the length of <em>chunk</em> c. For example, given an NP <em>chunk</em> &quot;??(Beijing) ??(Airport)&quot;, which includes two words, the value of label(&quot;??&quot;) ... Template specitermMatch(c) is used to check the punctuation matching within <em>chunk</em> c for the special terms, as illustrated in section 1. ... in our model, we have a chance to treat the <em>chunk</em> candidate as a whole during decoding, which means that we ... end_word(c) represent the first word and the last word of <em>chunk</em> c, respectively. Similarly, start_POS(c) and end_POS(c) represent the POS tags ... associated with the first word and the last word of <em>chunk</em> c, respectively. These features aim at expressing the formation patterns ... features aim at expressing the formation patterns of the current <em>chunk</em> with respect to words and POS tags. Template internalWords(c) denotes ... POS tags. Template internalWords(c) denotes the concatenation of words in <em>chunk</em> ... c, while internalPOSs(c) denotes the sequence of POS tags in <em>chunk</em> c using regular expression-like form, as illustrated in section 1. ... the Correlation-type features, where head(c) denotes the headword extracted from <em>chunk</em> c, and headPOS(c) denotes the POS tag associated with the ... headPOS(c) denotes the POS tag associated with the headword in <em>chunk</em> c. These features take into account various aspects of correlations ... features take into account various aspects of correlations between adjacent <em>chunks</em>. ... . For example, we extracted the headwords located in adjacent <em>chunks</em> ... to form headword bigrams to express semantic dependency between adjacent <em>chunks</em>. . To find the headword within every <em>chunk</em>, , we referred to the head-finding rules from (Bikel, 2004), ... <br /> ... of the F1-score, even for the voting methods. For text <em>chunking</em> task, our approach improves performance by 0.65% over SVMs, and ... and 0.43% over the voting method, respectively. Method F1 NP <em>chunking</em> CRFs 89.72 SVMs 90.62 Voting 91.13 Ours 91.50 Text <em>chunking</em> CRFs 90.74 SVMs 91.46 Voting 91.68 Ours 92.11 Table 4: ... SVMs 91.46 Voting 91.68 Ours 92.11 Table 4: Comparisons of <em>chunking</em> performance for Chinese NP <em>chunking</em> and text <em>chunking</em>. . In particular, for NP <em>chunking</em> task, the F1-score of our approach is improved by 0.88% ... the comparison of F1-scores of the two systems by the <em>chunk</em> length. In the Chinese <em>chunking</em> corpus, the max NP length is 27, and the mean ... the performance gap grows rapidly with the increase of the <em>chunk</em> length. In particular, the gap between the two systems is ... gap begins to become smaller with further growth of the <em>chunk</em> length. The reasons may include the following two aspects. First, ... of F1-scores of NP recognition on Chinese corpus by the <em>chunk</em> ... length. 6.5 Impact of Different Types of Features Our phrase <em>chunking</em> model is highly dependent upon <em>chunk</em>- -level information. To establish the impact of each type of ... to the system results in significant performance improvement on NP <em>chunking</em> and on text <em>chunking</em>, , achieving 2.53% and 1.37%, respectively. Further, if Correlation-type features ... Further, if Correlation-type features are used, the F1-scores on NP <em>chunking</em> and on text <em>chunking</em> are improved by 1.01% and 0.66%, respectively. The results show ... use of Internal-type features and Correlation-type features for both NP <em>chunking</em> and text <em>chunking</em>. . Task Type Feature Type F1 NP <em>chunking</em> SL-type 87.96 +Internal-type 90.49 +Correlation-type 91.50 Text chunkingSL-type 90.08 +Internal-type ... 6.6 Performance on Other Languages We mainly focused on Chinese <em>chunking</em> in this paper. However, our approach is generally applicable to ... CoNLL 2000 data set, a public benchmarking corpus for English <em>chunking</em> (Sang and Buchholz 2000). The training set consists of 8936 ... test set consists of 2012 sentences. We conducted both the NP-<em>chunking</em> and text <em>chunking</em> experiments on this data set with our approach, using the ... our approach, using the same feature templates as in Chinese <em>chunking</em> ... task excluding template 13. To find the headword within every <em>chunk</em>, , we referred to the head-finding rules from (Collins, 1999), ... state-of-the-art systems. Table 6 also shows state-of-the-art performance for both NP-<em>chunking</em> and text <em>chunking</em> tasks. LDCRF's results presented in (Sun et al., 2008) are ... (Sun et al., 2008) are the state-of-the-art for the NP <em>chunking</em> task, and SVM's results presented in (Wu et al., 2006) ... <br /> ... Press. Tong Zhang, F. Damerau, and D. Johnson. 2002. Text <em>chunking</em> based on a generalization of winnow. Journal of Machine Learning ... <br />
<br />
<strong>Abstract</strong>:<br />
&lt;p&gt;Most existing systems solved the phrase <em>chunking</em> task with the sequence labeling approaches, in which the <em>chunk</em> candidates cannot be treated as a whole during parsing process ... treated as a whole during parsing process so that the <em>chunk</em>- -level features cannot be exploited in a natural way. In ... in a natural way. In this paper, we formulate phrase <em>chunking</em> as a joint segmentation and labeling task. We propose an ... direct use of the features describing the internal characteristics of <em>chunk</em> and the features capturing the correlations between adjacent <em>chunks</em>. . A relaxed, online maximum margin training algorithm is used ... explored a variety of effective feature representations for Chinese phrase <em>chunking</em>. . The experimental results show that the use of <em>chunk</em>- -level features can lead to significant performance improvement, and that ... <br />
<br />
<strong>References</strong>:<br />
Steven P. Abney. 1991. Parsing by <em>chunks</em>. In Robert C. Berwick, Steven P. Abney, and Carol Tenny, editors, Principle-Based Parsing, pages 257--278. Kluwer Academic Publishers. <br /> Wenliang Chen, Yujie Zhang, and Hitoshi Isahara. 2006. An empirical study of Chinese <em>chunking</em>. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 97--104. <br /> Taku Kudo and Yuji Matsumoto. 2001. <em>Chunking</em> with support vector machines. In Proceedings of NAACL01. <br /> Heng Li, Jonathan J. Webster, Chunyu Kit, and Tianshun Yao. 2003. Transductive hmm based chinese text <em>chunking</em>. In Proceedings of IEEE NLPKE2003, pages 257--262, Beijing, China. <br /> E. F. T. K Sang and S. Buchholz. 2000. Introduction to the CoNLL-2000 shared task: <em>Chunking</em>. In Proceedings CoNLL-00, pages 127--132. <br /> Yongmei Tan, Tianshun Yao, Qing Chen, and Jingbo Zhu. 2004. Chinese <em>chunk</em> identification using svms plus sigmoid. In IJCNLP, pages 527--536. <br /> Erik F. Tjong Kim Sang. 2002. <em>Memory</em>-based shallow parsing. JMLR, 2(3): 559--594. <br /> Yu-Chieh Wu, Chia-Hui Chang, and Yue-Shi Lee. 2006. A general and multi-lingual phrase <em>chunking</em> model based on masking method. In Proceedings of 7th International Conference on Intelligent Text Processing and Computational Linguistics, pages 144--155. <br /> Tong Zhang, F. Damerau, and D. Johnson. 2002. Text <em>chunking</em> based on a generalization of winnow. Journal of Machine Learning Research, 2: 615--637. <br />
<br />
<strong>Title</strong>:<br />
Exploiting <em>chunk</em>-level features to improve phrase <em>chunking</em> <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
7
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=2387856" target="_self">SSMalloc: a low-latency, locality-conscious memory allocator with stable performance scalability</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81542423156">Ran Liu</a>,
<a href="author_page.cfm?id=81350589210">Haibo Chen</a>
</div>
<div class="source">
<span class="publicationDate">July 2012</span>
<span style="padding-left:10px">APSys '12: Proceedings of the Third ACM SIGOPS Asia-Pacific conference on Systems</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;USENIX Association
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 5</span></div>
<div></div>
</div>
</div>
<br clear="all" />
<div>[<a href="javascript: void(0);" onclick="expand('high2387856');">result highlights</a>]</div>
<div class="highlights" id="high2387856" style="display:none">
<strong>Full Text</strong>:<br />
... performancescalability are three key factors affecting the ef?-ciency of a <em>memory</em> allocator for many cores. How-ever, many previous state-of-the-art <em>memory</em> alloca-tors focus one or two of them, making the applica-tion ... investigation (detailed data in sec-tion 3) indicates that most state-of-art <em>memory</em> allo-cators cannot maintain stable scalability and local-ity when the number ... it canprovide more predictable performance for many ap-plications requiring frequent <em>memory</em> allocation.This paper presents a new <em>memory</em> allocator(called SSMalloc) that provide low-latency andlocality-consciousmemory management with stableperformance scalability ... decisions un-derlying SSMalloc include: 1) providing low andpredictable latency for <em>memory</em> management oper-ations through carefully minimized critical path; 2)minimizing mmap system ... version ofSSMalloc and evaluated its performance and scal-ability against state-of-the-art <em>memory</em> allocators.Experiments using a number of commonly usedallocation-benchmarks running on a ... elim-inates most of the synchronization. Each privateheap holds several ?xed-size <em>memory</em> <em>chunks</em>. . Amemory <em>chunk</em> contains many objects of the samesize class.???????t????r????????????????????r?????? ????r?????????????????????? ????? ????????????? ... heap space is insuf?cientto ful?ll a subsequent request, a free <em>memory</em> chunkis fetched from a global pool. If the thread privateheap ... global pool. If the thread privateheap holds too many free <em>memory</em> <em>chunks</em>, , somechunks will be reclaimed back to the global pool.Most ... to enlargethe global pool simultaneously, However, it is use-less since <em>memory</em> map operations will contend inkernel.2.1 <em>Memory</em> ChunksMemory <em>chunk</em> is the basic unit of the memoryexchange between the private ... <br /> <em>memory</em> <em>chunk</em> storesmemory objects of the same size class.Allocations requests smaller than ... threads. Small allocations are subdivided intoseveral prede?ned size classes. A <em>memory</em> requestis served with a <em>memory</em> block of the nearest sizeclass. SSMalloc chooses three sets of ... and Large (384B, 512B, ...,32768B, 49152B, 65536B).Data area of the <em>memory</em> <em>chunk</em> is divided intoclean area and dirty area. <em>Memory</em> in clean areahas never been touched in the <em>memory</em> <em>chunk</em>. . Theheader maintains a pointer to the clean area and ... a free object in this list. Ifthe list is empty, <em>memory</em> will be allocated from theclean area by increasing the clean ... from theclean area by increasing the clean pointer. Design-ing the <em>memory</em> <em>chunk</em> includes several other con-siderations:Uniform <em>Memory</em> <em>Chunk</em> Size for MemoryReuse: <em>Memory</em> <em>chunk</em> size is crucial to SSMal-loc’s performance. Smaller <em>chunk</em> size forces pri-vate heaps to perform more synchronization withthe global ... of mem-ory, thus suppress the scalability of the allocator,while larger <em>chunks</em> introduce more <em>memory</em> frag-mentation, which result in poor spatial locality andcomparably higher <em>memory</em> consumption.A typical approach adapted by many other allo-cators is using ... typical approach adapted by many other allo-cators is using larger <em>chunks</em> for larger classes. Itensures that <em>memory</em> <em>chunks</em> for every class con-tains enough available <em>memory</em> objects. In contrast,<em>memory</em> <em>chunks</em> in SSMalloc are of the same sizefor all the size ... frequently than largeones. This design naturally guarantees that a mem-ory <em>chunk</em> for smaller size class contains more avail-able <em>memory</em> objects. Further, this design bringsseveral more bene?ts: 1) In the ... more bene?ts: 1) In the private heap, the sizeclass for <em>memory</em> objects could be changed instantlywithout additional coalescing and splitting of ... instantlywithout additional coalescing and splitting of mem-ory areas. It allows <em>memory</em> <em>chunks</em> to be easilyreused as other size classes within the private ... a lock-free global pool possible.3) Indexing the metadata of a <em>memory</em> object be-came straightforward and can be done by a simplealignment ... and can be done by a simplealignment operation, as described below.Per-<em>chunk</em> Metadata to Ease Locating: Mem-ory allocators often cluster metadata in ... often cluster metadata in a central-ized area, which improves spatial <em>memory</em> local-ity by eliminating per-object header but make itharder to locate ... which is usually costly.2In SSMalloc, metadata are placed in the per-<em>chunk</em> header. Spatial locality is still preserved sincethere is no metadata ... no metadata in the data area of a memorychunk. As <em>memory</em> <em>chunks</em> are placed one after an-other in heap space, locating metadata ... locating metadata is as sim-ple as aligning the address of <em>memory</em> ... object to thechunk boundary, which is a simple O(1) operation.Unaligned <em>Chunk</em> to Reduce Cache Con?ict:As described above, the size of <em>memory</em> <em>chunks</em> inSSMalloc is 65536 bytes + 256 bytes, which is notaligned ... notaligned to page size. Although it would be easier tomanage <em>memory</em> resources if <em>memory</em> <em>chunk</em> size isaligned, all the headers would be placed at the ... all the headers would be placed at the be-ginning of <em>memory</em> pages, thus occupying the samecache sets. Accessing these headers will ... We address this problem by as-signing an unaligned size to <em>memory</em> <em>chunks</em>, , whichstaggers cache lines used by different headers andconsequently balances ... heap maintains several memorychunks in different states as listed below.Foreground <em>Chunks</em> are <em>chunks</em> currently in use,which are responsible for the next allocation. Hencethere ... allocation. Hencethere is at least one free object in each <em>chunk</em>. . Aprivate heap maintains one Foreground <em>Chunk</em> foreach size class.Full <em>Chunks</em> are <em>chunks</em> with no available mem-ory objects. After all the objects are ... available mem-ory objects. After all the objects are allocated, aForeground <em>Chunk</em> becomes a Full <em>Chunk</em> and a newForeground <em>Chunk</em> is selected.Background <em>Chunks</em> contains one or more freeobjects. Freeing a single object in ... object in a Full Chunkmakes it to be a Background <em>Chunk</em>. ... . They are main-tained in lists in private heaps.Local Free <em>Chunks</em> are completely free chunksthat are temporarily cached in the private ... chunksthat are temporarily cached in the private heap. ALocal Free <em>Chunk</em> could be directly converted intoa <em>memory</em> <em>chunk</em> ... of any size class and reused lo-cally. When the free <em>chunk</em> <br /> <em>chunks</em> are releasedto the global <em>memory</em> pool and become Global FreeChunks.Dummy <em>Chunk</em> is a special pseudo <em>chunk</em> thatcontains a valid header and only one available mem-ory object. ... mem-ory object. When a private heap is allocated, allthe Foreground <em>Chunk</em> pointers points to a sin-gle Dummy <em>Chunk</em> that resides in the private heapheader. During the ?rst allocation ... heapheader. During the ?rst allocation in a size class,the dummy <em>chunk</em> will be replaced by a real mem-ory <em>chunk</em>. . This trick eliminates the validity checkof <em>memory</em> <em>chunk</em> in critical path.2.3 Global PoolGlobal pool manages <em>memory</em> <em>chunks</em> and privateheaps in the lowest level of SSMalloc. All the ... privateheaps in the lowest level of SSMalloc. All the mem-ory <em>chunks</em> and private heaps are allocated from theGlobal Pool. Detailed structure ... 3.?r??r ????? -?? '???$????&quot;?????.?/?$????&quot;????Figure 3: Global Pool in SSMallocContiguous Raw <em>Memory</em> Pool to Reduce VMFootprint: Raw <em>Memory</em> Pool occupies a contigu-ous area in the address space, in ... de-sign is TLB-friendly since it keeps virtual memoryfootprint of allocated <em>memory</em> as smaller as possi-ble.There’s a pointer recording the begin of ... pointer recording the begin of unusedmemory area of the Raw <em>Memory</em> Pool. Memorychunks are allocated by increasing this pointer bythe size ... are allocated by increasing this pointer bythe size of a <em>memory</em> <em>chunk</em>, , which could be done inone atomic instruction.Raw <em>Memory</em> Pool is enlarged via mmap if itsspare space is not ... reduce the number of mmapcalls, the size of the Raw <em>Memory</em> Pool is enlargedexponentially each time. Besides, since the desig-nated virtual ... the total time spent in mmapcalls can be greatly reduced.Global <em>Memory</em> Reuse: Globally freed memorychunks are maintained in a lock-free Global ... FreeChunk List. When a private heap tries to allocate amemory <em>chunk</em> ... from the Global Pool, it ?rst tries topop a free <em>memory</em> <em>chunk</em> ... from this list. In case thelist is empty, a new <em>memory</em> <em>chunk</em> will be allocatedfrom the Raw <em>Memory</em> Pool. Since all the memorychunks are of the same size, ... the same size, no further processingis needed on the returned <em>memory</em> <em>chunks</em>. . In thisway <em>memory</em> <em>chunks</em> can be reused among differentlocal heaps.Private Heap Reuse: After a ... Reuse: After a thread is termi-nated, there may be several <em>memory</em> <em>chunks</em> remain-ing in the private heap. Rather than returning thesememory <em>chunks</em> to the Global Pool, SSMalloc di-rectly caches the whole private ... memorychunks. Reusing these private heaps reduces syn-chronization needed to allocate <em>memory</em> <em>chunks</em> tofresh private heaps. This mechanism minimizes theoverhead of thread creation ... a special value) is addedbefore the beginning of each large <em>memory</em> objectto record its related metadata. Since large alloca-tions rarely happen ... calculatedfrom the requested size. If it is a small allocation,a <em>memory</em> object is allocated from the ForegroundChunk of that class. Otherwise ... AlgorithmThe algorithm is summarized as the followingpseudo-code. Note that all <em>chunks</em> in SSMalloc areorganized in a FIFO fashion so that data ... ptr of the object to be deallocatedcph? CurrentPrivateHeap;1chunk ? ExtractChunk(ptr);2if IsOwner(cph,<em>chunk</em>) ) then3LocalFree(<em>chunk</em>, ,ptr);4else5if IsLarge(<em>chunk</em>) ) then6LargeFree(ptr);7else8RemoteFree(<em>chunk</em>, ,ptr);9end10end11Memory object may be freed by threads otherthan its owner ... <br /> not directly operate on the cor-responding <em>memory</em> <em>chunk</em>. . Similar to Stream-?ow [2], each <em>memory</em> <em>chunks</em> maintains an addi-tional lock-free list in to temporarily store memory4objects ... temporarily store memory4objects deallocated be other threads. Other threadscan insert <em>memory</em> objects to this list via a singleatomic instruction. Even so, ... with kernel version 3.2.10.The machine has 128 GB of memory.Other <em>memory</em> allocators we used for comparisoninclude (1) the thread-safe allocator of ... splint [8],a tool for statically checking C programs; (4)shbench, a <em>memory</em> allocator stress test tool fromMicroQuill [9]; (5) Larson benchmark from ... objects. It is a common characteristic ofmost applications using dynamic <em>memory</em> alloca-tion. The benchmarks we chose represent severaldifferent <em>memory</em> reuse patterns.Sequential Performance: We choose 3 applica-tions for sequential performance ... normalized to the one with glibc malloc.SSMalloc outperforms all other <em>memory</em> allocatorsin espresso, splint and 197.parser, due to the opti-mization for ... inmost cases. For Recycle, SSMalloc consistently out-perform all the other <em>memory</em> allocators for at least8.9% . It is mainly because SSMalloc ... also con?rms that SSMalloc experiencemuch less cache misses that other <em>memory</em> alloca-tors with both 48 and 1024 threads. This furthercontributes to ... much less execution time of theMapphase, as shown in Figure 4(f).<em>Memory</em> Space Ef?ciency: We measure the5 0.6 0.7 0.8 0.9 1 ... <br /> ... 25868K 25580K197.parser 10084K 10932K 8864K 21604K 9876K 10068KTable 1: Physical <em>memory</em> consumption of each <em>memory</em> allo-catorpeak physical <em>memory</em> footprint of all the bench-marks for 48 threads, as shown ... bench-marks for 48 threads, as shown in Table 1. SSMal-loc’s <em>memory</em> consumption for most programs aresimilar with other allocators. The <em>memory</em> footprintfor Larson is larger as Larson measures the through-put in ... as SFMalloccaches remotely freed objects locally and thus in-curs greater <em>memory</em> consumption.4 CONCLUSIONIn this paper, we have introduced an <em>memory</em> alloca-tor SSMalloc. SSMalloc explored the design spaceof <em>memory</em> allocator for many-thread programs onmany-core system. It simultaneously provided verylow ... Kim, and J. Lee. Sfmalloc: A lock-free and mostlysynchronization-free dynamic <em>memory</em> allocator for manycores.In Proc. PACT, 2011.[4] W. Gloger. Dynamic <em>memory</em> allocator implementationsin linux system libraries. http://www.dent.med.uni-muenchen.de/~wmglo/malloc-slides.html.[5] Google. Tcmalloc: Thread-caching malloc. ... 19(1):42–51, 2002.[9] MicroQuill, Inc. http://www.microquill.com.[10] P. . Larson and M. Krishnan. <em>Memory</em> allocation for long-running server applications. In ACM SIGPLAN Notices, vol-ume ... <br />
<br />
<strong>References</strong>:<br />
S. Seo, J. Kim, and J. Lee. Sfmalloc: A lock-free and mostly synchronization-free dynamic <em>memory</em> allocator for manycores. In <i>Proc. PACT</i>, 2011. <br /> W. Gloger. Dynamic <em>memory</em> allocator implementations in linux system libraries. http://www.dent.med. uni-muenchen.de/~wmglo/malloc-slides.html. <br /> P. &#197;. Larson and M. Krishnan. <em>Memory</em> allocation for long-running server applications. In <i>ACM SIGPLAN Notices</i>, volume 34, pages 176-185. ACM, 1998. <br />
<br />
<strong>Title</strong>:<br />
SSMalloc: a low-latency, locality-conscious <em>memory</em> allocator with stable performance scalability <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
8
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=2232067" target="_self">A fast mount mechanism for YAFFS2</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81460647374">Jinman Jung</a>,
<a href="author_page.cfm?id=81493647262">Joonhyouk Jang</a>,
<a href="author_page.cfm?id=81327488047">Yookun Cho</a>,
<a href="author_page.cfm?id=81414616255">Hwansoo Han</a>,
<a href="author_page.cfm?id=81452597037">Gwangil Jeon</a>,
<a href="author_page.cfm?id=81384590826">Seong-Je Cho</a>,
<a href="author_page.cfm?id=81493655692">Minwoo Jang</a>,
<a href="author_page.cfm?id=81502746004">Jung Y. Kim</a>
</div>
<div class="source">
<span class="publicationDate">March 2012</span>
<span style="padding-left:10px">SAC '12: Proceedings of the 27th Annual ACM Symposium on Applied Computing</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 0</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;1</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;1</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;123</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=2232067&ftid=1224170&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Flash file systems that are not cleanly unmounted (e.g., in the event of power failure or an abnormal shutdown) may cause a scan of all flash memory when the system is remounted in order to gather all inode information and store it in RAM. This results in an unacceptably long ...
</div>
<div class="kw">
<b>Keywords</b>:
YAFFS2, fast mounting, file system, flash memory
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high2232067');">result highlights</a>]</div>
<div class="highlights" id="high2232067" style="display:none">
<strong>Full Text</strong>:<br />
... an abnormal shutdown) may cause a scan of all flash <em>memory</em> when the system is remounted in order to gather all ... systems which relies on a block inband tag with the <em>chunk</em> deletion history. This provides the ability to selectively scan the ... organization Maintenance. General Terms Algorithms, Performance Keywords Fast Mounting, Flash <em>Memory</em>, , File System, YAFFS2 1. INTRODUCTION Flash <em>memory</em> is widely used for general data storage purposes in embedded ... high shock/vibration resistance and low power consumption. However, because flash <em>memory</em> has different physical characteristics compared to a traditional hard disk, ... systems designed for disks are typically not appropriate for flash <em>memory</em>. . One characteristic of flash <em>memory</em> is that each block has a limited erase count lifetime ... instances [1]. Since this can reduce the reliability of flash <em>memory</em>, , the file system needs to take into account the ... system needs to take into account the wearing of the <em>memory</em> blocks by making this process as even as possible. Additionally, ... by making this process as even as possible. Additionally, flash <em>memory</em> has a limitation related to overwriting. Because flash <em>memory</em> does not allow in-place updates, new data cannot be overwritten ... each time an overwrite operation is performed. To use flash <em>memory</em> as file system storage, file systems for a flash device ... or page mapping due to its unique characteristics. These flash <em>memory</em> functionalities can be provided as a software layer known as ... modification. However, this approach makes file system inefficient for flash <em>memory</em> management. For efficient flash <em>memory</em> management, we focus on a flash file system approach that ... file system operations while directly addressing the characteristics of flash <em>memory</em>. . Many types of file systems have been developed for ... log-structured flash file system [8] originally based on NOR flash <em>memory</em>. . Later, NAND flash <em>memory</em> support was added to JFFS2. JFFS and JFFS2 maintain nodes, ... which represents a file. They are stored in the flash <em>memory</em> in an append-only manner with a version number, which allows ... order to reconstruct file system, all nodes on the flash <em>memory</em> are scanned. This lengthens the mounting time in JFFS and ... time in JFFS and necessitates a large amount of main <em>memory</em> proportional to the size of the flash <em>memory</em>. . YAFFS (Yet Another Flash Filing System) [6] was designed ... was designed and developed by Aleph One for NAND flash <em>memory</em>. . In YAFFS, files are stored as either a file ... file object header or as a data type in fixed-size <em>chunks</em> in NAND flash <em>memory</em>. . Each <em>chunk</em> has a spare area that holds additional information such as ... a spare area that holds additional information such as the <em>chunk</em> ID, serial number, number of bytes, object ID and ECC ... number of bytes, object ID and ECC of the corresponding <em>chunk</em>. . YAFFS has a faster mount time than JFFS2, as ... as it does not require reading of all of the <em>chunks</em>, , needing only to read tags in the spare area ... tags in the spare area and object headers in the <em>chunks</em>. . YAFFS2 is similar in concept to YAFFS and can ... <br /> ... scanBackward scanNoYesSort ChronologicallyBlocksRestore checkpoint dataReconstruct file systemsEndmounting…file ID # 1, <em>Chunk</em> # 0file ID # 1, <em>Chunk</em> # 1file ID # 2, <em>Chunk</em> # 0…Header TagDataHeaderTagDataDataDataTagTagTagTagHeader TagDataDataTagDataDataHeaderTagTagTagTagBlock Sequence = iBlock Sequence = i ... Sequence = iBlock Sequence = i +1file ID # 2, <em>Chunk</em> # 1file ID # 2, <em>Chunk</em> # 2file ID # 2, <em>Chunk</em> # 3file ID # 3, <em>Chunk</em> # 0file ID # 3, <em>Chunk</em> # 1file ID # 4, <em>Chunk</em> # 1file ID # 2, <em>Chunk</em> # 0file ID # 2, <em>Chunk</em> # 1file ID # 2, <em>Chunk</em> # 2File Object ListFile ID = 2RAM Flash <em>Memory</em> BackwardScan1792Figure 3 shows an example of a backward scan. In ... file with a file ID of two uses three valid <em>chunks</em> located in the block with a block sequence of (i+1) ... block with a block sequence of (i+1) and one valid <em>chunk</em> located in the block with a block sequence of i, ... block with a block sequence of i, as the second <em>chunks</em> with the same file ID and <em>chunk</em> ID as the previously encountered <em>chunk</em> during the backward scan will be discarded. Some common notations ... time A The availability of checkpoint data P The flash <em>memory</em> usage ratio Tscan The time of the backward scan Tckpt ... file system by introducing a block inband tag with the <em>chunk</em> deletion history. Our mechanism can be independently combined with a ... is faster to fetch all of the tags from a <em>chunk</em> (assuming the existence of redundant tags in the last <em>chunk</em> of each block) than from all of the tags within ... the tags within each block. We refer to the last <em>chunk</em> that contains all of the tags of a block as ... tag, as it is provided at the sacrifice of one <em>chunk</em> of data in the block. Table 2. High-level read operation ... block inband tag within each block, which consists of M <em>chunks</em>. . The (M-1) <em>chunks</em> are used for the data parts and the Mth <em>chunk</em> is reserved for the block inband tag, which is marked ... with a special number in the tag of the last <em>chunk</em>. . When the (M-1)st <em>chunks</em> in the block are filled, the block inband tag is ... a block, however, is being used for allocation by the <em>chunk</em> allocator or is being collected by the garbage collector at ... inband tag 75 us (? Tp + Tt) Figure 5. <em>Chunk</em> deletion history (CDH) In addition, to address the problem of ... all the tags regardless of the actual use of the <em>chunk</em>, , we use the <em>chunk</em> deletion history (CDH) by adding the information of the previously ... history (CDH) by adding the information of the previously original <em>chunk</em> to the tag of the newly created <em>chunk</em> as a software deletion marker 1whenever a <em>chunk</em> is updated. This 1 The hardware deletion marker can be ... <br /> ... iBlock Sequence = i +1Header TagDataHeaderTagDataDataDataTagTagTagTag…Header TagDataDataTagDataDataTagTagTagObject ID # 2, <em>Chunk</em> # 1Object ID # 2, <em>Chunk</em> # 1After updating a data chunkPrevious block sequence Previous <em>chunk</em> indexChunk deletion history (CDH)ij1793information includes the block sequence and <em>chunk</em> offset of the previously original <em>chunk</em>, , as shown in Figure 5. This approach allows a ... bitmap in the Mth tag, CDHs are loaded into the <em>memory</em> and inserted into the deletion marker list in the order ... at least one written (whether it is valid or not) <em>chunk</em> because empty blocks are eliminated from the block list needing ... of these written blocks, the block inband tag with the <em>chunk</em> deletion history provides two scan mechanisms. The first is to ... two scan mechanisms. The first is to read the last <em>chunk</em> of each block with the block inband tag instead of ... of the tags ALOCATING read only the tags of used <em>chunks</em> FULL read the block inband tag PARTIALLY INVALIDATED read either ... either the block inband tag or the tags of valid <em>chunks</em> FULLY INVALIDATED do not read all of the tags COLLECTING ... read either the block inband tag or tags of valid <em>chunks</em> when a page is obsolete. This can cause an additive ... of the block inband tags indicates that all of the <em>chunks</em> in this block have been allocated. In contrast, the absence ... This signifies that the block contains at least one invalid <em>chunk</em>. . Here, if the number of valid <em>chunks</em> (X) of the block in the deletion marker list is ... mount mechanism can scan selectively by reading either the last <em>chunk</em> of each block or certain valid tags of the block ... with an 833 MHz ARM processor, 256 MB of main <em>memory</em> and 512MB of NAND flash <em>memory</em>. . Figure 8 summarizes our experimental environment. In the experiments, ... we measured the average mount time of the NAND flash <em>memory</em> with a file size range of 256 Kbytes to 20 ... Item Specification CPU Samsung S5PC100 ARM Cortex A8 (833Mhz) Main <em>Memory</em> 256MB Flash <em>Memory</em> NAND Flash <em>Memory</em> ... 512MB OS Linux 2.6.29 Figure 7. Impact of the flash <em>memory</em> usage … …Tagi (where 1 ? i ? M-1 )Block ... deletion historyBlock inband tagChunk deletion history (CDH) bitmapPrevious block sequencePrevious <em>chunk</em> offset…<em>Chunk</em> deletion history (CDH)Block StateNumber of BytesBlock SequenceChunk deletion history bitmapTagMTagiTagMTag1In ... <br /> ... BS = j-4InvalidCnt:1……0 10 20 30 40 50 60 70012345678910Flash <em>memory</em> usage (%)Mount time (sec)YAFFS2The proposed approach1794Figure 7 shows the average ... 7 shows the average mount time according to the flash <em>memory</em> usage with files 10 Mbytes in size. Our findings show ... an increase in the mount time arises as the flash <em>memory</em> usage increases for both approaches. This occurs mainly due to ... scanning of only blocks that have at least one written <em>chunk</em> with the help of the pre-scan. We also observed that ... We also observed that YAFFS2 was more sensitive to flash <em>memory</em> usage compared to our scheme. The result shows that the ... However, the block inband tag incurs the overhead of one <em>chunk</em> per block. Figure 9 illustrates the throughput of the write ... write operation required by the block inband tag when (M-1) <em>chunks</em> in each block are written. This figure also shows that ... read operation by introducing a block inband tag with the <em>chunk</em> deletion history was increased. 5. CONCLUSION This paper presented a ... time, our approach used a block inband tag with the <em>chunk</em> deletion history (CDH), thus providing the ability to fetch the ... 2011. 7. REFERENCES [1] S. Skorobogatov, Data remnants in flash <em>memory</em> devices, In proceedings of Cryptographic Hardware and Embedded Systems(CHES), pp. ... Gal and S. Toledo, Algorithms and Data Structures for Flash <em>Memories</em>, , ACM Computing Surveys, vol. 37, no. 2, pp. 138-163, ... proposed approach [4] A. Kawaguchi, S.Nishioka, and H. Motoda, A flash-<em>memory</em> based file system, In Proceedings of the USNIX, pp. 155-164, ... Flash File System to Support Fast Mounting for NAND Flash <em>Memory</em> Based Embedded Systems, Embedded Computer Systems: Architectures, Modeling, and Simulation(SAMOS), ... <br /> ... ordered list, the first occurrence of any object ID and <em>chunk</em> ID is the most active occurrence, allowing it to determine ... spare area, which can hold the tag of an invalid <em>chunk</em> (except for empty blocks) to build up the structure of ... on the use of a block inband tag with the <em>chunk</em> deletion history (CDH), which is the last page of each ... tags in the block including the deletion histories of the <em>chunk</em> upon the sacrifice of the last page. Our fast mount ... device with N blocks which consists of M pages. Each <em>chunk</em> (identical to that in YAFFS2 terminology) has a spare area ... sequence numbers increase monotonically with a newly written block. Each <em>chunk</em> within a block is allocated in a sequential order, and ... a block is allocated in a sequential order, and each <em>chunk</em> should be erased before it is overwritten or programmed. Thus, ... be erased before it is overwritten or programmed. Thus, the <em>chunk</em> and spare areas cannot be rewritten at the same location. ... location. Files are identified by a file ID and a <em>chunk</em> ID which identifies where the <em>chunk</em> belongs in the file. Files are stored as either an ... either an object header or a data type into fixed-size <em>chunks</em> on the flash device. The file ID, <em>chunk</em> ID and sequence number are stored as a tag in ... scanning, in which it is easy to choose the actual <em>chunks</em> with the largest sequence number from among multiple pages having ... from among multiple pages having the same file ID and <em>chunk</em> ID. Figure 3. An example of backward scanning … …<em>Chunk</em> SpareTagBlock StateChunk IDFile IDNumber of BytesBlock SequenceTags ECCECCUnusedTypeNameParent file IDFile ... <br />
<br />
<strong>Abstract</strong>:<br />
... an abnormal shutdown) may cause a scan of all flash <em>memory</em> when the system is remounted in order to gather all ... systems which relies on a block inband tag with the <em>chunk</em> deletion history. This provides the ability to selectively scan the ... <br />
<br />
<strong>References</strong>:<br />
S. Skorobogatov, Data remnants in flash <em>memory</em> devices, In proceedings of Cryptographic Hardware and Embedded Systems(CHES), pp. 339, 2005 <br /> E. Gal and S. Toledo, Algorithms and Data Structures for Flash <em>Memories</em>, ACM Computing Surveys, vol. 37, no. 2, pp. 138--163, 2005 <br /> A. Kawaguchi, S. Nishioka, and H. Motoda, A flash-<em>memory</em> based file system, in <i>Proceedings of the USNIX</i>, pp. 155--164, 1995 <br /> S. H. Park, T. H. Lee, K. D. Chung, A Flash File System to Support Fast Mounting for NAND Flash <em>Memory</em> Based Embedded Systems, Embedded Computer Systems: Architectures, Modeling, and Simulation(SAMOS), vol. 4017, pp. 415--424, 2006 <br />
<br />
<strong>Keywords</strong>:<br />
flash <em>memory</em> <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
9
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=3292535" target="_self">Tree-based Read-only Data Chunks for NVRAM Programming</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=99658650058">Kumud Bhandari</a>,
<a href="author_page.cfm?id=81548006882">Vivek Sarkar</a>
</div>
<div class="source">
<span class="publicationDate">September 2016</span>
<span style="padding-left:10px">DFM'16: Proceedings of the Sixth Workshop on Data-Flow Execution Models for Extreme Scale Computing</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 0</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;0</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;0</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;0</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3292535&ftid=2026843&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
As the DRAM technology is fast reaching a scaling threshold, emerging non-volatile, byte-addressable memory (NVRAM) is expected to supplement and eventually replace DRAM. Future computing systems are anticipated to have a large amount of NVRAM, possibly spanning across more than one coherence domain. Furthermore, taking advantage of in-place persistence provided ...
</div>
<div class="kw">
<b>Keywords</b>:
NVM, NVRAM, data persistency, failure resilience, memory model
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high3292535');">result highlights</a>]</div>
<div class="highlights" id="high3292535" style="display:none">
<strong>Full Text</strong>:<br />
Tree-based Read-only Data <em>Chunks</em> for NVRAM ProgrammingTree-based Read-only Data <em>Chunks</em> for NVRAM ProgrammingKumud BhandariDepartment of Computer ScienceHouston, <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="f2a6978a938199879f879690b2809b9197dc979687a49b849799">[email&#160;protected]</a> SarkarDepartment of ... technology is fast reaching a scaling threshold, emerg-ing non-volatile, byte-addressable <em>memory</em> (NVRAM) is expectedto supplement and eventually replace DRAM. Future computingsystems ... leaving persistent data in an incoherentstate. A fresh look at <em>memory</em> management approaches across thesystem stack is required to fully utilize ... future NVRAM. In this pa-per, we carefully assess the NVRAM-related <em>memory</em> access andmanagement challenges, its implication to application level pro-gramming, and ... read-only datachunks to NVRAM programming.KEYWORDSNVM, NVRAM, data persistency, failure resilience, <em>memory</em> modelACM Reference Format:KumudBhandari andVivek Sarkar. 2016. Tree-based Read-onlyData Chunksfor NVRAM ... physical lim-itations in recent years, researchers have been pursuing variousalternative <em>memory</em> technologies to overcome the current limita-tions. Incidentally, almost all emerging ... almost all emerging next generation memorytechnologies such as Phase Change <em>Memory</em>( (PCM) [17], Memristor[20], and 3D XPoint [15] are non-volatile in ... data stored in DRAM and NVRAM respec-tively. Fig.1 shows the <em>memory</em> hierarchy of future systems withDFM’16, September 15, 2016, Haifa, Israel ... be comparable to current DRAM[2].Today’s conventional approach to managing a <em>memory</em> hierar-chy is less than suitable for fully exploiting the next ... is less than suitable for fully exploiting the next generationnon-volatile <em>memory</em>. . Experts anticipate that NVRAM will scale pastthe current 256 ... such as HP’s“The Machine&quot; [12] is expected to have non-volatile <em>memory</em> spreadacross multiple coherence domains. In the absence of proper pro-gramming ... <br /> ... beingvisible in NVRAM due to a failure. Without the proper <em>memory</em> man-agement framework, this would result in a permanent <em>memory</em> leak.Such permanent <em>memory</em> leaks in NVRAM are more problematic thanin DRAM because they ... irrespective of whether the lineis dirty or cleanTree-based Read-only Data <em>Chunks</em> ... for NVRAM Programming DFM’16, September 15, 2016, Haifa, Israelavoid permanent <em>memory</em> leaks. NVRAM programming libraries, suchas Atlas, require programmers to ensure ... programming libraries, suchas Atlas, require programmers to ensure that all <em>memory</em> allocationsoccur only within a failure-atomic section to avoid <em>memory</em> leaks.Memory leaks due to programming errors are not addressed inmost ... of the NVRAM programming libraries offers asatisfactory solution against permanent <em>memory</em> leaks. Recent workin persistent <em>memory</em> allocator [2] allows garbage collection butas offline post-failure recovery step. ... describe the tree-basedmemory (TBM) hierar-chy and explain how such a <em>memory</em> architecture addresses NVRAMprogramming challenges discussed in 2. HICAMP [6] ... 2. HICAMP [6] and FreshBreeze [11] projects have explored <em>memory</em> organized as a treeof related read-only data <em>chunks</em> in the past. However, previouswork did not focus on systems ... in this section, we present specific cachingpolicies and an automatic <em>memory</em> management scheme suitablefor both transient and persistent <em>memory</em> in the context of TBMarchitecture.3.1 Fixed-size read only data chunksBoth ... and transient data is organized as a fixed size block,called <em>chunks</em>, , where the size of a <em>chunk</em> is the same as the cacheline size. For the purpose ... a 128-byte chunkand cache lines of the same size. Each <em>chunk</em> has a unique identifier,called a handle, associated with it. Throughout ... life time of achunk, a handles is unique to the <em>chunk</em> and valid across the system.This is in contrast with the ... for the life time of theprocess. A thread creates a <em>chunk</em> in a processor’s private transientscratch pad <em>memory</em>, , and only the creating thread can write to ituntil ... allows programmers to explicitly allocate and final-ize persistent or transient <em>chunks</em>. . Once finalized, a 64-bit handle isassigned to the <em>chunk</em>, , and the <em>chunk</em> subsequently becomes read-only. When a finalized <em>chunk</em> is modified by the creator thread or adifferent thread, a ... by the creator thread or adifferent thread, a new resultant <em>chunk</em> with a new <em>chunk</em> handleis created. A 128-byte <em>chunk</em> ... is divided into 16 64-bit slots. Apartfrom a handle, each <em>chunk</em> also has a metadata associated with it. Achunk metadata constitutes ... information stored in the slot, 2)a reference count for the <em>chunk</em> (see 3.3), and 3) a bit indicatingwhether the <em>chunk</em> is transient or persistent. Each slot in a chunkcan have ... tag bits:HANDLE: the 64-bit value is a handle to another <em>chunk</em>, ,DATA: the 64-bit value is non-handle data,LDATA: 32-bit value stored ... stored as rightmost bits, andUNDEF: the slot is unusedRead-only data <em>chunks</em> have immediate consequences to NVRAMprogramming. It makes cache coherence protocol ... architecture for accommodatinga large amount of NVRAM. Copies of read-only <em>chunk</em> referred by aspecific handle may be cached in multiple <em>memory</em> locations acrossthe system, but all copies will have the same ... copies will have the same content. The contentof a new <em>chunk</em> is visible to another thread only when the creatingthread finalizes ... the race condition be-tween read and write access to a <em>chunk</em>. . The use of globally validchunk handle addresses the challenge ... in NVRAM across execution cycles. The read-only natureof the data <em>chunks</em> and the globally valid handle enable sharingof persistent data across ... <br /> <em>memory</em> hierarchyEach processor has a scratch pad <em>memory</em> and relies on a hierarchyof cache for fast access to ... relies on a hierarchyof cache for fast access to primary <em>memory</em> (NVRAM + DRAM), withL1 and L2 caches being private to ... cache. All levels of cache, along with thetransient and persistent <em>memories</em>, , are fully associative. Givena valid handle to a <em>chunk</em>, , an associative unit at each level of thememory hierarchy ... thememory hierarchy maps that handle to the physical location ofthe <em>chunk</em> at that level if the <em>chunk</em> ... is present. A read miss at acertain level in the <em>memory</em> hierarchy prompts the system to fetchthe <em>chunk</em> from the next level and so on. <em>Chunks</em> actively partici-pating in computations are closer to the processors. <em>Chunks</em> at agiven level of cache are replaced using least recently ... of cache are replaced using least recently used policy(LRU). As <em>chunks</em> are read-only, they need not be written back tomain <em>memory</em> when evicted. As a part of finalization step, a chunkis ... written to L1 and all the way to the primary <em>memory</em> (DRAM orNVRAM depending on the type of a <em>chunk</em>) ). It is also cached at eachlevel of the <em>memory</em> hierarchy during the process (write throughpolicy). As a large amount ... during the process (write throughpolicy). As a large amount of <em>memory</em> will be distributed across anumber of <em>memory</em> banks, all last level caches (LLCs) and memorybanks will be ... will be connected by a crossbar switch. When accessing aparticular <em>chunk</em>, , if there is a cache miss at the LLC, ... cache miss at the LLC, bits in thehandle of the <em>chunk</em> indicates the <em>memory</em> bank to which the chunkoriginally belongs (allocated).Given a universally valid ... unit at eachlevel, CPU cycles are not wasted computing effective <em>memory</em> ad-dresses for accessing persistent data. This is in contrast with ... Array as a tree of blocksFailure consistency in the proposed <em>memory</em> architecture can beachieved at no additional cost. Updates to <em>chunks</em> are automaticallyatomic with respect to failure. If a failure occurs ... respect to failure. If a failure occurs before a partiallywritten <em>chunk</em> is finalized, such a <em>chunk</em> is only present in proces-sor’s private scratch-pad and its incomplete ... after a failure. If a handle is returned to the <em>chunk</em> after asuccessful finalization, the <em>chunk</em> is guaranteed to be visible aftera failure in NVRAM due ... accumulated before the cacheline is ultimately written back to the <em>memory</em>. . In TBM architec-ture with read-only data <em>chunks</em>, , we found this not to be the case.All modifications ... found this not to be the case.All modifications to the <em>chunk</em> in scratch-pad <em>memory</em> precedesthe finalization step, and therefore, all updates to a <em>chunk</em> ... is ac-cumulated and written all the way to the primary <em>memory</em> onlyonce (as each <em>chunk</em> is finalized only once). Our experiments alsoconfirm that WT in ... write-through in TBM architecture is cheaperthan the write-back in conventional <em>memory</em> architecture in caseof NVRAM programming, as there is no need ... the case in WB in conventional memorysystem) in WT-enabled TBM.Each <em>memory</em> bank is also backed by a slower archival storage(such as ... would act as an overflow swap space.Similar to the primary <em>memory</em>, , data is stored as <em>chunks</em> with thesame globally valid handle, with associative unit mapping the ... unit mapping the han-dle to the physical location of the <em>chunk</em>. .3.3 Hardware-level automatic memorymanagementIn TBM, two or more <em>chunks</em> do not form a cycle. The handle to achunk is ... cycle. The handle to achunk is only available after that <em>chunk</em> is finalized. Therefore, itcan only be stored in other <em>chunks</em> that are finalized later in timeas illustrated in fig. 3. ... a chunkis persistent or transient. A handle to a persistent <em>chunk</em> can bestored in a transient <em>chunk</em> but not vice-versa. Transient chunksare all automatically reclaimed after a ... after a system restart rendering thetransient handles stored in persistent <em>chunks</em> meaningless.Each <em>chunk</em> has two types of reference count in its metadata:transient and ... reference count in its metadata:transient and persistent. For a transient <em>chunk</em>, ... , the persistent refer-ence count is always 0. A persistent <em>chunk</em> can have non-zero valuesfor both types of reference counts. In ... reference counts. In cases of both, a transient anda persistent <em>chunk</em>, , a chunk’s transient reference (and not the per-sistent reference) ... not the per-sistent reference) is incremented to 1 when the <em>chunk</em> is finalized.When a persistent <em>chunk</em>, <br /> reachable from anotherpersistent <em>chunk</em>, , say p2, the persistent reference count for p1 isincremented ... reference count for p1 isincremented by 1. Likewise, when a <em>chunk</em> (persistent or transient)is shared with another thread, or a reference ... transient)is shared with another thread, or a reference to the <em>chunk</em> is storedin another transient <em>chunk</em>, , its transient reference count increases.Recall that a <em>chunk</em> is private to a thread until it is shared with ... total reference count (sum of transient and persistent)is zero, the <em>chunk</em> is reclaimed, and its handle reused. For each han-dle stored ... and its handle reused. For each han-dle stored in a <em>chunk</em> being reclaimed, the corresponding chunk’spersistent or transient reference count is ... or transient reference count is decremented dependingon whether the reclaimed <em>chunk</em> is transient or persistent, andso on. Reference counted garbage collection ... to perform thegarbage collection work.After a system restart, all transient <em>chunks</em> are reclaimed. Ad-ditionally, a transient reference count for each persistent ... count for each persistent chunkis reset to 0. Any persistent <em>chunk</em> ... with no persistent reference isthen reclaimed. This prevents any persistent <em>memory</em> leaks dueto a failure. Reconsider a scenario described in ... 2.4, where a fail-ure occurs right after a persistent <em>memory</em> allocation. Under thescheme presented here, such <em>chunks</em> will only have a transientreference count which will be zeroed ... persistent root. TBM API provides a method to specify apersistent <em>chunk</em> to be a persistent root. Specifying it as a persistentroot ... by 1, which ensures that thechunk and all other persistent <em>chunks</em> reachable from this chunksurvives a garbage collection after system restart.3.4 ... system restart.3.4 Storing data larger than a chunkIn TBM, all <em>chunks</em> are of a fixed size. Data that does not fit ... a fixed size. Data that does not fit withina single <em>chunk</em> can be stored as a linked-list of <em>chunks</em> or moreeffectively as a multi-way tree of <em>chunks</em>. . Fig.4 shows an array of 32elements being stored as ... an array of 32elements being stored as a tree of <em>chunks</em>. . In this case, a persistentchunk c1 can be considered ... a persistentchunk c1 can be considered the persistent root. Non-leaf <em>chunks</em> c2and c3 store handles to the next level <em>chunks</em>, , while leaf <em>chunks</em> c4 -c11 stores elements of the array.Suppose the 2nd and ... are to be modifiedatomically w.r.t failure. First a new leaf <em>chunks</em> in place of c4 and c11are created with new values ... for 2nd and 31st elements respectively,followed by a new non-leaf <em>chunks</em> ... in place of c2 and c3 containinghandle to new leaf <em>chunks</em> and finally a new root <em>chunk</em>. . If a failureoccurs before a handle to the new ... root is established. The old treeremains intact, while any persistent <em>chunks</em> allocated before thefailure is reclaimed at the restart. Hence, a ... this case atno additional programming or performance cost.Tree-based Read-only Data <em>Chunks</em> for NVRAM Programming DFM’16, September 15, 2016, Haifa, Israel4 LIBRARY-BASED ... September 15, 2016, Haifa, Israel4 LIBRARY-BASED EMULATORProvided that the tree-based <em>memory</em> (TBM) architecture is a drasticdeparture from a conventional architecture, we ... 8 (processor private) L1 cache,a shared L2 cache, a main <em>memory</em> and the archival storage. Wedo not emulate the processors, registers ... of get andput methods as API to store and retrieve <em>chunks</em> in the emulatedmemory architecture. All <em>chunk</em> transfers for a particular workerthread are then carried out through ... cache. Theput methods receive data to be stored in a <em>chunk</em> as well as themetadata information and return a handle to ... well as themetadata information and return a handle to the <em>chunk</em>. . The putmethod essentially writes a new <em>chunk</em> to L1 cache and finalizes it.Likewise, the get methods receive ... finalizes it.Likewise, the get methods receive a handle to the <em>chunk</em> and returnthe <em>chunk</em> ... as well as the metadata associated with it.The size of <em>memory</em> <br /> ... is the same as described in 3.2.The emulated main <em>memory</em> comprises of NVRAM and DRAM. Thechunks are offered to L1 ... is eitherwritten to DRAM or NVRAM based on whether the <em>chunk</em> is persistentor transient as indicated by its metadata bits. The ... L1 cache, the amountof data transferred across each levels of <em>memory</em> hierarchy andreports the statistics at the end of the program ... Ha-banero Java (HJ) [3] provides a suitable programming approach fortree-based <em>memory</em> systems. Our experiments confirm that TBM ar-chitecture combined with HJ ... program using TSPL [3] can have roughly one-to-onecorrespondence with the <em>chunks</em> in a <em>chunk</em> tree representing thedata to be processed. Furthermore, a lightweight task, ... to be processed. Furthermore, a lightweight task, along withthe data <em>chunk</em> related to that task, can be easily migrated to thedesired ... arrayin figure 4, the main task t1 corresponding to the <em>chunk</em> c1 mayspawn and wait for two tasks t2 and t3 ... and wait for two tasks t2 and t3 corresponding to <em>chunks</em> c2and c3 respectively. Tasks t2 and t3 may further spawn ... Each leaf task returns a handle for a newresultant leaf <em>chunk</em> to its parent task. Parent tasks at each levelaccumulate returned ... task. Parent tasks at each levelaccumulate returned handles into a <em>chunk</em> and finally the main taskreturns a new root handle for ... taskreturns a new root handle for the new tree.5.1 In <em>memory</em> key-value storeWe implemented the B-tree based in-<em>memory</em> persistent key-valuestore. We treated each <em>chunk</em> as a node in a B-tree. For the purposeof convenience, ... versions of B-tree related algorithms[9]. The B-tree nodes correspond to <em>chunks</em> in the emulator.5.2 Matrix multiplicationMatrix multiplication is an important part ... someeffort. However, tree-based and tile-based recursive layout of matrixin conventional <em>memory</em> architecture for high cache locality andhigh performance have been extensively ... base tile in our case matched the size of a <em>chunk</em>. . We then usedvarious layout based on space filling curves, ... by an appropriate compiler inthe future.6 RELATEDWORKWork on Fresh Breeze <em>memory</em> architecture [11] is most closelyrelated to our work. HICAMP [6] ... is most closelyrelated to our work. HICAMP [6] is another <em>memory</em> architecturethat is based on read-only data <em>chunks</em>. . Both of these line of workis not pursued with ... a focus. As a result,these previous work on tree based <em>memory</em> architecture lack theassessment of challenges posed by future NVRAM technologies ... deal with the challenges such asfailure induced data inconsistencies and <em>memory</em> leaks.To make NVRAM programming more accessible, previous workssuch as Atlas ... programming challenges discussed in 2,such as cache coherence, persistent <em>memory</em> addressing, persistentmemory garbage collection, and scalability. Other work on NVRAMsuch ... <br /> <em>memory</em> for general-purpose in-placepersistence programming.7 EVALUATIONWe evaluated the proposed tree-based <em>memory</em> (TBM) architectureby collecting statistics on data transfers among various <em>memory</em> hi-erarchies using the emulator described in 4. To study ... described in 4. To study its character-istic difference in <em>memory</em> performance compared to conventionalarchitecture, we extended and used MESI coherence ... coherence protocol cacheemulator, MultiCacheSim [18]. It performs PIN-based instrumen-tation of <em>memory</em> accesses and simulates assigned number of L1cache and assigns <em>memory</em> accesses to the L1 caches based on theid of the ... caches based on theid of the thread that originated the <em>memory</em> access. Specifically, weextended MultiCacheSim to emulate cache line flushes. Althoughwe ... flushes. Althoughwe studied data transfers at each level of the <em>memory</em> for TBM, weonly present here the L1 cache performance due ... back policy. This settingresembles L1 caches in most common conventional <em>memory</em> archi-tecture. In MultiCacheSim, a cache line flush command resemblesthe Intel ... behavior [16], i.e. it evicts and invalidates acache line.7.1 Transient <em>memory</em> programsWe first used transient implementation of matrix multiplicationalgorithms and layouts ... for standard matrixmultiplication using Hilbert layout. We implemented a conven-tional <em>memory</em> version of this algorithm and layout. In conventionalmemory version, base ... comparison of conventional versionwith TBM emulation, we only emulated the <em>memory</em> access to theoperand and resultant matrix elements using address filtering. ... increasing number of L1 cachesas shown in fig. 6d.7.2 Persistent <em>memory</em> programsWe used in-<em>memory</em> ... persistent key-value store described in 5.1to compare the persistent <em>memory</em> program cache performancebetween TBM and conventional <em>memory</em> architecture. We comparethe the performance of our implementation of key-value ... store (see 5.1) running on TBM emulator with the persistent in-<em>memory</em> ver-sion of MDB[7] implemented using Atlas [4]. MDB is a ... updates to persistent data in MDB. For emulation purpose, wecaptured <em>memory</em> accesses to the B-tree in both architectures andadditional transactional logs ... in TBM.8 CONCLUSIONSWe have presented an evaluation of a tree-based <em>memory</em> withread-only <em>chunks</em> as the <em>memory</em> hierarchy for future systemswith NVRAM. Together with task structured parallel ... promising.REFERENCES[1] Kumud Bhandari. 2015. Evaluating the programmability and scalability of <em>memory</em> <br /> ... Chakrabarti, and Hans-J. Boehm. 2016. Makalu:Fast Recoverable Allocation of Non-volatile <em>Memory</em>. . In Proceedings of the 2016ACM SIGPLAN International Conference on ... Hans-J. Boehm, and Kumud Bhandari. 2014. Atlas:Leveraging Locks for Non-volatile <em>Memory</em> Consistency. In Proceedings of theOOSPLA’14. ACM, 433–452.[5] Siddhartha Chatterjee and ... the 11th SPAA. ACM, New York, NY, USA,Tree-based Read-only Data <em>Chunks</em> for NVRAM Programming DFM’16, September 15, 2016, Haifa, Israel(a) Total ... Matrix size = 1024 1024 64-bit integers. TBM=tree based <em>memory</em>, , Conv=conventional arch.222–231.[6] David Cheriton and et. al. 2012. HICAMP: ... of the 17thASPLOS. ACM, 287–300.[7] Howard Chu. 2011. MDB: A <em>Memory</em>- -Mapped Database and Backend for OpenL-DAP. 3rd Int’l Conf. on ... 2011. NV-Heaps: Making Persistent ObjectsFast and Safe with Next-generation, Non-volatile <em>Memories</em>. . In Proceedings ofthe Sixteenth International Conference on Architectural Support ... Engin Ipek, Onur Mutlu, and Doug Burger. 2009. ArchitectingPhase Change <em>Memory</em> As a Scalable Dram Alternative. In Proc. of the 36th ... 2016. MulticacheSim. https://github.com/blucia0a/MultiCacheSim[19] PMDK Team @ Intel. 2016. Pmem.io: Persistent <em>Memory</em> Programming. http://pmem.io/[20] Dmitri B. Strukov and et. al. 2008. The ... Jaan Tack, and Michael M. Swift. 2011. Mnemosyne: Light-weight Persistent <em>Memory</em>. . In Proceedings of the Sixteenth International Conferenceon Architectural Support ... = 2,097,151 32-bit random keys with 32-bit corresponding values.TBM=tree based <em>memory</em>, , Conv=conventional arch.Abstract1 Introduction2 NVRAM programming challenges2.1 Failure consistency overhead ... overhead and complexity2.2 Persistent data across multiple coherence domain2.3 Persistent <em>memory</em> addressing2.4 Dynamic management of persistent memory3 Tree-based memory3.1 Fixed-size read ... memory3 Tree-based memory3.1 Fixed-size read only data chunks3.2 Fully associative <em>memory</em> hierarchy3.3 Hardware-level automatic <em>memory</em> management3.4 Storing data larger than a chunk4 Library-based emulator5 Programmability ... a chunk4 Library-based emulator5 Programmability of tree based memory5.1 In <em>memory</em> key-value store5.2 Matrix multiplication6 Related Work7 Evaluation7.1 Transient <em>memory</em> programs7.2 Persistent <em>memory</em> <br /> ... this paper is to demonstrate that the Freshbreeze-inspired [11] tree-based <em>memory</em> (TBM) architecture (with read-only data blocks) along with a suitable ... blocks) along with a suitable caching policy and an auto-matic <em>memory</em> management scheme can support persistence as afirst-class citizen within a ... challenges associatedwith NVRAM systems,• preliminary feasibility study of a tree-based <em>memory</em> archi-tecture in the context of NVRAM,• an appropriate caching policy ... policy and a scheme for automaticmanagement of persistent and transient <em>memory</em> in the con-text of a TBM architecture, and• a library-based ... Failure consistency overhead andcomplexityGiven volatile caches, and CPU reordering of <em>memory</em> writes, up-dates to persistent data may not appear in correct ... a simple program in fig. 2. In this example, somepersistent <em>memory</em> is being allocated, initialized, and published(made reachable from some persistent ... inconsistentdue to a persistent pointer, p_root, referring to an uninitializedpersistent <em>memory</em> location upon a restart.1: int t[]=nvm_new int[5];2: initialize (t);3: p_root ... across multiple coherencedomainGiven the anticipated size of the available persistent <em>memory</em> infuture systems, it is likely that data will be spread ... updatesto persistent data across multiple coherence domains in futuresystems.2.3 Persistent <em>memory</em> addressingIn NVRAM, data is stored in the same format as ... <br />
<br />
<strong>Abstract</strong>:<br />
... technology is fast reaching a scaling threshold, emerging non-volatile, byte-addressable <em>memory</em> (NVRAM) is expected to supplement and eventually replace DRAM. Future ... persistent data in an incoherent state. A fresh look at <em>memory</em> management approaches across the system stack is required to fully ... future NVRAM. In this paper, we carefully assess the NVRAM-related <em>memory</em> access and management challenges, its implication to application level programming, ... level programming, and examine the suitability of tree-based read-only data <em>chunks</em> <br />
<br />
<strong>References</strong>:<br />
Kumud Bhandari. 2015. Evaluating the programmability and scalability of <em>memory</em> hierarchies with read-only data blocks. Master's thesis. Rice University, Houston, Texas. <br /> Kumud Bhandari, Dhruva R. Chakrabarti, and Hans-J. Boehm. 2016. Makalu: Fast Recoverable Allocation of Non-volatile <em>Memory</em>. In Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA 2016). ACM, New York, NY, USA, 677--694. https://doi.org/10.1145/2983990.2984019 <br /> Dhruva R. Chakrabarti, Hans-J. Boehm, and Kumud Bhandari. 2014. Atlas: Leveraging Locks for Non-volatile <em>Memory</em> Consistency. In Proceedings of the OOSPLA'14. ACM, 433--452. <br /> Howard Chu. 2011. MDB: A <em>Memory</em>-Mapped Database and Backend for OpenL-DAP. 3rd Int'l Conf. on LDAP(LDAPCon) (Oct. 2011). <br /> Joel Coburn, Adrian M. Caulfield, Ameen Akel, Laura M. Grupp, Rajesh K. Gupta, Ranjit Jhala, and Steven Swanson. 2011. NV-Heaps: Making Persistent Objects Fast and Safe with Next-generation, Non-volatile <em>Memories</em>. In Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS XVI). ACM, New York, NY, USA, 105--118. <br /> Benjamin C. Lee, Engin Ipek, Onur Mutlu, and Doug Burger. 2009. Architecting Phase Change <em>Memory</em> As a Scalable Dram Alternative. In Proc. of the 36th ISCA. ACM, 2--13. <br /> PMDK Team @ Intel. 2016. Pmem.io: Persistent <em>Memory</em> Programming. http://pmem.io/ <br /> Haris Volos and et. al. 2014. Aerie: Flexible File-system Interfaces to Storage-class <em>Memory</em>. In Proceedings of the 9th Eurosys. ACM, Article 14, 14:1-14:14 pages. <br /> Haris Volos, Andres Jaan Tack, and Michael M. Swift. 2011. Mnemosyne: Lightweight Persistent <em>Memory</em>. In Proceedings of the Sixteenth International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS XVI). ACM, New York, NY, USA, 91--104. <br />
<br />
<strong>Keywords</strong>:<br />
<em>memory</em> model <br />
<br />
<strong>Title</strong>:<br />
Tree-based Read-only Data <em>Chunks</em> for NVRAM Programming <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
10
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=644218" target="_self">Implicit dictionaries supporting searches and amortized updates in <i>O</i>(log <i>n</i> log log <i>n</i>) time</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81100130093">Gianni Franceschini</a>,
<a href="author_page.cfm?id=81100592374">Roberto Grossi</a>
</div>
<div class="source">
<span class="publicationDate">January 2003</span>
<span style="padding-left:10px">SODA '03: Proceedings of the fourteenth annual ACM-SIAM symposium on Discrete algorithms</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;Society for Industrial and Applied Mathematics
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 8</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;1</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;3</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;313</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=644218&ftid=149596&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
We describe a new implicit data structure for maintaining n data values in the first n locations of an array. No information other than n and the data is to be retained, and the only operations which we may perform on the data values (other than reads and writes) are ...
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high644218');">result highlights</a>]</div>
<div class="highlights" id="high644218" style="display:none">
<strong>Full Text</strong>:<br />
... time, the keys in our data structure are grouped into <em>chunk</em> of k = O(logN) = O(logn) keys each. Each <em>chunk</em> contains (pairwise permuted) keys from a certain interval of values, ... (pairwise permuted) keys from a certain interval of values, and <em>chunks</em> are pairwise disjoint as intervals. This allows us to define ... to define a total order on any set of the <em>chunks</em>. . Our data structure hinges on a known tree orga- ... equal sets. Given n keys, we or- ganize them into <em>chunks</em> as described above. We select O(vZn) <em>chunks</em> as in distribution sorting, and distribute the remaining <em>chunks</em> in buckets. The selected <em>chunks</em> are stored in the root, and the buckets are recursively ... the recursion as soon as the bucket size is O(1) <em>chunks</em>. . These buckets are stored in the leaves of the ... tree satisfies the following properties: 1. The root contains r <em>chunks</em> such that 1 &lt; r &lt; 4/~0. 2. An arbitrary ... An arbitrary node at level i &gt; I containing r <em>chunks</em> satisfies fli _&lt; r &lt; 4j~i 3. An arbitrary leaf ... _&lt; r &lt; 4j~i 3. An arbitrary leaf contains r <em>chunks</em> plus at most k - 1 spare keys, where b ... nodes are of variable size depending on their level. The <em>chunks</em> are the basic items encoding the pointers to children in ... data structure. A crucial component of our solution is the <em>memory</em> layout of the nodes to support the amortized updates. In ... amortized updates. In particular, we keep some invariants on the <em>chunks</em> (and their encoded pointers to the children) in the nodes ... so that, given an internal node u, we classify its <em>chunks</em> as being actual and virtual (leaves are only made of ... being actual and virtual (leaves are only made of actual <em>chunks</em>) ). The actual <em>chunks</em> physically reside inside the <em>memory</em> area allocated to u, while the virtual <em>chunks</em> are interleaved with the latter <em>chunks</em>, ... , but stored independently in another special area of the <em>memory</em>. . From a logical point of view, node u is ... node u is the merge of the two kinds of <em>chunks</em>, , and so a simple variant of the binary search ... to route the keys to its children. We introduce virtual <em>chunks</em> to accumulate enough potential in the amortized insertions, so as ... to absorb the cost of reallocating u to a larger <em>memory</em> area. We need therefore to store virtual <em>chunks</em> in a common area shared by all nodes so as ... so as not to change frequently the number of actual <em>chunks</em> during the insertions. We further classify actual <em>chunks</em> into original and patch to accumulate operations for the amortized ... that we postpone the reallocation of u in a smaller <em>memory</em> area. The invariants on all these <em>chunks</em> guarantee a correct balance, so that amortization can work in ... searches, and introduce the mathematical definition of actual and virtual <em>chunks</em>. . In Section 3, we then consider the full case ... dictionary supporting insertions, deletions and searches, introducing original and patch <em>chunks</em> and their invari- ant. In Section 4, we provide the ... how to deal also with deletions. 2.1 Actual and virtual <em>chunks</em>. . <em>Chunks</em> are at the heart of our data structure as they ... a suitable permutation of their keys. We need to classify <em>chunks</em> according to their 672 physical allocation in <em>memory</em>. . The <em>chunks</em> that are stored in the <em>memory</em> area allocated to a node v are called actual. We ... to a node v are called actual. We also employ <em>chunks</em> <br /> ... with that node v, but are stored in a separate <em>memory</em> area (note that we do not need virtual <em>chunks</em> in the leaves). We denote the set of actual <em>chunks</em> by act(v) and the set of virtual <em>chunks</em> by vir(v). The former can be retrieved by accessing v. ... latter is represented by a doubly linked list of virtual <em>chunks</em>, , in which the pointer to the head of the ... beginning of node v, and the pointers to the adjacent <em>chunks</em> of c ~ E vir(v) are encoded in c ~ ... ~ E vir(v) are encoded in c ~ itself. Actual <em>chunks</em> and virtual <em>chunks</em> are related, so that 1. each <em>chunk</em> c E act(v) has associated at most one <em>chunk</em> c' E vir(v), with a pointer to d being encoded ... (hence, c ~ cannot be the successor of another virtual <em>chunk</em> in v). As a result, the <em>chunks</em> in act(v) and vir(v) are inter- leaved and encodes the ... 1). We preserve an invariant on the number of actual <em>chunks</em> and virtual <em>chunks</em>. . Recall from Section 1.1 that the actual <em>chunks</em> satisfy the conditions 1 &lt; lact(v)[ &lt; 4f10 for i ... a multiple of v f~ -. As for the virtual <em>chunks</em>, , they satisfy ~ &lt; Ivir(v)l &lt; 4x/~- for i ... size of v as the number lact(v)l of its actual <em>chunks</em> (intuitively, changing their number causes a relocation). 2.2 Routing and ... the set act(v), which is available inside v. Once a <em>chunk</em> c E act(v) is identified by the search, we access ... is identified by the search, we access its as- sociated <em>chunk</em> c t E vir(v) (if any) in O(logn) time and ... vir(v). We anticipate that the layout of node v in <em>memory</em> can store act(v) in O(1) <em>memory</em> areas, but this is not much a problem as it ... dictionary requires O(log n log logn) time. 2.3 Layout in <em>Memory</em> ... . We now detail how the nodes and the virtual <em>chunks</em> are allocated in <em>memory</em>. . We divide the <em>memory</em> in O(h) zones: • Zone P has the only purpose ... i &lt; h. • Zone V storing all the virtual <em>chunks</em> at the several levels. The zones in the <em>memory</em> layout appear in the order given by P, Z1, Z2, ... nodes at level i in compacted lists. We encode the <em>memory</em> address of zone Zi and the value of j3i in ... j3i in zone P. Knowing that the number of actual <em>chunks</em> in each node is a multiple of ~ ranging from ... We therefore keep so many lists for their storage in <em>memory</em>, , where doubly linked list j (0 &lt; j &lt; ... jv f~ - + fli into allocation units of f~i <em>chunks</em> each (a node can be stored in more than one ... single sequence). Note that Hi contains at most (3vf~- 1)~i <em>chunks</em>. . We refer the reader to the compactor lists described ... of O(vf~ -) heads, each containing a multiple of actual <em>chunks</em>. . Each such head is kept fragmented into O(x/~-) pieces ... is kept fragmented into O(x/~-) pieces of ~ linked actual <em>chunks</em>, , so that relocation takes O (~3i k) time plus ... time for redirecting O(v /~ -) pointers. Next in the <em>memory</em> layout, we have zone V for the virtual <em>chunks</em>. . This is a simple sequence of allocation units, each ... a simple sequence of allocation units, each containing exactly one <em>chunk</em>. . Its starting 673 ! ! Cq-2 cq -1 F ... F W V Figure 1: The set act(v) of actual <em>chunks</em> (top row) and the set vir(v) of virtual <em>chunks</em> (bottom row) in a node v, along with their encoded ... <br /> We refer to the number q of actual <em>chunks</em> in C as the length of C, denoted by [C ... the invariant that it satisfies on the number of virtual <em>chunks</em> (see Section 2.1). Let c be the <em>chunk</em> that must be inserted into v and has been originated ... Increasing the number o f v i r tua l <em>chunks</em>. . This case holds when the number of virtual <em>chunks</em> Ivir(v)] &lt; 4x/~- is not maximal. We have room for ... maximal. We have room for at least one more virtual <em>chunk</em>, , and we do not change the number lact(v)l of ... and we do not change the number lact(v)l of actual <em>chunks</em>. . We find the actual <em>chunk</em> p that is the predecessor of c in node v ... at p (by definition of chain, cq_l has no virtual <em>chunk</em> associated). We find the position of c in C (either ... obtain a sorted sequence S, which is the sequence of <em>chunks</em> in C with c added in its suitable position. At ... from S to replace C with C ~ in the <em>memory</em> layout. Namely, the <em>chunks</em> in odd positions become actual and those in even positions ... that ICI = IC~I, that is, the number of actual <em>chunks</em> in chains C and C ~ does not change (although ... 1). After this operation, we preserve the invariant on virtual <em>chunks</em> defined in Section 2.1. Since the total number of <em>chunk</em> involved in chains C and C ~ is at most ... C ~ is at most twice the number of virtual <em>chunks</em>, , we have: LEMMA 2.3. The cost for increasing the ... LEMMA 2.3. The cost for increasing the number of virtual <em>chunks</em> in a node at level i is O(vf~-k) time. Increasing ... level i is O(vf~-k) time. Increasing the number of actual <em>chunks</em>. . This case applies when the number of virtual <em>chunks</em> is maximal Ivir(v)l = 4~/~-, while the number r _&lt; ... 4~/~-, while the number r _&lt; 4fli - of actual <em>chunks</em> is not maximal in node v. In this case, we ... and we increase the size of v by ~ actual <em>chunks</em>, , which are chosen from the virtual <em>chunks</em> available in v. After restructuring, node v contains r + ... v. After restructuring, node v contains r + ~- actual <em>chunks</em> and 3x/~- virtual <em>chunks</em>. . Now we can resume the insertion of c in ... described in the previous paragraph, increasing the number of virtual <em>chunks</em> by 1. We detail how to add v~- actual <em>chunks</em> to v. We first select ~ virtual <em>chunks</em> in v, which are all in zone V as described ... filling the ~ slots left empty by the selected virtual <em>chunks</em> with other <em>chunks</em> in V (the first rE - remaining ones in it). ... it). As a result, we shrink zone V by v~- <em>chunks</em> to the left. Now, zone Zh-~ preceding zone V has ... has its part Hi enlarged to host the ~ selected <em>chunks</em>. . They are turned into actual <em>chunks</em> in node v. We then reorganize part Hi as described ... Hi as described in Section 2.4. The relocation of ~ <em>chunks</em> in zone V requires to perform so many searches to ... searches to locate the nodes having them associated as virtual <em>chunks</em>. . We also need to perform further O(1) searches to ... LEMMA 2.4. The cost for increasing the number of actual <em>chunks</em> in a node at level i is O(~ik-t- v~- log ... t ing. The last case is when both the actual <em>chunks</em> and the virtual <em>chunks</em> are maximal in number (i.e., lact(v)l = 4fli and Ivir(v)l ... (i.e., lact(v)l = 4fli and Ivir(v)l = 4vf~-). We insert <em>chunk</em> c in node v, and we take the median <em>chunk</em> m in the set act(v) U vir(v) U {c}, and ... two nodes v' and v&quot;, each node with 2fii actual <em>chunks</em> and 2Vr~/ virtual <em>chunks</em>. . In general, the actual <em>chunks</em> and the virtual <em>chunks</em> are not so evenly partitioned. Without getting into detail, we ... into detail, we redistribute them evenly by in-place merging the <em>chunks</em> in act(v) U vir(v) tO {c} - {m}. The total ... <br /> ... 1)k keys. We are in the situation in which a <em>chunk</em> c of an internal node v must be moved to ... ing the number o f v i r tua l <em>chunks</em>. . This case holds when the number of virtual <em>chunks</em> Ivir(v)l &gt; ~ is not minimal. Hence, we can remove ... &gt; ~ is not minimal. Hence, we can remove virtual <em>chunks</em> without changing the number l act(v)l of actual <em>chunks</em>. . If c is virtual, we can safely remove it ... c is actual (original or patch) and has a virtual <em>chunk</em> c ~ associated, we can remove c and replace it ... a problem when c is actual but has no virtual <em>chunk</em> associated. We have two cases. 1. If c is patch, ... is patch, we remove it and replace with any virtual <em>chunk</em> c ~ of v. Then, we insert c ~ in ... contains at most Ipat(v)l &lt; Iseg(v)l + ~ = O(~/~-) <em>chunks</em>, , we can (in-place) redistribute them in the segments of ... c, and slide c to the end of the original <em>chunks</em> in z, so that z contains first all the original ... original except c, then c, and finally all the patch <em>chunks</em>. . At this point, we remove c from z and ... remove c from z and replace it with any virtual <em>chunk</em> c ~ of v. We then turn c ~ into ... that, in case 2, we increase the number of patch <em>chunks</em> in v by 1. If invariant (I1) is violated in ... node v, merging (in- place) the original and the patch <em>chunks</em> and their virtual <em>chunks</em>, , and redistributing the <em>chunks</em> in the segments of v, so that we preserve the ... of v, so that we preserve the number of virtual <em>chunks</em> and actual <em>chunks</em>, , and we only leave one patch <em>chunk</em> in the last position of each segment to maintain the ... LEMMA 3.2. The cost for decreasing the number of virtual <em>chunks</em> in a node at level i is O(x/~-k) time. If ... O(~ik) time. Decreas ing the number of ac tua l <em>chunks</em>. . This case applies when the number of virtual <em>chunks</em> is minimal Ivir(v)l = ~/~-, while the number r &gt;_ ... while the number r &gt;_ fli + 677 of actual <em>chunks</em> is not minimal in node v. In this case, we ... and we decrease the size of v by ~ actual <em>chunks</em>, , which become virtual <em>chunks</em> in v. After restructuring, node v contains r - ~ ... v. After restructuring, node v contains r - ~ actual <em>chunks</em> and 2x/~- virtual <em>chunks</em>. . Now we can resume the deletion of c in ... described in the first case (decreasing the number of virtual <em>chunks</em>) ), decreasing the number of virtual <em>chunks</em> by 1. Making ~ actual <em>chunks</em> virtual, requires a reorganization of the <em>memory</em> layout symmetrical to what discussed in the second case of ... LEMMA 3.3. The cost for decreasing the number of actual <em>chunks</em> in a node at level i is O(/3ik + log ... 2) time. Merging. This case holds when both the actual <em>chunks</em> and the virtual <em>chunks</em> are minimal in number (i.e., lact(v)l = j3i and Ivir(v)l ... v' of v that satisfies the same conditions on its <em>chunks</em>. . Let d be the <em>chunk</em> in the common parent that separates v from v ~. ... from the parent, and merge (in-place) c' and all the <em>chunks</em> (actual and virtual) in v ~ and in v, except ... node from v and v ~, and redistribute the sorted <em>chunks</em> in the segments of the new node, so that we ... the new node, so that we assign 2vf~ - virtual <em>chunks</em> and 2fli actual <em>chunks</em>, , leaving one patch <em>chunk</em> in the last position of each segment to maintain the ... of the previous three cases holds. Namely, both the actual <em>chunks</em> and the virtual <em>chunks</em> in v are minimal in number (i.e., lact(v)l = fli ... (say to the right) has more than fli + V~&quot; <em>chunks</em>. . Let fi be the <em>chunk</em> in the common parent that separates v from v t. ... described in the first case (decreasing the number of virtual <em>chunks</em>) ). After that, v has v f~ - - 1 ... After that, v has v f~ - - 1 virtual <em>chunks</em>. . We then identify the minimal <em>chunk</em> c ~ (actual or virtual) in v ~, and remove ... <br /> ... time. The best known bound for these operations in main <em>memory</em> is O(log 2 n~ log log n) in the worst ... the best space saving possible, that is, they occupy no <em>memory</em> cells besides those needed for the distinct keys and the ... In other words, if we take a snapshot of the <em>memory</em>, , we just see the n distinct keys permuted in ... just see the n distinct keys permuted in n consecutive <em>memory</em> cells (no empty cells can be interspersed), assuming that each ... fully encode the resulting implicit data structure at no extra <em>memory</em> cost. This class of data structures are known in the ... a previous work [1], an implicit data structure for two-level <em>memory</em> requires O(log B n) block transfers per operation in the ... transfer size is B = ~(logn). Using it in main <em>memory</em> with B -- O(logn), it provides a bound of O(log ... height of o(log n) while allocating variable-size nodes in compact <em>memory</em> lists of fixed-size allocation units. We exploit the latter fea- ... amortized updates in main mem- ory. When used in external <em>memory</em>, , our solution does not improve the worst-case bounds in ... are a significant improvement over the worst-case bounds in main <em>memory</em> of O(log 2 n) in [4] and of O(log 2 ... data structures, amortized updating may require the usage of additional <em>memory</em>, , which we can avoid in our case. 1.1 Overv ... <br /> ... that the allocation unit of the lists is exactly one <em>chunk</em> of k keys and the number of these lists is ... the successor of c and the 2. In node v, <em>chunk</em> c 1 predecessor of c~; <em>chunk</em> c~ is the successor of cj-1 and the predecessor of ... j, for 2 &lt; j &lt; q - 1. 3. <em>Chunk</em> cq-1 has no virtual <em>chunk</em> associated with it (i.e., its successor is another actual <em>chunk</em>, <br /> ... in the data structure presented in Section 2. The virtual <em>chunks</em> can mostly help us in handing deletions. Unfortunately, this is ... is not the case when merging two nodes with the <em>chunk</em> c removed from their parent, and c is actual with ... their parent, and c is actual with no associated virtual <em>chunk</em>. . In this case, we cannot find easily a replacement ... this case, we cannot find easily a replacement for that <em>chunk</em> in the parent node, and we must completely reorganize it ... size of the internal nodes, i.e., their number of actual <em>chunks</em>) ). This enforces an update of the layout, as described ... in Section 2.4, that we cannot amortize. We introduce patch <em>chunks</em> as replacements when this kind of situation arises. 3.1 Extens ... . Given an internal node v, we divide its actual <em>chunks</em> in a set seg(v) made up of segments, each of ... set seg(v) made up of segments, each of ~ adjacent <em>chunks</em> (recall that the size of v is multiple of v~/', ... is further divided in two parts, one storing the actual <em>chunks</em> called original and the other the actual <em>chunks</em> called patch (see Figure 3). We denote by orig(v) the ... Figure 3). We denote by orig(v) the set of original <em>chunks</em> in all segments of v, and by pat(v) the set ... of v, and by pat(v) the set of all patch <em>chunks</em> in those segments. Note that each of these sets is ... v: (I1) Ipat(v)l &lt; Iseg(v)l + viE-; (I2) the first <em>chunk</em> of z is in orig(v) and the last <em>chunk</em> of z is in pat(v). Note that each segment z ... two parts, with the left part storing only the original <em>chunks</em> and the right part storing only the patch <em>chunks</em>. . Moreover, we encode in the first <em>chunk</em> of z the last position in z occupied by an ... z the last position in z occupied by an original <em>chunk</em>. . Since we keep orig(v) and pat(v) sorted indepen- dently ... pat(v) sorted indepen- dently of each other, we associate virtual <em>chunks</em> with each of them separately. In particular, orig(v) and its ... each of them separately. In particular, orig(v) and its virtual <em>chunks</em> satisfy properties 1-2 of the invariant de- scribed in Section ... Section 2.1, as well as do pat(v) and its virtual <em>chunks</em>. . Note that orig (v)Upat(v) and the union of their ... Note that orig (v)Upat(v) and the union of their virtual <em>chunks</em> do not necessarily satisfy that invariant. When needed, we can ... run an in-place merge and a redis- tribution of the <em>chunks</em> to satisfy the invariant globally in the node v at ... in Section 2.5, applied to either orig(v) and its virtual <em>chunks</em> or to pat(v) and its virtual <em>chunks</em>. . In order to route keys in the new organization ... perform first a binary search on orig(v) and its virtual <em>chunks</em>, , and then another binary search on pat(v) and its ... and then another binary search on pat(v) and its virtual <em>chunks</em>. . As <em>chunks</em> are disjoint, either we end up inside a <em>chunk</em> and we stop the search, or we have to access ... (see Section 2.5). (a) If the total number of virtual <em>chunks</em> is not maximal, we find a 676 segment z r ... segment z r Figure 3: A partition of the actual <em>chunks</em> in segment z into original <em>chunks</em> (left) and patch <em>chunks</em> (right), shown in the top row. Their associated virtual <em>chunks</em> are shown in the bottom row. chain either in orig(v) ... pat(v), and proceed analo- gously by adding one more virtual <em>chunk</em>. . (b) If the total number of virtual <em>chunks</em> is maximal but the number of actual <em>chunks</em> is not maximal, we proceed as before by adding ~ ... not maximal, we proceed as before by adding ~ virtual <em>chunks</em>. . (c) Splitting does not vary. In addition to cases ... to cases (b) and (c), we turn all the patch <em>chunks</em> in the node into original and distribute them in the ... them in the segments of the node, except the last <em>chunk</em> in each segment (which remain patch to reflect the invariant ... of the tree like in the search, eventually finding the <em>chunk</em> of a node u in which the key must be ... the key must be deleted. We remove x from the <em>chunk</em> and, if u is not a leaf, we insert in ... if u is not a leaf, we insert in the <em>chunk</em> the smallest key in the leftmost (or rightmost, depending on ... case) leaf descending from the right pointer encoded in the <em>chunk</em> (and delete that key from the leaf). As a result, ... <br /> discussed (decreasing the number of virtual <em>chunks</em>, , or decreasing the number of actual <em>chunks</em>) ). We replace with d in the common parent of ... described in the first case (increasing the number of virtual <em>chunks</em>) ) of Section 2.5. As a result, v ~ has ... Section 2.5. As a result, v ~ has one less <em>chunk</em>, , the common parent of v and v' does not ... not change the number of its actual (original and patch) <em>chunks</em> and their virtual <em>chunks</em>, , satisfying the invariants (I1) and (I2) of Section 3.1. ... and (I2) of Section 3.1. Finally, v has ~ virtual <em>chunks</em> and ~i actual <em>chunks</em>. . The cost of sharing depends on how d is ... same time complexity of either decreasing the number of virtual <em>chunks</em> (Lemma 3.2) or decreasing the number of actual <em>chunks</em> (Lemma 3.3). Being more explicit, the time bound implied by ... by Lemma 3.5 is 1. O(~/~-k) when v borrows a <em>chunk</em> from v' by decreasing the number of virtual <em>chunks</em> in v ' under invariant (I1); 2. O(flik) when v ... ' under invariant (I1); 2. O(flik) when v borrows a <em>chunk</em> ... from v ~ by decreas- ing the number of virtual <em>chunks</em> in v ~ under invari- ant (I2); 3. O(~ik + ... O(~ik + vf~' logn( loglogn) 2) when v borrows a <em>chunk</em> from v ~ by decreasing the number of actual <em>chunks</em> in v ~. 4 Amort i zed Analysis In this ... log n log log n be the &quot;potential&quot; of a <em>chunk</em> of k keys. In the formula for ~(v), we denote ... by J / (v) the potential provided by the actual <em>chunks</em>, , having value c11~i7 for a constant cl when the ... having value c11~i7 for a constant cl when the actual <em>chunks</em> are minimal or maximal, and having value 0 when they ... denote by ~ (v) the potential provided by the virtual <em>chunks</em>, , having value C2~i7 for a constant c2 when the ... having value C2~i7 for a constant c2 when the virtual <em>chunks</em> are minimal or maximal, and having value 0 when they ... 2v~, We denote by ~i(v) the potential for the patch <em>chunks</em> having value 0 when they are minimal ([pat(v) = 678 ... stop splitting as we can increase the number of actual <em>chunks</em> of v (see Section 2.5). In the following, we denote ... - ~ since we can increase the number of actual <em>chunks</em> by hypothesis. Assuming without loss of generality that r &gt; ... <br />
<br />
<strong>Abstract</strong>:<br />
... time. The best known bound for these operations in main <em>memory</em> <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
11
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=3325834" target="_self">SS-CDC: a two-stage parallel content-defined chunking for deduplicating backup storage</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=99659060647">Fan Ni</a>,
<a href="author_page.cfm?id=99659375295">Xing Lin</a>,
<a href="author_page.cfm?id=99659443413">Song Jiang</a>
</div>
<div class="source">
<span class="publicationDate">May 2019</span>
<span style="padding-left:10px">SYSTOR '19: Proceedings of the 12th ACM International Conference on Systems and Storage</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
 <div><span class="citedCount">Citation Count: 0</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;15</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;37</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;37</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=3325834&ftid=2063361&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Data deduplication has been widely used in storage systems to improve storage efficiency and I/O performance. In particular, content-defined variable-size chunking (CDC) is often used in data deduplication systems for its capability to detect and remove duplicate data in modified files. However, the CDC algorithm is very compute-intensive and inherently ...
</div>
<div class="kw">
<b>Keywords</b>:
content-defined-chunking (CDC), deduplication, storage
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high3325834');">result highlights</a>]</div>
<div class="highlights" id="high3325834" style="display:none">
<strong>Full Text</strong>:<br />
... how a data insertion changes the segment bound-aries and thus <em>chunk</em> boundaries, leading to the failure indetecting identical data in the ... indetecting identical data in the second segment using thesegment-based parallel <em>chunking</em> approach. Hash values forrolling windows at offsets B1, B2, ..., ... match the predefined value and thus these offsets maypotentially be <em>chunk</em> boundaries. Before the insertion, B′4, B′5,B′6, and B′7 are too ... B′5,B′6, and B′7 are too close to their respective previous <em>chunks</em>( (within the minimum <em>chunk</em> size) and thus were not selectedas <em>chunk</em> boundaries. Instead, B4, B5, and B6 were selected.After the insertion ... number of bytes. Now B′4, B′5, B′6, and B′7become valid <em>chunk</em> boundaries and accordingly invalidateoriginal <em>chunk</em> boundaries at offsets B4, B5, and B6. For thesecond segment, ... offsets B4, B5, and B6. For thesecond segment, the new <em>chunks</em> are unlikely to be identicalto the old ones and cannot ... general, datainsertions or deletions will shift segment boundaries, whichcan change <em>chunk</em> boundaries and reduce deduplication ratio.The root cause of the reduction ... is that segment boundariesare not defined by data content, though <em>chunks</em> within eachsegment are. In contrast, in a sequential CDC algorithm ... eachsegment are. In contrast, in a sequential CDC algorithm ev-ery <em>chunk</em> is content-defined without impact of boundariesdefined by the segmentation.There have ... of boundariesdefined by the segmentation.There have been a few parallel <em>chunking</em> approaches. Thechunking operation in P-Dedup uses a segment-based andmultithreading approach ... andmultithreading approach [28]. It made efforts to achievechunking invariability. After <em>chunks</em> within each segmentare determined, a master thread computes additional rollinghashes ... the data between any two adjacent segments anddeclares a new <em>chunk</em> boundary whenever it finds a matchinghash value. However, this approach ... finds a matchinghash value. However, this approach only produces additionalsmall <em>chunks</em> and cannot ensure <em>chunking</em> invariability.The only work we are aware of that guarantees chunkinginvariability ... are aware of that guarantees chunkinginvariability and also provides multithreading <em>chunking</em> isMUCH [27]. In MUCH, data is partitioned into segments andeach ... segment is assigned to one thread for parallel chunking.To ensure <em>chunking</em> invariability, it introduces a <em>chunk</em> mar-shalling stage to additionally process <em>chunks</em> obtained withineach segment, which includes coalescing <em>chunks</em> that aresmaller than the minimum <em>chunk</em> size and splitting chunksthat are larger than the maximum <em>chunk</em> size. Nevertheless,MUCHwas designed as amultithreading <em>chunking</em> algorithmwithout consideration of running on an SIMD hardware. Asa result, ... be applied on AVX or GPUs.Shredder [2] is a parallel <em>chunking</em> scheme that is designedfor running on GPUs. A major issue ... data transfer from the mainmemory to the GPU device’s local <em>memory</em> and to minimizeits performance impact on the <em>chunking</em>. . However, becausethe window does not roll over segment boundaries, ... roll over segment boundaries, chunkTable 1: Comparison of existing parallel <em>chunking</em> algo-rithms with SS-CDCChunkinginvariabilityMulti-core GPU AVXP-Dedup No Yes No NoMUCH Yes ... in corresponding regions can be missed. Thus,Shredder does not guarantee <em>chunking</em> invariability.Table 1 summarizes existing parallel <em>chunking</em> approachesand compares them with our approach, SS-CDC. SS-CDCis the only ... with our approach, SS-CDC. SS-CDCis the only approach that guarantees <em>chunking</em> invariabilitywhile at the same time enables parallel <em>chunking</em> on multi-core processors, AVX, and GPUs.3 THE DESIGNSS-CDC is a ... a new CDC approach which enables high par-allelism for CDC <em>chunking</em> to utilize parallel hardware’scomputing power without compromising deduplication ra-tio. The ... ra-tio. The key insight of the work is that the <em>chunking</em> processcan be separated into two tasks. One task is for ... task is for rolling win-dow computation to generate all potential <em>chunk</em> boundaries,which is expensive but can be performed in parallel in ... parallel in differ-ent segments. The second task is to select <em>chunk</em> boundariesout of the candidate ones so that they meet the ... the candidate ones so that they meet the minimumand maximum <em>chunk</em> size requirements, whose executionhas to be serialized across the segments ... serialized across the segments but is lightweight.Accordingly, SS-CDC separates the <em>chunking</em> process intotwo stages, one for each task. As both the ... in the second stage are conducted in par-allel, the CDC <em>chunking</em> is almost fully parallelized at anyreasonably small granularity. Meanwhile, as ... parallelized at anyreasonably small granularity. Meanwhile, as the determina-tion of <em>chunk</em> boundaries is performed sequentially, SS-CDCproduces identical set of <em>chunk</em> boundaries and the samededuplication ratio as the sequential CDC.3.1 Decoupling ... Rolling Hashing fromChunk Boundary DeterminationFor rolling window based CDC, a <em>chunk</em> boundary is de-clared at the end of the current window ... rolling window matches a predefined value. Second, thesize of the <em>chunk</em> is within the range of the minimum andmaximum <em>chunk</em> <br /> ... rolling window is calculated and compared with thepredefined value. A <em>chunk</em> boundary candidate is declared89S4S1 E1S2 E2S3 E3Input dataStage 1P0P1P2P3hashcmp0hashcmp1hashcmp0hashcmp0Bit array ... 0 0 1 0 … 0 0 1 0 1Determine <em>chunk</em> boundaries, based on the bit array and min/max <em>chunk</em> size constraintsChunksFind all potential <em>chunk</em> boundaries and record them in a bit arrayFigure 3: The ... the end of this stage, it produces a set of <em>chunk</em> bound-ary candidates which satisfy the first condition. During thesecond stage, ... candidates which satisfy the first condition. During thesecond stage, final <em>chunk</em> boundaries are selected from thecandidates, which meet the minimum and ... S4), each of which is assigned to a thread foridentifying <em>chunk</em> boundary candidates. To determine chunkcandidates at every offset, a thread ... ‘1’ at the bit-offset k in thebit array indicates a <em>chunk</em> boundary candidate at the byte-offset k in the input file. ... searching forthe ‘1’ bits that meet the minimum and maximum <em>chunk</em> sizeconstraints. These offsets are the final <em>chunk</em> boundaries.3.2 Parallelizing Operations in SS-CDCTo achieve parallel <em>chunking</em> performance, SS-CDC paral-lelizes both of its stages to take full ... stage. We assign each segment to a different thread,3The additional <em>memory</em> to store the bit array can be freed or reused ... bit array can be freed or reused assoon as the <em>chunking</em> is completed.and the rolling window hashing and comparison are per-formed ... only a few ‘1’ bits. For example,with an expected average <em>chunk</em> size of 4KB, there will beone ‘1’ bit in every ... <br /> ... 16 equal-size segments, are processed in parallelto identify all potential <em>chunk</em> boundaries. We use an AVX90register (named Rc ) to store ... support loading 16 32-bit values from 16different locations in the <em>memory</em> to an AVX register. So thebytes entering and leaving a ... very time-consuming if performed sequentially becauseit would require 16 separated <em>memory</em> accesses for eachlookup. One such example is to use the ... the bit array unless non-zerointeger(s) are found or the maximum <em>chunk</em> size is reached,which will declare a <em>chunk</em> boundary. Compared to scanningthe bit array one bit at a ... making its runningtime account for only ?2% of the total <em>chunking</em> time.3.4 SS-CDC on Multiple Cores with AVXBy leveraging AVX instructions, ... instructions, our implementation of SS-CDC is able to do parallel <em>chunking</em> among segments from asingle file on individual cores. However, parallel ... we need to furtherexplore multiple cores to further improve the <em>chunking</em> band-width. In addition, most backup systems need to supportmultiple concurrent ... parallelism. In this section, we will discuss how wescale SS-CDC <em>chunking</em> to multiple cores for single files andthen how to handle ... how to handle multiple backup jobs (or backup files).To scale <em>chunking</em> for a single file to multiple cores, thebackup file is ... a segment queue. The system allocates thenumber of cores for <em>chunking</em> for this backup job. A <em>chunk</em>- -ing thread is started at each core. It retrieves a ... time from the head of the queue for the first-stage <em>chunking</em>. . As a lock is required to enforce an exclusiveaccess ... <br /> ... do itsequentially. Besides, the other cores that have completedtheir first-stage <em>chunking</em> can be used to process other files.To handle multiple concurrent ... to determine how many cores to allocatefor each job for <em>chunking</em>. . The system could allocate a singlecore for <em>chunking</em> for each job if that can provide sufficientchunking bandwidth or ... to it if desired. The sys-tem could allocate cores for <em>chunking</em> evenly among backupjobs or based on priority. For a given ... SS-CDC’s scalability with parallelchunking by either using all cores to <em>chunk</em> one file at a timeor use each core to <em>chunk</em> a different file.To make the presentation more concise, we follow ... introducethe following terms. SFMS (Single File Multiple Segments)refers to parallel <em>chunking</em> of a single file at a time on multi-ple cores ... single file at a time on multi-ple cores and parallel <em>chunking</em> of multiple segments within91each AVX-supported core. Similarly, SFSS (Single File ... AVX-supported core. Similarly, SFSS (Single File SingleSegment) refers to parallel <em>chunking</em> of a single file on multi-ple cores without using AVX ... single file on multi-ple cores without using AVX for parallel <em>chunking</em> within acore. MFMS (Multiple Files Multiple Segments) is similar toSFMS ... compare thespeedups from SS-CDC with existing multithreading CDC,for both single-file <em>chunking</em> and multi-file <em>chunking</em>. . Finally,we evaluate the deduplication ratio reduction (degradation)from existing segment-based ... cores and 16MB LLC. The server is equipped with256GB DDR4 <em>memory</em> and installed with Ubuntu 18.04 OS.The processors support Intel AVX-512 ... Thedatasets are stored on the local disks. In the measurements,the <em>chunking</em> time only includes the time spent on determin-ing <em>chunking</em> boundaries, and excludes the time for loadingthe data to <em>memory</em> before the <em>chunking</em> is performed. Weuse 7 real-world datasets as shown in Table ... average, and maximumchunk size respectively, as those in LBFS [16].4.1 <em>Chunking</em> SpeedWith the instruction-level parallelism enabled by the AVXinstructions, we expect ... enabled by the AVXinstructions, we expect to see speedups in <em>chunking</em> for bothone core and multiple cores for SS-CDC.Results on One ... multiple cores for SS-CDC.Results on One Core.We first run the <em>chunking</em> processon one core with different datasets and see how the ... ofCassandra Redis Debian Linux-src Neo4j Wordpress NodeDatasets050010001500ChunkingThroughput(MB/s)SS-CDC Sequential CDCFigure 4: <em>Chunking</em> speed of single-threaded SS-CDC andsequential CDC with one core. The ... CDC with one core. The minimum, expected av-erage and maximum <em>chunk</em> ... sizes are 2KB, 16KB, and 64KB,respectively.the AVX instructions improves the <em>chunking</em> performance.Figure 4 shows the <em>chunking</em> throughput of SS-CDC andsequential CDC with one thread running on ... <br /> ... read more data and do more rolling hash calculationthan sequential <em>chunking</em>, , as it does not skip the input datausing the ... as it does not skip the input datausing the minimum <em>chunk</em> size. As we will show, the mini-mum <em>chunk</em> size has a considerable impact on the speedupsof SS-CDC. Second, ... a considerable impact on the speedupsof SS-CDC. Second, while the <em>chunking</em> process is CPU inten-sive, it also includes substantial <em>memory</em> accesses for loadingdata from the <em>memory</em> to registers. While SS-CDC leveragesthe AVX instructions and reduces number ... SS-CDC leveragesthe AVX instructions and reduces number of instructionsexecuted for <em>chunking</em>, , it does not reduce the amount of datathat needs ... the amount of datathat needs to be loaded from the <em>memory</em>. . Third, since weconduct <em>chunking</em> ... for 16 segments concurrently, data are ac-cessed at 16 different <em>memory</em> addresses in parallel. ExistingDRAM controllers and CPU caches may not ... impacted by the deduplica-tion ratio of a dataset, the minimum <em>chunk</em> size has a directimpact on the speedup of SS-CDC. The ... SS-CDC. The reason is that thesequential CDC skips the minimum <em>chunk</em> size of bytes aftereach new <em>chunk</em> boundary is detected while SS-CDC hasto scan and calculate a ... Linux-src Neo4j Wordpress NodeDatasets0123ChunkingSpeedupMini=2 KB Mini=4 KB Mini=8 KBFigure 5: <em>Chunking</em> speedups when different minimumchunk sizes are used. The expected average ... sizes are 16KB and 64KB, respectively.the impact of the minimum <em>chunk</em> size on SS-CDC’s perfor-mance advantage, we measured the <em>chunking</em> speedups withdifferent minimum <em>chunk</em> ... sizes. The results are presented inFigure 5. As expected, the <em>chunking</em> speedup is decreasedwhen the minimum <em>chunk</em> size is increased. However, evenwith a large minimum <em>chunk</em> size (e.g., with a 8KB minimumchunk size and a 16KB ... (e.g., with a 8KB minimumchunk size and a 16KB average <em>chunk</em> size, 50% of the inputdata can be skipped in the ... thechunking speedups are still substantial, about 2.5 . As the2KB minimum <em>chunk</em> size is commonly used, we adopt it asthe default value ... on Multiple cores. Next we evaluated the scal-ability of the <em>chunking</em> speed of SS-CDC on multiple cores.Specifically, we examined multithreading SFMS ... CDC methods (SFSS andMFSS) that do not use AVX. Their <em>chunking</em> speeds werenormalized to the sequential CDC without using AVX, onefile ... on one core.To examine how SS-CDC scales for single file <em>chunking</em>, ,we look at how the <em>chunking</em> speedup increases when we usemore threads for <em>chunking</em> ... a single file. After we establishSS-CDC scales for single file <em>chunking</em>, , we examine multiplefile <em>chunking</em> where one file is assigned to only one threadand we ... in a real deployment, there are many differentways to assign <em>chunking</em> threads among backup jobs, theexperiments serve our purpose to demonstrate ... to demonstrate the scalabil-ity of SS-CDC for both single file <em>chunking</em> and multiplefile <em>chunking</em>. . For each dataset, we change the number ofchunking threads ... threads from 1 to 8 and show their speedups oversequential <em>chunking</em> using one thread.The results are shown in Figure 6 for ... 6 for single file chunkingand Figure 7 for multiple file <em>chunking</em>. . From Figures 6(a)and 7(a) (note the Y axes in ... for using locks at the segment queueand waiting for all <em>chunking</em> <br /> SS-CDC: A Two-stage Parallel Content-Defined <em>Chunking</em> for Deduplicating Backup StorageSS-CDC: A Two-stage Parallel Content-DefinedChunking for Deduplicating ... improve storage efficiency and I/O performance. In partic-ular, content-defined variable-size <em>chunking</em> (CDC) is oftenused in data deduplication systems for its capability ... SS-CDC, a two-stage parallelCDC, that enables (almost) full parallelism on <em>chunking</em> of afile without compromising deduplication ratio. Further, SS-CDC exploits instruction-level ... Publication rights licensedto ACM.ACM ISBN 978-1-4503-6749-3/19/06. . . $15.00https://doi.org/10.1145/3319647.3325834KEYWORDSStorage, Deduplication, Content-defined-<em>Chunking</em> (CDC)ACM Reference Format:Fan Ni, Xing Lin, and Song Jiang. 2019. ... Lin, and Song Jiang. 2019. SS-CDC: A Two-stage Par-allel Content-Defined <em>Chunking</em> for Deduplicating Backup Storage.In The 12th ACM International Systems and ... among backups. A data deduplication scheme partitionsinput files into small <em>chunks</em> and only unique <em>chunks</em> arestored in the system. Deduplication ratio, which is defined asthe ... <br /> ... is commonly used in backup storagesystems. A typical variable size <em>chunking</em> algorithm, suchas content-defined <em>chunking</em> (CDC) [16], scans almost everybyte in an input file using ... is determined when two conditions are met. Oneis that the <em>chunk</em> ... size is within the range of pre-defined min-imum and maximum <em>chunk</em> sizes. And the other is that thehash value of the ... parallel hardware,such as multi-core processors or GPGPU platforms, to per-form <em>chunking</em> on the segments in parallel, termed as parallelCDC hereafter. While ... of the twolimitations. They do not provide either guarantee of <em>chunk</em>- -ing invariability [27] or compatibility to the SIMD platforms,such as ... that a parallel chunkingalgorithm always generates the identical set of <em>chunks</em> in-dependent of the parallelism degree and the segment size.However, many ... size.However, many parallel CDC algorithms do not provide thisguarantee. The <em>chunks</em> generated from a parallel chunking2The hash function used here is ... hash function used togenerate the fingerprint to uniquely identify a <em>chunk</em>. . To support efficientrolling hashing, we assume a hash function ... size. The fundamental reason is thatthe boundary of the next <em>chunk</em> ... in a file is determined notonly by contents in the <em>chunk</em> but also by the boundary of itsprevious <em>chunk</em>. . Besides, to detect a new boundary we needto skip ... number of bytes from the last boundary tomaintain a minimum <em>chunk</em> size before starting the rolling-window-based hashing. Due to existence of ... starting the rolling-window-based hashing. Due to existence of this inherentdependency, <em>chunk</em> boundaries produced by independentlyperforming CDC within individual segments are differentfrom ... ratios of sequential CDC and parallel CDCusing 1MB segments and <em>chunk</em> size configuration from DellEMC Data Domain (4KB, 8KB, and 12KB ... (4KB, 8KB, and 12KB as the minimum,expected average, and maximum <em>chunk</em> sizes, respectively).The deduplication ratios from the parallel CDC are reducedby ... other limitation of many parallel CDC algorithms, inparticular the multithreading <em>chunking</em> algorithms, is thatthey can only be accelerated with multiple cores, ... with frequentbranches cannot be efficiently executed on such platforms.However, the <em>chunking</em> process does have frequent branches.At the same offset for different ... branches.At the same offset for different segments, some may detectvalid <em>chunk</em> boundaries while others may not. As a result,applying existing CDC ... more important toleverage the SIMD platforms for compute-intensive tasks,such as <em>chunking</em>, , for three reasons. One is that the cost perCPU ... soon beavailable in enterprise storage systems. On a backup system,compute-intensive <em>chunking</em> ... job is certainly a good candidateto utilize them. By offloading <em>chunking</em> to SIMD platforms,we can free up the CPU resources for ... <br /> ... on it usingreal-world datasets. We propose SS-CDC, a two-stage par-allel <em>chunking</em> ... algorithm, that can be parallelized by SIMDplatforms and meanwhile provide <em>chunking</em> invariability. Weimplemented SS-CDC with Intel AVX instructions as a casestudy. ... work is the firstto use Intel AVX instructions for parallel <em>chunking</em>. . Our ex-periments with real-world datasets show that compared toexisting ... BACKGROUND AND RELATEDWORKIn this section we provide additional background on <em>chunk</em>- -ing techniques of data deduplication, especially the time-consuming content-defined <em>chunking</em> and efforts on its par-allelization.2.1 Fixed vs. Variable-size ChunkingA file ... partitioned into either fixed-size or variable-sizechunks for deduplication. With fixed-size <em>chunking</em>, , chunkboundaries are determined at offsets of multiple of a ... Flash FAS [19]or Pure Storage [20], due to its high <em>chunking</em> speed. How-ever, fixed-size <em>chunking</em> cannot address the issue of bound-ary shifting due to data ... data insertions or deletions in a file. Tothis end, variable-size <em>chunking</em>, , whose <em>chunk</em> boundariesare defined by file content, is proposed so that duplicatechunks ... be identified even after file data shifting. In theso-called content-defined <em>chunking</em> (CDC) algorithm, a fixed-size rolling window is used to scan ... used to scan a file in a byte-by-bytemanner to determine <em>chunk</em> boundaries. For the rolling win-dow at any byte offset, a ... and com-pared to a predefined value. If they match, a <em>chunk</em> boundaryis declared at the end of the window. Otherwise, the ... is re-peated. To avoid generating too small or too large <em>chunks</em>, ,the minimum-<em>chunk</em>- -size and maximum-<em>chunk</em>- -size thresh-olds are defined. When a <em>chunk</em> boundary is declared, therolling window skips the following minimum-<em>chunk</em>- -sizebytes. Meanwhile, a <em>chunk</em> boundary is immediately declaredonce the <em>chunk</em> ... size reaches the maximum-chunk-size.It is noted that in the CDC <em>chunking</em> the process of de-termining a sequence of boundaries in a ... position. This placesSegment boundarySkipped boundaryBefore change After changeB1 B2 B3Minimum <em>chunk</em> sizeDetermined <em>chunking</em> boundarySegment 1 Segment 2B4 B5 B6B’4 B’5 B’6 B’7Inserted dataB1 ... on its effective parallelization. Meanwhile, it isimportant to accelerate the <em>chunking</em> process as it is highlycompute-intensive and can become the performance ... of the system. There are two categories of efforts foraccelerating <em>chunking</em> process, which are optimization ofthe rolling hashing and parallel <em>chunking</em>. .2.2 Optimizing Rolling HashingIn CDC, a hash value is computed ... the rolling hash function has a signifi-cant impact on the <em>chunking</em> speed. Lightweight hash func-tions have been proposed to reduce the ... lookups. FastCDC [30] proposed afew techniques to accelerate the Gear-based <em>chunking</em> pro-cess. AE [32] is a non-rolling-hash-based <em>chunking</em> algorithmthat employs an asymmetric rolling window to identify ex-tremums of ... use twofunctions, one lightweight and the other heavyweight, toselect a <em>chunk</em> boundary. A simpler condition is tested first.Only when the condition ... can be parallelized and acceler-ated using the SS-CDC technique.2.3 Parallel <em>Chunking</em> and its LimitationsAnother approach to speed up CDC is to ... partition theinput files into segments and use a thread to <em>chunk</em> a seg-ment independently. With this approach, we can leveragemulti-core processors ... With this approach, we can leveragemulti-core processors to achieve parallel <em>chunking</em>. . However,it does not guarantee <em>chunking</em> invariability and compro-mises the deduplication ratio. And it cannot fully ... <br /> of the AVX instructions, multi-threading SS-CDC achieves superlinear <em>chunking</em> speedups.Still take the Cassandra dataset as an example. Its MFMSspeedups ... ?3 ). When scaling SS-CDC’s performance to mul-tiple cores for single-file <em>chunking</em> in SFMS, the speedupsbecome smaller. For example, the SFMS speedups ... thread 2 threads 4 threads 8 threads(b) SFMS SS-CDCFigure 6: <em>Chunking</em> speedups of multithreading regular CDC and multithreading SS-CDC over sequential ... thread 2 threads 4 threads 8 threads(b) MFMS SS-CDCFigure 7: <em>Chunking</em> speedups of multithreading regular CDC and multithreading SS-CDC over sequential ... segmentsFigure 8: Deduplication ratio reduction of the regular mul-tithreading CDC <em>chunking</em> approach (SFSS), compared withthat of SS-CDC’s SFMS implementation (on 8 ... segment sizes are used.4.2 Deduplication RatioSS-CDC is designed to provide <em>chunking</em> invariability. Whenused in either MFMS or SFMS, it can always ... verifyour SS-CDC implementation is correct. However, existingsegment-based single file parallel <em>chunking</em> (SFSS) cannotachieve this <em>chunking</em> invariability, and experience dedupli-cation ratio reduction. To gauge significance of ... a quantitative studywhere we vary the segment size and the <em>chunk</em> size.Figure 8 presents the deduplication ratio reduction fromSFSS with different ... the segments in the limited device localmemory. Existing segment-based parallel <em>chunking</em>, , as inSFSS, has the fundamental limitation that requires a ... Linux-src Neo4j Wordpress NodeDatasets01020304050DedupRatioReduction(%) Mini=2 KBMini=4 KBMini=8 KB(a) Varying minimum <em>chunk</em> sizesCassandra Redis Debian Linux-src Neo4j Wordpress NodeDatasets01020304050DedupRatioReduction(%) Expected Avg =4 ... =4 KBExpected Avg =8 KBExpected Avg =16 KB(b) Varying average <em>chunk</em> sizesCassandra Redis Debian Linux-src Neo4j Wordpress NodeDatasets01020304050DedupRatioReduction(%) Maxi=32 KBMaxi=64 KBMaxi=128 ... Linux-src Neo4j Wordpress NodeDatasets01020304050DedupRatioReduction(%) Maxi=32 KBMaxi=64 KBMaxi=128 KB(c) Varying maximum <em>chunk</em> sizesFigure 9: Reduction of deduplication ratio (in percentage) for multithreading ... (SFSS) on 8 cores, compared to SS-CDC(multithreading SFMS) with different <em>chunk</em> size configurations. The segment size is 1MB.large segment size.With SS-CDC, ... <br /> look at how the <em>chunk</em> size impacts dedu-plication ratio for SFSS. We vary all three ... ratio for SFSS. We vary all three parameters con-trolling the <em>chunk</em> size, including the minimum, the expectedaverage, and the maximum <em>chunk</em> sizes, one at a time. Thededuplication ratios are compared with ... in the dataset, SFSS is more likelyto turn a duplicate <em>chunk</em> into a unique one due to chunkboundary shifts because of ... dedupli-cation ratio reduction is most significant when we vary theminimum <em>chunk</em> size, ranging from 10% to 38% as shownin Figure 9a. ... minimumchunk size, the reduction becomes larger. With a larger min-imum <em>chunk</em> size, it increases the possibility of finding amatching rolling hash ... amatching rolling hash value in that window and having dif-ferent <em>chunks</em> between sequential CDC and SFSS. This canleave the use of ... use of SFSS in a dilemma where a larger mini-mum <em>chunk</em> size can skip more bytes for better chunkingperformance while a ... skip more bytes for better chunkingperformance while a smaller minimum <em>chunk</em> ... size can avoidsubstantial deduplication ratio reduction.The impacts of the average <em>chunk</em> size on deduplicationratio for SFSS are more complicated. On one ... SFSS are more complicated. On one hand, with alarger average <em>chunk</em> size, there are fewer <em>chunks</em> and thusfewer <em>chunk</em> boundaries. We have a smaller probability tofind candidate <em>chunk</em> boundaries in the minimum <em>chunk</em> sizewindow that could lead to different <em>chunks</em> ... in segment-basedSFSS. On the other hand, with a larger average <em>chunk</em> size,it takes more bytes for SFSS to synchronize back to ... as those in sequential CDC as there will be fewercandidate <em>chunk</em> boundaries. To investigate which factorhas a larger impact on the ... ondeduplication ratio reduction.In addition to the minimum and the average <em>chunk</em> sizes,the maximum <em>chunk</em> size also affects deduplication ratio. Fig-ure 9c shows the deduplication ... Fig-ure 9c shows the deduplication ratio reduction when varyingthe maximum <em>chunk</em> size. With a larger maximum chunksize, the deduplication reduction is ... deduplication reduction is more significant. By us-ing a larger maximum <em>chunk</em> size, the size of the chunksare more likely larger as ... larger as more bytes can be scanned whendeciding the next <em>chunk</em> boundary. So once a unique chunkis generated due to the ... makea larger range of bytes not deduplicated.To summarize, existing parallel <em>chunking</em> using seg-ments suffers significant deduplication ratio reduction whenthey exploit segment-based ... whenthey exploit segment-based parallelism. SS-CDC guaranteeschunking invariability and achieves parallel <em>chunking</em> per-formance without impacting deduplication ratios.5 CONCLUSIONSIn this paper, we presented ... of the parallel computing power of theunderlying hardware for high <em>chunking</em> speed without com-promising deduplication ratio. SS-CDC separates the <em>chunk</em>- -ing process into a stage that is compute intensive but ... an SIMD platform and eval-uated that we can achieve parallel <em>chunking</em> performance forboth single file <em>chunking</em> and multi-file <em>chunking</em>. . With SS-CDC, we can now offload compute-intensive CDC to ... compute-intensive CDC to SIMDplatforms to exploit extra instruction-level parallelism toaccelerate <em>chunking</em> and get high deduplication ratios.ACKNOWLEDGMENTSWe are grateful to the anonymous ... <br /> ... K. Lim, and J. Min. 2015. MUCH: Multithreaded Content-Based File <em>Chunking</em>. . IEEE Trans. Comput. 64, 5 (May 2015), 1375–1388.https://doi.org/10.1109/TC.2014.2322600[28] Wen ... Zhang, and Qing Liu. 2016. FastCDC: A Fast and EfficientContent-defined <em>Chunking</em> Approach for Data Deduplication. In Pro-ceedings of the 2016 USENIX ... and Yukun Zhou. 2017. A Fast Asymmetric Extremum Con-tent Defined <em>Chunking</em> Algorithm for Data Deduplication in BackupStorage Systems. IEEE Trans. Comput. ... <br />
<br />
<strong>Abstract</strong>:<br />
... improve storage efficiency and I/O performance. In particular, content-defined variable-size <em>chunking</em> (CDC) is often used in data deduplication systems for its ... a two-stage parallel CDC, that enables (almost) full parallelism on <em>chunking</em> of a file without compromising deduplication ratio. Further, SS-CDC exploits ... <br />
<br />
<strong>References</strong>:<br />
Y. Won, K. Lim, and J. Min. 2015. MUCH: Multithreaded Content-Based File <em>Chunking</em>. <i>IEEE Trans. Comput.</i> 64, 5 (May 2015), 1375--1388. <br /> Wen Xia, Yukun Zhou, Hong Jiang, Dan Feng, Yu Hua, Yuchong Hu, Yucheng Zhang, and Qing Liu. 2016. FastCDC: A Fast and Efficient Content-defined <em>Chunking</em> Approach for Data Deduplication. In <i>Proceedings of the 2016 USENIX Conference on Usenix Annual Technical Conference (USENIX ATC '16).</i> USENIX Association, Berkeley, CA, USA, 101--114. http://dl.acm.org/citation.cfm?id=3026959.3026969 <br /> C. Yu, C. Zhang, Y. Mao, and F. Li. 2015. Leap-based Content Defined <em>Chunking</em> - Theory and Implementation. In <i>2015 31st Symposium on Mass Storage Systems and Technologies (MSST).</i> IEEE, Santa Clara, CA, 1--12. <br /> Yucheng Zhang, Dan Feng, Hong Jiang, Wen Xia, Min Fu, Fangting Huang, and Yukun Zhou. 2017. A Fast Asymmetric Extremum Content Defined <em>Chunking</em> Algorithm for Data Deduplication in Backup Storage Systems. <i>IEEE Trans. Comput.</i> 66, 2 (Feb 2017), 199--211. <br />
<br />
<strong>Keywords</strong>:<br />
content-defined-<em>chunking</em> (CDC) <br />
<br />
<strong>Title</strong>:<br />
SS-CDC: a two-stage parallel content-defined <em>chunking</em> for deduplicating backup storage <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
12
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=1534540" target="_self">The effectiveness of deduplication on virtual machine disk images</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81421600083">Keren Jin</a>,
<a href="author_page.cfm?id=81339517516">Ethan L. Miller</a>
</div>
<div class="source">
<span class="publicationDate">May 2009</span>
<span style="padding-left:10px">SYSTOR '09: Proceedings of SYSTOR 2009: The Israeli Experimental Systems Conference</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 64</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;2</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;60</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;1,054</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1534540&ftid=630278&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Virtualization is becoming widely deployed in servers to efficiently provide many logically separate execution environments while reducing the need for physical servers. While this approach saves physical CPU resources, it still consumes large amounts of storage because each virtual machine (VM) instance requires its own multi-gigabyte disk image. Moreover, existing ...
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high1534540');">result highlights</a>]</div>
<div class="highlights" id="high1534540" style="display:none">
<strong>Full Text</strong>:<br />
<em>chunking</em> anddeduplication approaches to analyze VM disk images. Sec-tion 4 evaluates ... of storage required for a set of files by identifyingduplicate “<em>chunks</em>” ” of data in a set of files and storing ... a set of files and storing onlyone copy of each <em>chunk</em> [17, 19]. Subsequent requests to storea <em>chunk</em> that already exists in the <em>chunk</em> store are done bysimply recording the identity of the <em>chunk</em> ... in the file’s inodeor block list; by not storing the <em>chunk</em> a second time, thesystem stores less data, thus reducing cost.Different ... cost.Different implementations of deduplication use differenttechniques to break files into <em>chunks</em>. . Fixed-size <em>chunking</em>, ,such as that used in Venti [20] simply divides files ... used in Venti [20] simply divides files at blockboundaries. Variable-size <em>chunking</em>, , used in systems suchas LBFS [17] and Deep Store ... performance by requiring non-block alignedI/O requests.While their approaches to identifying <em>chunks</em> differ, bothfixed-size and variable-size <em>chunking</em> use cryptographically-secure content hashes such as MD5 or SHA1 [2] ... content hashes such as MD5 or SHA1 [2] to iden-tify <em>chunks</em>, , thus allowing the system to quickly discoverthat newly-generated <em>chunks</em> already have stored instances.Even for a 128 bit MD5 hash, ... MD5 hash, the chance of a single colli-sion among 1015 <em>chunks</em>— —1018 bytes, assuming an averagechunk size of 1KB—is about 10?9 ... can reduce the probability of a singlecollision in an exabyte-scale <em>chunk</em> store to about 7 10?18.Collisions in SHA1 have been reported ... [26], and intention-ally forging different but still equivalently meaningful in-dependent <em>chunks</em> is a potential security breach, though itis not yet practical ... system implementer from using SHA1 [13], we choseSHA1 to name <em>chunks</em> in our experiments because these is-sues clearly do not impact ... Using deduplication in an online systemrequires fast identification of duplicate <em>chunks</em>; ; techniquessuch as those developed by Bhagwat, et al. [6] ... [18] and the Difference En-gine [12] used deduplication to share in-<em>memory</em> pages be-tween different virtual machine instances. While these usesare not ... <br /> ... project [12] useddeduplication to allow multiple virtual machines to share in-<em>memory</em> pages. This approach proved effective, though thelevel of deduplication was ... approach proved effective, though thelevel of deduplication was lower for <em>memory</em> page dedupli-cation than for storage deduplication. Moreover, the VMswere limited ... of VM disk images, we firstbroke VM disk images into <em>chunks</em>, , and then analyzed dif-ferent sets of <em>chunks</em> to determine both the amount of dedu-Name Valuedivisor 512, 1024, ... the amount of dedu-Name Valuedivisor 512, 1024, 2048, 4096 (bytes)maximum <em>chunk</em> size divisor 2minimum <em>chunk</em> ... size divisor / 16irreducible polynomial 0x91407E3C7A67DF6Dresidual 0sliding window size minimum <em>chunk</em> size / 2Table 1: Parameters for variable-size chunking.plication possible and ... 1: Parameters for variable-size chunking.plication possible and the source of <em>chunk</em> similarity. Sec-tion 3.1 discusses the techniques we used to generate ... parts of disk images, we di-vide the image files into <em>chunks</em> to reduce their granular-ities. This is done by treating each ... bytestream and identifying boundaries using either a “constant”function (for fixed-size <em>chunking</em>) ) or a Rabin fingerprint (forvariable-sized <em>chunking</em>) ). A <em>chunk</em> is simply the data be-tween two boundaries; there are implicit ... implicit boundaries at thestart and end of each image file. <em>Chunks</em> are identified bytheir SHA1 hash, which is calculated by running ... which is calculated by running SHA1 overthe contents of the <em>chunk</em>. . We assume that <em>chunks</em> with thesame <em>chunk</em> ID are identical; we do not do a byte-by-bytecomparison to ... we do not do a byte-by-bytecomparison to ensure that the <em>chunks</em> are identical.We implemented both fixed-size and variable-size <em>chunk</em>- -ing to test the efficiency of each approach in deduplicatingdisk ... test the efficiency of each approach in deduplicatingdisk images. Fixed-size <em>chunking</em> was done by reading animage file from its start and ... done by reading animage file from its start and setting <em>chunk</em> boundaries ev-ery N bytes, where N is the <em>chunk</em> size. For variable-sizechunking, we calculated 64-bit Rabin fingerprint using theirreducible ... have greatly varying sizes, so we imposed mini-mum and maximum <em>chunk</em> sizes on the function to reducethe variability, as is usually ... Table 1; these parameters were chosen to en-sure that the <em>chunking</em> algorithm generates <em>chunks</em> with thedesired average <em>chunk</em> size. We conducted experiments foraverage <em>chunk</em> sizes of 512, 1024, 2048, and 4096 bytes forboth fixed-size ... <br /> ... eval-uations on different sets of virtual machine disk images withdifferent <em>chunking</em> strategies. Our experiments found thatthe amount of stored data grows ... or differentoperating systems are included. We also show that fixed-length <em>chunks</em> ... work well, achieving nearly the same com-pression rate as variable-length <em>chunks</em>. . Finally, we showthat simply identifying zero-filled blocks, even in ... of which are under system control (e. g., fixed versusvariable-sized <em>chunking</em> and average <em>chunk</em> size) and some ofwhich are dependent on the usage environment ... <br /> variable-size chunking.We <em>chunked</em> each image file separately because fixed-sizechunking exhibits the “avalanche effect”: ... effect”: although alteringbytes in the file only changes the corresponding <em>chunk</em> IDs,inserting or removing bytes before the end of an image ... the end of an image filechanges all of the remaining <em>chunk</em> IDs, unless the length of(a) Fixed-size chunkingwith <em>chunk</em> size 512B.(b) Variable-size chunkingwith expected averagechunk size 512B.Figure 1: <em>Chunking</em> a file with size 0xF300 bytes.insertion or deletion is multiple ... with size 0xF300 bytes.insertion or deletion is multiple of the <em>chunk</em> size for fixed-size <em>chunking</em>. ... . Thus, if image file sizes are not multiples ofthe <em>chunk</em> size, the result of <em>chunking</em> across files is differentthan that of <em>chunking</em> each separately. Also, because bothmonolithic and spanning image files have ... spanning image files have a header specific tothe VM instance, <em>chunking</em> sequentially across the spanningfiles does not restore the original guest ... does not restore the original guest file system becausethe last <em>chunk</em> ... of each file could be shorter than the specifiedchunk size.Zero-filled <em>chunks</em> are common in VM disk images, andcome from three sources. ... affected by the choice of virtual disk size. In fixed-size <em>chunking</em>, , all zero-filled <em>chunks</em> are identical—they allcontain identical content. In the variable-size <em>chunking</em> ex-periments, runs of zeros do not generate boundaries, andthus result ... runs of zeros do not generate boundaries, andthus result in <em>chunks</em> of the maximum <em>chunk</em> size. Sinceall zero-filled <em>chunks</em> are the same (maximal) size (exceptperhaps for a run at ... allidentical to one another.To further reduce space, we compressed each <em>chunk</em> usingzip after hashing it to generate the <em>chunk</em> ID. This approachis often used with deduplication, and results in ... loss of fidelity.3.2 DeduplicationThe deduplication process is simple: for each <em>chunk</em> beingstored, attempt to locate an existing instance in the chunkstore. ... instance in the chunkstore. If none is found, the new <em>chunk</em> is added to the chunkstore; otherwise, the new <em>chunk</em> is a shared <em>chunk</em>. . As de-scribed in Section 3.1, nearly all zero <em>chunks</em> are identical,except for a non-maximal length zero <em>chunk</em> at the end of animage file. Since even large spanning ... have rela-tively few files, most of which end with non-zero <em>chunks</em>, , anoptimization that recognizes such non-maximal length zerochunks would provide ... 05 11 E4Intra Inter Intra-inter NoneSharing:StoredFigure 2: Share categories of <em>chunks</em>. . <em>Chunks</em> seenfor the first time must be stored; subsequent occur-rences need ... time must be stored; subsequent occur-rences need not be stored.The <em>chunk</em> ID, which is generated from the SHA1 hash ofthe chunk’s ... value used to look up existingchunks. Even for an exabyte-scale <em>chunk</em> store, collisionswould be highly unlikely; for the multi-terabyte <em>chunk</em> storein our experiments, the chances of collision are even smaller.We ... are even smaller.We calculate the deduplication ratio for a given <em>chunk</em> storeand <em>chunking</em> method by:1?Stored bytes of all disk imagesOriginal bytes of all ... fraction in [0, 1), since there isat least one stored <em>chunk</em> in a <em>chunk</em> store, and the worstpossible case is that there are no ... and the worstpossible case is that there are no duplicate <em>chunks</em>. . We ex-clude per-<em>chunk</em> overhead in our studies; this overhead is lessthan 4% for ... in our studies; this overhead is lessthan 4% for 512B <em>chunks</em>, , and smaller for larger chunks.We classify each occurrence of ... and smaller for larger chunks.We classify each occurrence of a <em>chunk</em> ... into one of fourcategories, shown in Figure 2. When a <em>chunk</em> appears ex-actly once in the entire set of VM disk ... entire set of VM disk images, it is calledan unshared <em>chunk</em>, , labeled “none” in Figure 2. Chunksthat appear in more ... in more than one disk image are termed inter-image shared <em>chunks</em>, , and <em>chunks</em> that appear multiple times,within a single disk image but not ... single disk image but not elsewhere are called intra-image shared <em>chunks</em>. . <em>Chunks</em> that appear in multiple diskimages and appear more than once ... once in at least one of thoseimages are inter-intra-image shared <em>chunks</em>. . Zero-filled chunksare tracked separately; however, they are typically inter-intra-image ... Zero-filled chunksare tracked separately; however, they are typically inter-intra-image shared <em>chunks</em> in sets with more than one diskimage because zero-filled <em>chunks</em> appear in every disk imagethat we examined.As Figure 2 shows, ... in every disk imagethat we examined.As Figure 2 shows, all <em>chunks</em> must be stored the firsttime they are seen. Subsequent occurrences ... <br /> <em>chunks</em> are groupedtogether for our experiments, while non-stored <em>chunks</em> ... areclassified by the disk images in which other occurrences ofthe <em>chunks</em> are found. Thus, a <em>chunk</em> c that occurs one timein disk image A and then ... two times in disk image B wouldresult in one stored <em>chunk</em> and two inter-intra shared chunksbecause there are occurrences of <em>chunk</em> c in two separate diskimages, and multiple occurrences of <em>chunk</em> c in at least onedisk image. The total size of ... in at least onedisk image. The total size of a <em>chunk</em> store before dedu-plication is thus the sum of the sizes ... themetrics used by another study [16], which only concentrateson “duplicate” <em>chunks</em>. . In their study, two identical disk im-ages would be ... two identical disk im-ages would be 100% similar, and 40% <em>chunks</em> would typicallyneed to be stored.Changing the processing order for a ... produce different intermediate results for the numberand type of shared <em>chunks</em> and the deduplication ration, butthe final result will always be ... were compatiblewith VirtualBox 2.0.For the figures in this section, stored <em>chunks</em> are countedthe first time seen during the deduplication process, each ... process, each ofwhich must be stored. Each of the other <em>chunk</em> categoriesis reduced in size by its remaining instances. Zero chunksare ... by its remaining instances. Zero chunksare isolated as a separate <em>chunk</em> class, not part of inter-intrashared <em>chunk</em>. .4.1 Overall ImpactsBefore going into detail on how much specific ... 1KB and 4KBchunk size, respectively. Of the 22% of the <em>chunks</em> that arestored, 12% are <em>chunks</em> that occur exactly once and 10%are <em>chunks</em> that occur more than once, with only a singleinstance stored. ... Since it takes more time andstorage overhead to generate smaller <em>chunks</em>, , 4KB chunksize might be a good idea if space ... <br /> ... image file,X is a disk image file split into 2GB <em>chunks</em>, , S is a sparse image file, and F is ... highly similar.In our next experiment, we compared deduplication lev-els for <em>chunk</em> stores consisting only of VMs with a singleoperating system—BSD or ... a singleoperating system—BSD or Linux—to that of two more het-erogeneous <em>chunk</em> stores: one with BSD, OpenSolaris, andDarwin (labeled “Unix”), and another ... with all types of op-erating systems (labeled “All”). The All <em>chunk</em> store is asuper set of the other three <em>chunk</em> stores, and contains moreflat disk images. As Figure 5 shows, ... contains moreflat disk images. As Figure 5 shows, the All <em>chunk</em> storeachieved the best deduplication ratio, indicating that, evenfor operating systems ... high deduplication level comes from twosources. The first is zero <em>chunks</em>, , as the All <em>chunk</em> storeincludes more flat disk images than any other <em>chunk</em> stores.The second is additional inter <em>chunks</em>, , as they appeared onlyonce in BSD or Linux <em>chunk</em> stores and were considered asstored <em>chunks</em>. . Nevertheless, the higher levels of sharing fornon-zero <em>chunks</em> in the Linux <em>chunk</em> store indicates that theLinux disk images were more homogeneous than ... 6 8 10 12 14number of processed virtual machines051015202530size of <em>chunk</em> category (GB)zerointra-interintra shareinter sharestored0 2 4 6 8 10 12 ... sharestored0 2 4 6 8 10 12 140.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> category(a) Average <em>chunk</em> size = 1KB.0 2 4 6 8 10 12 14number ... 6 8 10 12 14number of processed virtual machines051015202530size of <em>chunk</em> category (GB)zerointra-interintra shareinter sharestored0 2 4 6 8 10 12 ... sharestored0 2 4 6 8 10 12 140.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> category(b) Average <em>chunk</em> size = 4KB.Figure 3: Growth of data in different categories ... these figures, stored data includes the first in-stance of each <em>chunk</em>, , regardless of how it is shared.The sharp increase in ... notable feature in Figure 5 is that the fractionof zero <em>chunks</em> decreases markedly from the 512B Linuxcase to the 4KB Linux ... <br /> unique <em>chunks</em>, , indicating that most of the zerochunks are 2KB or ... The figure also shows that,while the relative fractions of zero <em>chunks</em> and unique chunkschanges from 512B <em>chunks</em> to 4KB <em>chunks</em>, , the amount ofsharing changes relatively little, indicating that <em>chunk</em> sizemay have relatively little impact on relative frequency ofshared chunks.Figure ... relative frequency ofshared chunks.Figure 6 shows the cumulative distribution of <em>chunks</em> byboth count and total size in the Linux <em>chunk</em> store. Chunksthat appear only once are unique <em>chunks</em> and must be stored;for other <em>chunks</em>, , the <em>chunk</em> store need only contain one copyof the <em>chunk</em>. . As the figure shows, over 70% of <em>chunks</em> occurexactly once, and these <em>chunks</em> make up about 35% of theundeduplicated storage. The zero <em>chunks</em> take about 20%storage, as shown in Figure 5; they are ... 4 6 8 10 12number of processed virtual machines05101520size of <em>chunk</em> category (GB)zerointra-interintra shareinter sharestored0 2 4 6 8 10 120.00.10.20.30.40.50.60.70.80.91.0size ... shareinter sharestored0 2 4 6 8 10 120.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categoryFigure 4: Growth of category data for 13 Unix andLinux ... data for 13 Unix andLinux virtual machines, using variable size <em>chunking</em>, ,with an average <em>chunk</em> size of 1KB. Unique datagrows significantly as each disk image ... a flat disk image.BSDUnix Linux(512 B)Linux(4 KB)Alldeduplication subject0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categorystoredinterintrainter-intrazeroFigure 5: Effects of varying operating system typeon deduplication. All ... of varying operating system typeon deduplication. All experiments used 512Bvariable-size <em>chunks</em>, ... , except for the Linux experi-ment that uses 4KB variable-size <em>chunks</em>. . There ismore intra-inter sharing in Linux than in BSD, ... the former is more homogeneous.We first examined the effect of <em>chunk</em> size and boundarycreation technique on deduplication ratio. Figure 7 showsthe ... of Ubuntu Server using fixed and variable-sizechunking for different average <em>chunk</em> sizes. As expected,smaller <em>chunk</em> sizes result in better deduplication ratios; thisis done by converting ... result in better deduplication ratios; thisis done by converting unique <em>chunks</em> into shared <em>chunks</em> andzero <em>chunks</em>. . Interestingly, the number of zero <em>chunks</em> growssignificantly as <em>chunk</em> size decreases, indicating that zerochunks are more likely to be ... more effective than variable-size chunkingin this experiment, suggesting that fixed-size <em>chunking</em> maybe appropriate for VM disk images.We next examined the effects ... Ubuntu68 is deduplicated against1 10 20 30 40 50number of <em>chunk</em> appearance0.00.20.40.60.81.0cumulative ratio of distinct chunkssizenumberFigure 6: Cumulative distribution of <em>chunks</em> bycount and total size. The upper line shows the cu-mulative ... total size. The upper line shows the cu-mulative number of <em>chunks</em> with total count of n orless, and the lower line ... lower line shows the total space thatwould be consumed by <em>chunks</em> ... with count n or less.The data is from the Linux <em>chunk</em> store with chunksize 512B. As the graph shows, most <em>chunks</em> occurfewer than 14 times, and few non-zero <em>chunks</em> ap-pear more than 50 times in the set of disk ... in the set of disk images.4096 2048 1024 512(expected) average <em>chunk</em> size (bytes)0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categorystoredinterintrainter-intrazeroFigure 7: Effects of <em>chunk</em> size and fixed versus.variable-size <em>chunking</em> on deduplication for a set ofdisk images including Ubuntu Server ... In each group of two bars, the left barmeasures fixed-size <em>chunking</em> and the right bar indi-cates variable-size <em>chunking</em>. . The graph shows thatsmaller <em>chunk</em> sizes result in more effective dedupli-cation.Ubuntu 6.10 and Ubuntu 8.04. ... <br /> ... it is one of the only cases in which variable-size <em>chunking</em> significantly outperforms fixed size chunkingin our experiments, confirming that deduplication ... chunkingin our experiments, confirming that deduplication for VMsshould use fixed-size <em>chunking</em> rather than adding the com-plexity of variable-size chunking.Ubuntu 7-8 Ubuntu ... 7-8 Ubuntu 6-8 Fedora 8-9 Fedora 7-9deduplication subject0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categorystoredinterintrainter-intrazeroFigure 8: Deduplication on different releases of asingle Linux distribution. ... asingle Linux distribution. The left bar in each pairis fixed-size <em>chunking</em> and right bar is variable-sizechunking; <em>chunk</em> size is 512B. Consecutive releasesonly have slightly lower deduplication ratio ... thannon-consecutive releases.Ubuntu en | en+frFedora en | en+frdeduplication subject01234567size of <em>chunk</em> category (GB)storedinterintrainter-intrazeroFigure 9: Locale versions (variable-size <em>chunking</em>, ,<em>chunk</em> size 512B). The left bar in each pair only mea-sures ... version of each OS againstits English version adds few stored <em>chunks</em>, , indicating thatchanging the localization of an operating system introducesvery ... the distribution—in thisDebian series Red Hat seriesdeduplication subject0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categorystoredinterintrainter-intrazeroFigure 10: Distribution lineage. Debian series com-prises Debian, Ubuntu and ... and Knoppix. Red Hat seriescomprises Fedora, CentOS and Mandriva. Variable-size <em>chunking</em>, , <em>chunk</em> size 512B. Despite the commonlineages, there is a relatively low ... low level of deduplica-tion.BSD AMP Hybrid AMPdeduplication subject0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categorystoredinterintrainter-intrazeroFigure 11: Deduplication of Web appliance VMs(variable-size <em>chunking</em>, , <em>chunk</em> size 512B). AMPstands for Apache, MySQL and PHP. Since thededuplication ... that diverseoperating systems with similar goals do not havemany identical <em>chunks</em> of code.case, serving Web pages—constant. We built a <em>chunk</em> storefrom disk images of DragonflyBSD, NetBSD and OpenBSDwith Apache, MySQL, ... added similar configura-tions of CentOS, Gentoo and Ubuntu into the <em>chunk</em> store;the results are shown in Figure 11. Excluding the large ... shown in Figure 11. Excluding the large num-ber of zero <em>chunks</em>, , the deduplication ratios are not high,showing that the common ... notimprove the deduplication ratio. While it may appear thatdiversifying the <em>chunk</em> store with Linux distributions helps,this is an illusion caused by ... is an illusion caused by the large number of zero <em>chunks</em>; ;the levels of sharing remain low.The choice of virtual machine ... is used. The large variation in deduplication effec-tiveness for fixed-size <em>chunking</em> is due to different offsets inthe disk image for the ... the same value modulo 512 but not modulo 1024, fixed-size <em>chunking</em> is only effective for 512B <em>chunks</em>. . Figure 12b4096 2048 1024 512(expected) average <em>chunk</em> size (bytes)0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categorystoredinterintrainter-intrazero(a) Ubuntu Server 8.04.1 on VMware and Virtual-Box (sparse disk ... Virtual-Box (sparse disk image, 4GB maximum)4096 2048 1024 512(expected) average <em>chunk</em> size (bytes)0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> <br /> ... differentVMMs deduplicate well. The bar on the left mea-sures fixed-size <em>chunking</em>, , and the right-hand barmeasures variable-size chunking.shows that, not surprisingly, ... package sets are approximatelyp1a-p1ap1a-p1d p2a-p2d p1a-p2a p1a-p2ddeduplication subject0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categorystoredinterintrainter-intrazeroFigure 13: Differing package installation orders. p1adenotes package set 1, ... 1, ascending order, and othersfollow the same naming rule. Variable-size <em>chunk</em>- -ing, <em>chunk</em> size 512B. Different package installationorders generate nearly identical disk images.equal, ... <br /> ... set 1 on Ubuntu, CentOS and Fe-U-CbeforeU-CafterF-CbeforeF-Cafterdeduplication subject0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categorystoredinterintrainter-intrazeroFigure 14: Package systems comparison on UbuntuServer 8.04 (U), CentOS ... desktop (F). Both install package set1 in ascending order. Variable-size <em>chunking</em>, , chunksize 512B. Package system’s contribution to dedu-plication is outweighed ... dedu-plication is outweighed by OS heterogeneity.rp-rrrp-p1d rr-orideduplication subject0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categorystoredinterintrainter-intrazeroFigure 15: Package removal orders. Variable-sizechunking, <em>chunk</em> size 512B. rp denotes removingonly target packages. rr denotes removing ... level 9 21152781050 (19.7 GB)7-zip, level 9 15008385189 (14.0 GB)var, <em>chunk</em> size 512B, level 9 29664832343 (27.6 GB)var, <em>chunk</em> size 4KB, level 9 23994815029 (22.3 GB)Table 5: Compression parameters.0 ... (4 KB)zip compression level (0 means no compression)0.00.10.20.30.40.50.60.70.80.91.0size fraction of <em>chunk</em> categorystoredinterintrainter-intrazeroFigure 16: <em>Chunk</em>- -wise compression. Variable-sizechunking, <em>chunk</em> size 512B except the rightmost barfor 4KB. <em>Chunk</em>- -wise compression is effective butlimited by small window size.ence in ... no additional space, so thereis no reason to remove them.4.4 <em>Chunk</em> CompressionIn this section, we discuss the impact of compressing chunkson ... 7-zipis capable of higher compression than zip. We used theLinux <em>chunk</em> store from Section 4.1 for our compression ex-periments. The final ... 4.1 for our compression ex-periments. The final sizes of the <em>chunk</em> store are shown inTable 5.Figure 16 tells us three things. ... are shown inTable 5.Figure 16 tells us three things. First, <em>chunk</em>- -wise compres-sion can reduce the size of the stored <em>chunks</em> by 40%. Most ofthe saving is contributed by <em>chunks</em> that occur exactly once;shared <em>chunks</em> are unlikely to be further compressed. Sincewe only store a ... further compressed. Sincewe only store a single instance of zero <em>chunks</em>, , the savingfrom such <em>chunks</em> is no more than 1KB. Second, for 512Bchunks, increasing compression ... 512Bchunks, increasing compression level yields negligible bene-fit because the 512B <em>chunks</em> ... do not fully utilize zip’s 32KBsliding window. Third, while larger <em>chunk</em> size yields bettercompression, this effect does not counteract the lower ... not counteract the lower dedu-plication ratio generated by using larger <em>chunks</em>, , and maydeteriorates real-time performance as spending more timeon decompression.5. ... <br /> ... be-cause similar files in different disk images will contain manysimilar <em>chunks</em> in the same order. We are currently workingto evaluate the ... is significant locality, we can improve deduplicationperformance by co-locating nearby <em>chunks</em> from one disk im-age, since those <em>chunks</em> will likely be near one another inother disk images as ... more difficult for an intruder from system A tocompromise encrypted <em>chunks</em> from system B.We have not integrated deduplication into a VMM; ... if no obviously similar VMs are in-volved. However, while smaller <em>chunk</em> sizes provide betterdeduplication, the relative importance of different categoriesof sharing ... relative importance of different categoriesof sharing is largely unaffected by <em>chunk</em> size. As expected,<em>chunk</em>- -wise compression dramatically reduces <em>chunk</em> storesize, but compression level has little effect on the amountspace ... compression level has little effect on the amountspace saved by <em>chunk</em> compression.We also noted that fixed-size <em>chunking</em> works very wellfor VM disk images, outperforming variable-sized chunkingin some ... cases, thus confirming earlier findings [19] stated.In particular, in small <em>chunk</em> stores such as those in theUbuntu Server series experiment in ... is good news for implementers of deduplica-tion systems, since fixed-size <em>chunking</em> is typically easier toimplement, and performs considerably better.Surprisingly, the deduplication ... <br />
<br />
 <strong>Abstract</strong>:<br />
... on different sets of virtual machine disk images with different <em>chunking</em> strategies. Our experiments found that the amount of stored data ... different operating systems are included. We also show that fixed-length <em>chunks</em> ... work well, achieving nearly the same compression rate as variable-length <em>chunks</em>. . Finally, we show that simply identifying zero-filled blocks, even ... <br />
<br />
<strong>References</strong>:<br />
Gupta, D., Lee, S., Vrable, M., Savage, S., Snoeren, A. C., Varghese, G., Voelker, G. M., and Vahdat, A. Difference Engine: Harnessing <em>memory</em> redundancy in virtual machines. In <i>Proceedings of the 8th Symposium on Operating Systems Design and Implementation (OSDI)</i> (Dec. 2008), pp. 309--322. <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
13
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=1900101" target="_self">A running time improvement for the two thresholds two divisors algorithm</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81100056617">Teng-Sheng Moh</a>,
<a href="author_page.cfm?id=99659295739">BingChun Chang</a>
</div>
<div class="source">
<span class="publicationDate">April 2010</span>
<span style="padding-left:10px">ACM SE '10: Proceedings of the 48th Annual Southeast Regional Conference</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 2</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;0</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;8</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;135</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1900101&ftid=868838&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Chunking algorithms play an important role in hash-based data de-duplication systems. The Basic Sliding Window (BSW) algorithm is the first prototype of a content-based chunking algorithm that can handle most types of data. The Two Thresholds Two Divisors (TTTD) algorithm was proposed to improve the BSW algorithm by controlling the ...
</div>
<div class="kw">
<b>Keywords</b>:
chunk, content-based chunking, de-duplication, duplicate, performance, redundancy, signature, threshold
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high1900101');">result highlights</a>]</div>
<div class="highlights" id="high1900101" style="display:none">
<strong>Full Text</strong>:<br />
... San Jose State University San Jose, CA 95192-0249 <a href="/cdn-cgi/l/email-protection" class="__cf_email__" data-cfemail="a7c5cec9c0c4cfd2c989c4cfc6c9c0e7c0cac6cecb89c4c8ca">[email&#160;protected]</a> ABSTRACT <em>Chunking</em> algorithms play an important role in hash-based data de-duplication systems. ... Window (BSW) algorithm is the first prototype of a content-based <em>chunking</em> algorithm that can handle most types of data. The Two ... was proposed to improve the BSW algorithm by controlling the <em>chunk</em>- -size variations. We conducted a series of systematic experiments to ... 6% of the running time and 50% of the large-sized <em>chunks</em>, , and also brought other significant benefits. Categories and Subject ... Systems and Software---Performance evaluation. General Terms Algorithms, Performance, Experimentation. Keywords <em>Chunk</em>, , Content-Based <em>Chunking</em>, , De-Duplication, Duplicate, Performance, Redundancy, Signature, Threshold. 1. INTRODUCTION By ... when a new file arrives, the de-duplication system uses a <em>chunking</em> algorithm to break the entire file into many small blocks ... break the entire file into many small blocks known as <em>chunks</em>. . Then the system uses a hash algorithm, like SHA-1 ... or MD-5 [4, 5], to generate unique signatures for the <em>chunks</em>. . After that, the system can accurately compare those signatures ... signatures with the ones in its database to identify these <em>chunks</em> as new data or redundant data. If the system detects ... already stored in the database. Otherwise, the system treats these <em>chunks</em> ... as new data and stores them in its database. 2. <em>CHUNKING</em> <em>Chunking</em> ... is a process that partitions an entire file into smaller <em>chunks</em>. . This process is the most time consuming since it ... to traverse the entire file. Basically, the smaller size the <em>chunks</em> are, the better de-duplication ratio the system has. However, reducing ... the better de-duplication ratio the system has. However, reducing the <em>chunk</em>- -size means increasing the number of <em>chunks</em> and the size of the lookup table. In the worst ... the lookup table is too large to be loaded into <em>memory</em>. . Then the system has to pay expensive costs in ... in disk I/O [6, 7]. For these reasons, a good <em>chunking</em> algorithm has to satisfy certain conditions, such as minimizing the ... time, balancing the scalability and de-duplication ratio, and controlling the <em>chunk</em>- -size variations. 2.1 <em>Chunking</em> ... Level There are three main approaches according to how a <em>chunking</em> algorithm breaks a file - whole file <em>chunking</em>, , fixed-size <em>chunking</em>, , and variable-size <em>chunking</em> [8, 9]. The whole-file <em>chunking</em> algorithm treats the entire file as a <em>chunk</em>. . Obviously, whole-file <em>chunking</em> is the simplest and fastest, but it has the worst ... even if most of the data is unchanged. The fixed-size <em>chunking</em> algorithm breaks the entire file into many equal-sized <em>chunks</em>. . This approach, however, faces the boundary shifting problem [10, ... 11]. When users modify data, the algorithm will generate different <em>chunk</em> boundaries for all subsequent <em>chunks</em>, , even if most of the data remain unchanged. This ... data remain unchanged. This is because this algorithm determines the <em>chunk</em> boundaries by the distance from the beginning of the file. ... 2010, Oxford, MS, USA. Copyright 2010 ACM 978-1-4503-0064-3/10/04…$10.00. The variable-size <em>chunking</em> algorithm, also known as the content-based <em>chunking</em> algorithm [9, 10, 11], determines the boundaries depending on the ... content of a file. For example, the algorithm may determine <em>chunk</em> boundaries by punctuation marks, lines, or paragraphs. Therefore, when data ... <br /> ... always picks the last backup breakpoint it found as the <em>chunk</em> boundary. In other words, the algorithm wastes unnecessary time finding ... Since the algorithm always picks the last backup breakpoint, the <em>chunks</em> which are determined by the secondD will be close to ... algorithm increases both total running time and the number of <em>chunks</em>. . If these increases in ratios are very large, say ... hardware: z Intel Core2 T7200 2.00GHz processor. z 2GBytes Physical <em>Memory</em>. . z 120GBytes SATA-2 hard disk drive, 5400 RPM. We ... would like to point out three special cases where the <em>chunks</em> could not be determined by algorithm itself: z The size ... second and third cases, we took this fragment as one <em>chunk</em> regardless of what the size was. 5.3 Results of Experiments ... calculated the average of remaining five results. For the average <em>chunk</em>- -size and the total number of <em>chunks</em>, , the results were deterministic. This is because the TTTD ... deterministic. This is because the TTTD algorithm is a content-based <em>chunking</em> algorithm. In other words, once the test data remained unchanged, ... and TTTD algorithms in this section. 5.3.1 Running Time, Total <em>Chunks</em>, , and Average <em>Chunk</em>- -Size The first thing we were interested in was what ... the results in Table 3. Table 3. Running time, total <em>chunks</em> and average <em>chunk</em>- -size comparisons for the BSW and TTTD algorithms. Total Running ... and TTTD algorithms. Total Running Time (sec) Total number of <em>Chunks</em> Average <em>Chunk</em> Size (bytes) Data Set BSW TTTD BSW TTTD BSW TTTD ... see the TTTD algorithm increased the running time and total <em>chunks</em>. . In the average of the cases, the ratio of ... (BSW to TTTD). The ratio of the total number of <em>chunks</em> was about 1:1.13 (BSW to TTTD). These two ratios were ... <br /> the <em>chunks</em> remain unchanged. Hence, the variable-size <em>chunking</em> algorithm avoids the boundary shifting problem. 3. BASIC SLIDING WINDOW ... (BSW) ALGORITHM It is impractical to break a file into <em>chunks</em> by symbols because this kind of approach can only be ... or programming codes. The BSW algorithm was the first content-based <em>chunking</em> algorithm which could handle most types of data. It was ... algorithm sets the current position P as a breakpoint for <em>chunk</em> boundaries. After that, the window W starts at position P ... breakpoint. The parameter D can be configured to make the <em>chunk</em>- -sizes close to our expectations. Since any integer is divided ... after traversing the entire file. In this case, the BSW <em>chunking</em> algorithm is the same as the whole-file <em>chunking</em> algorithm. The second problem is that the BSW algorithm finds ... in every shift. In this case, the size of each <em>chunk</em> equals the size of the sliding window. In other words, ... other words, the BSW algorithm is identical to the fixed-size <em>chunking</em> algorithm. The last problem is that the BSW algorithm may ... the BSW algorithm may generate very large-sized or very small-sized <em>chunks</em>. ... . Thus, the BSW algorithm has poor control over the <em>chunk</em>- -size variations. The first two problems are unusual, but that ... network resources to transmit these very large or very small <em>chunks</em> when one-byte modification happens. 4. TWO THRESHOLDS TWO DIVISOR (TTTD) ... minT are used to eliminate very large and very small <em>chunks</em>. . The mainD plays the same role as D did ... breakpoint by mainD, then the algorithm uses it as the <em>chunk</em> boundary and then repeats the procedures. If the algorithm cannot ... tradeoffs. The TTTD algorithm eliminates very large and very small <em>chunks</em> to control the variations in <em>chunk</em>- -size. Obviously, these eliminations increase the number of <em>chunks</em> and the processing time. The second problem is due to ... Parameters’ configuration for the BSW and TTTD algorithms when expected <em>chunk</em>- -size is 1000 bytes. Algorithm Parameter BSW TTTD Window Size ... <br /> <em>chunk</em>- -size, the results of the TTTD algorithm were much closer ... of the TTTD algorithm were much closer to our expected <em>chunk</em>- -size (1000 bytes) in all data sets. 5.3.2 Maximum and ... (1000 bytes) in all data sets. 5.3.2 Maximum and Minimum <em>Chunk</em>- -Size, and <em>Chunk</em>- -Size Distributions We compared the maximum and minimum <em>chunk</em>- -size as shown in Table 4 to see how much ... how much better the TTTD algorithm controlled the variations in <em>chunk</em>- -size. In all the data sets, all the values of ... all the data sets, all the values of the maximum <em>chunk</em>- -size of the TTTD algorithm were 2800 bytes. The BSW ... The BSW algorithm, however, had a huge variation in maximum <em>chunk</em>- ... -size. This variation was large enough to affect the average <em>chunk</em>- -size. Theoretically speaking, the minimum <em>chunk</em>- -size of the TTTD algorithm should have been 460 bytes ... discussed in Section 5.2. Table 4. The maximum and minimum <em>chunk</em>- -size for the BSW and TTTD algorithms. Max <em>Chunk</em>- -Size (bytes) Min <em>Chunk</em>- -Size (bytes) Data Set BSW TTTD BSW TTTD #1 16442 ... 62 Average 83977 2800 38 138 We also analyzed the <em>chunk</em>- -size distributions to obtain a clearer view. Table 5 and ... for the BSW algorithm and the TTTD algorithm. Table 5. <em>Chunk</em>- -Size distribution of the BSW algorithm. Data Set # Interval ... &gt;= 2800 (%) 6.41 16.41 14.91 11.67 12.35 Table 6. <em>Chunk</em>- -Size distribution of the TTTD algorithm. Data Set # Interval ... the cases, the BSW algorithm had 40.28% of the total <em>chunks</em> less than 460 bytes in size and the TTTD algorithm ... size and the TTTD algorithm had 40.45% of the total <em>chunks</em> between 460 and 799 bytes. In addition, in the average ... the cases, the BSW algorithm had 12.35% of the total <em>chunks</em> larger than or equal to 2800 bytes and the TTTD ... and the maxT to eliminate very large and very small <em>chunks</em>. . Therefore, it obtained better controls over the <em>chunk</em>- -size variations and distributions, and forced the average <em>chunk</em>- -size close to the expected <em>chunk</em>- -size. The results also proved the problem of the tradeoffs ... Second Divisor Problem Firstly, we analyzed the percentages about how <em>chunks</em> ... were determined as shown in Table 7. Table 7. The <em>chunks</em> determination in the TTTD algorithm. Data Set # <em>Chunk</em> Determined #1 #2 #3 #4 Average By Main Divisor 180156 ... (3.08%) 461 (2.36%) 1.9 % On average, most of the <em>chunks</em> (90.3%) were determined by mainD and only 7.8% of the ... were determined by mainD and only 7.8% of the total <em>chunks</em> were determined by secondD. We re-present the data in the ... TTTD algorithm always picks the last backup breakpoint as the <em>chunk</em> boundary. Table 6, Table 7 and Figure 2 prove our ... TTTD algorithm wasted time determining other backup breakpoints, and the <em>chunks</em> determined by the secondD were close to the maxT and ... ~ 27992800Chunk-Size IntervalPercentage %Data Set-1Data Set-2Data Set-3Data Set-4Average Figure 2. <em>Chunk</em>- -Size distribution of the TTTD algorithm. 6.2 Concept of the ... we remove the secondD, then about 10% of the total <em>chunks</em> ... will be determined by maxT. In this case, the 10% <em>chunks</em> are determined by fixed-size <em>chunking</em> and face the boundary shifting problem. However, if we can ... can make the second peak happen earlier, and determine the <em>chunks</em> earlier, then we can reduce the unnecessary calculations and comparisons ... <br /> time, and also minimize the larger <em>chunks</em>. . Based on the results of our experiments, we know ... of our experiments, we know that about 70% of the <em>chunks</em> are determined before 1600 bytes and the second peak begins ... algorithm obtained the best balance between the running time, total <em>chunks</em>, , and average <em>chunk</em>- -size. In practice, the value of switchP should be 1.6 ... the value of switchP should be 1.6 times the expected <em>chunk</em>- -size. In the second part of our experiments, we used ... first results in Table 8. Table 8. Running time, total <em>chunks</em> and average <em>chunk</em>- -size comparisons for the TTTD and TTTD-S algorithms. Total Running ... and TTTD-S algorithms. Total Running Time (sec) Total number of <em>Chunks</em> Average <em>Chunk</em> Size (bytes) Data Set TTTD TTTD-S TTTD TTTD-S TTTD TTTD-S ... the running time. In addition, the TTTD-S made the average <em>chunk</em>- -size closer to the expected <em>chunk</em>- -size from 1168 to 1121 bytes. The only tradeoff was ... tradeoff was that the TTTD-S algorithm increased the number of <em>chunks</em>. . The ratio of the increased <em>chunks</em> ... was about 1:1.05 (TTTD to TTTD-S). Secondly, we present the <em>chunk</em>- -size distribution of the TTTD-S algorithm in Table 9 and ... 6. On average, the TTTD algorithm had 76.47% of its <em>chunks</em> before 1600 bytes (in Table 6), and the TTTD-S had ... (in Table 6), and the TTTD-S had 75.74% of its <em>chunks</em> before 1600 bytes (in Table 9). These two percentages were ... original behaviors of the mainD. In terms of the large-sized <em>chunks</em> (from 2400 to 2800 bytes), the TTTD-S algorithm also reduced ... and also illustrates the above analyses. 8. REFERENCES Table 9. <em>Chunk</em>- -Size distribution of the TTTD-S algorithm. [1] IDC. 2010. Backup ... <br /> ... Companion (Leuven, Belgium, December 01 - 05, 2008). Figure 4. <em>Chunk</em>- -Size distribution of the TTTD-S algorithm. [9] Bobbarjung, D. R., ... H. K. 2005. A Framework for Analyzing and Improving Content-Based <em>Chunking</em> Algorithms. Technical Report, TR 2005-30. Hewlett-Packard Development Company, L.P. http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.html ... August 21 - 24, 2005). This paper focused on the <em>chunking</em> algorithms. There are still many related problems that require further ... <br />
<br />
<strong>Abstract</strong>:<br />
&lt;p&gt;<em>Chunking</em> algorithms play an important role in hash-based data de-duplication systems. ... Window (BSW) algorithm is the first prototype of a content-based <em>chunking</em> algorithm that can handle most types of data. The Two ... was proposed to improve the BSW algorithm by controlling the <em>chunk</em>- -size variations. We conducted a series of systematic experiments to ... 6% of the running time and 50% of the large-sized <em>chunks</em>, <br />
<br />
<strong>References</strong>:<br />
Eshghi, K. and Tang, H. K. 2005. A Framework for Analyzing and Improving Content-Based <em>Chunking</em> Algorithms. Technical Report, TR 2005--30. Hewlett-Packard Development Company, L. P. http://www.hpl.hp.com/techreports/2005/HPL-2005-30R1.html <br />
<br />
<strong>Keywords</strong>:<br />
<em>chunk</em> <br /> content-based <em>chunking</em> <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
14
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=2661777" target="_self">PLWAH+: a bitmap index compressing scheme based on PLWAH</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=99658652137">Jiahui Chang</a>,
<a href="author_page.cfm?id=81414614149">Zhen Chen</a>,
<a href="author_page.cfm?id=99658648483">Wenxun Zheng</a>,
<a href="author_page.cfm?id=99658644588">Yuhao Wen</a>,
<a href="author_page.cfm?id=81100131261">Junwei Cao</a>,
<a href="author_page.cfm?id=99658646244">Wen-Liang Huang</a>
</div>
<div class="source">
<span class="publicationDate">October 2014</span>
<span style="padding-left:10px">ANCS '14: Proceedings of the tenth ACM/IEEE symposium on Architectures for networking and communications systems</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 1</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;2</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;6</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;95</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=2661777&ftid=1507284&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Archiving of the Internet traffic is essential for analyzing network events in the field of network security and network forensics. The bitmap index is widely used to achieve fast searching in archival traffic data requiring a large storage space. As current state-of-art, WAH, PLWAH and COMPAX are proposed for compressing ...
</div>
<div class="kw">
<b>Keywords</b>:
bitmap coding, bitmap index, traffic analysis, data retrieval, internet traffic, traffic forensic
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high2661777');">result highlights</a>]</div>
<div class="highlights" id="high2661777" style="display:none">
<strong>Full Text</strong>:<br />
... is a Fill and the second codeword is a NI <em>Chunk</em>, , this 2-tuple is encoded into a FL codeword, including ... including 0-Fill-NI-0, 0-Fill-NI-1, 1-Fill-NI-0, and 1-Fill-NI-1. Literal: If a Literal <em>Chunk</em> survives after the encoding procedure with FL and LF, it’s ... So the number of the dirty bits in the NI <em>Chunk</em> is no more than four. The counter of the FL ... for the modern CPU architecture. The concept of the NI-1 <em>chunk</em> and the LF word which are not considered in PLWAH ... pp. 99-108, 2002. [4] Van Schaik, Sebastiaan et al. &quot;A <em>memory</em> efficient reachability data structure through bit vector compression.&quot; ACM SIGMOD’ ... <br /> ... bitmap compression scheme. 2. PLWAH+ CODING SCHEME 2.1 Definitions for <em>Chunks</em> ... In PLWAH+ compression scheme, a bit vector is divided into <em>chunks</em> of 31 bits to ensure they are fit into the ... into the L1 cache. At first, we will classify each <em>chunk</em> into different types. Types for a <em>chunk</em> are defined as below: 0-Filled <em>Chunk</em>: : If the 31 bits of a <em>chunk</em> are all ‘0’, we call the <em>chunk</em> 0-Filled <em>Chunk</em>. . 1-Filled <em>Chunk</em>: : If the 31 bits of a <em>chunk</em> are all ‘1’, we call the <em>chunk</em> 1-Filled <em>Chunk</em>. . Literal <em>Chunk</em>: : If a <em>chunk</em> cannot be classified into 0-Filled <em>Chunk</em> or 1-Filled <em>Chunk</em>, , it is called a Literal <em>Chunk</em>. . Dirty Bit: If only a few bits in a ... Dirty Bit: If only a few bits in a Literal <em>Chunk</em> are different from Filled <em>Chunk</em>, , they are all called Dirty Bit. Furthermore, they can ... 1-Dirty Bit (1 bit) and 0-Dirty Bit (0 bit). NI <em>Chunk</em>: : If a <em>Chunk</em> is a Literal <em>Chunk</em> with less than 4 Dirty Bit, it is called a ... less than 4 Dirty Bit, it is called a NI <em>Chunk</em>. . The NI <em>Chunk</em> can be divided into two parts as follows: NI-0 <em>Chunk</em>: : If a <em>Chunk</em> is nearly identical to the ‘0’ sequence with less than ... less than 4 1-Dirty Bits, it is called a NI-0 <em>Chunk</em>. . NI-1 <em>Chunk</em>: : If a <em>Chunk</em> is nearly identical to the ‘1’ sequence with less than ... less than 4 0-Dirty Bits, it is called a NI-1 <em>Chunk</em>. ... . 2.2 Definitions for Codewords After the categorization of the <em>chunks</em>, , we begin to encode the bitmap roughly into the ... as shown below: 0-Fill: If there are some continuous 0-Filled <em>Chunks</em>, , replace them with a 0-Fill codeword which indicates the ... a 0-Fill codeword which indicates the number of the replaced <em>chunks</em>. . 1-Fill: If there are some continuous 1-Filled <em>chunks</em>, , replace them with a 1-Fill codeword which indicates the ... a 1-Fill codeword which indicates the number of the replaced <em>chunks</em>. . Permission to make digital or hard copies of part ... in the sequence, if the first element is a NI <em>Chunk</em> and the second codeword is a Fill, this 2-tuple is ... <br />
<br />
<strong>References</strong>:<br />
Van Schaik, Sebastiaan et al. "A <em>memory</em> efficient reachability data structure through bit vector compression." ACM SIGMOD' 2011, pp.913--924, 2011. <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
15
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=1072224" target="_self">T&#252;SBL: a similarity-based chunk parser for robust syntactic processing</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81100336195">Sandra K&#252;bler</a>,
<a href="author_page.cfm?id=81329489276">Erhard W. Hinrichs</a>
</div>
<div class="source">
<span class="publicationDate">March 2001</span>
<span style="padding-left:10px">HLT '01: Proceedings of the first international conference on Human language technology research</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;Association for Computational Linguistics
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 2</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;4</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;13</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;81</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1072224&ftid=569800&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Chunk parsing has focused on the recognition of partial constituent structures at the level of individual chunks. Little attention has been paid to the question of how such partial analyses can be combined into larger structures for complete utterances.The T&uuml;SBL parser extends current chunk parsing techniques by a tree-construction component ...
</div>
<div class="kw">
<b>Keywords</b>:
similarity-based learning, robust parsing, chunk parsing
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high1072224');">result highlights</a>]</div>
<div class="highlights" id="high1072224" style="display:none">
<strong>Full Text</strong>:<br />
chunkparsing.dviTu SBL: A Similarity-Based <em>Chunk</em> Parserfor Robust Syntactic ProcessingSandra Ku blerSeminar fu r SprachwissenschaftUniversity of Tu bingenWilhelmstr. 113D-72074 ... the recognition of partial constituentstructures at the level of individual <em>chunks</em>. . Little attention has beenpaid to the question of how ... combinedinto larger structures for complete utterances.The Tu SBL parser extends current <em>chunk</em> parsing techniques bya tree-construction component that extends partial <em>chunk</em> parses tocomplete tree structures including recursive phrase structure as wellas ... function-argument structure. Tu SBL’s tree construction algo-rithm relies on techniques from <em>memory</em>- -based learning that allowsimilarity-based classification of a given input structure ... as its main goal robustness of partially analyzed struc-tures.Keywordsrobust parsing, <em>chunk</em> parsing, similarity-based learning1. INTRODUCTIONCurrent research on natural language parsing tends ... aim atcomplete analysis for a narrowly defined set of data. <em>Chunk</em> pars-ing [1, 2] offers a particularly promising and by now ... to isolate the (finite-state) analysis of non-recursive, syntactic structure, i.e. <em>chunks</em>, , from larger, recursivestructures. This results in a highly-efficient parsing ... pattern-matching strategy at eachlevel of analysis.Despite the popularity of the <em>chunk</em> parsing approach, there seemto be two apparent gaps in current ... approach, there seemto be two apparent gaps in current research:1. <em>Chunk</em> parsing research has focused on the recognition ofpartial constituent structures ... complete utterances.2. Relatively little has been reported on quantitative evaluationsof <em>chunk</em> parsers that measure the correctness of the outputstructures obtained by ... that measure the correctness of the outputstructures obtained by a <em>chunk</em> parser.The main goal of the present paper is help close ... order to ensure a robust and efficient architecture, Tu SBL, asimilarity-based <em>chunk</em> parser, is organized in a three-level archi-tecture, with the output ... speech serve as pre-terminal elements for the next step,i.e. the <em>chunk</em> analysis. <em>Chunk</em> parsing is carried out by an adaptedversion of Abney’s [2] ... parser, which is realized as a cascadeof finite-state transducers. The <em>chunks</em>, , which extend if possible tothe simplex clause level, are ... sentences took 106.5 seconds to parse on an Ultra Sparc10).3. <em>CHUNK</em> PARSING AND TREE CONSTRUC-TIONThe division of labor between the <em>chunking</em> and tree constructionmodules can best be illustrated by an example.1The ... August(then I would suggest maybe Thursday eleventh and Friday twelfthof August)<em>Chunk</em> <br /> ... Donnerstag][art den][adja elften]][kon und][nx3 [day Freitag][art den][adja zw&quot;olften][month August]]Figure 1: <em>Chunk</em> parser outputFor complex sentences such as the German input dann ... some constituents remain unattached or partiallyannotated in keeping with the <em>chunk</em>- -parsing strategy to factor outrecursion and to resolve only unambigous ... a completely flat struc-ture. Tu SBL’s tree construction module enriches the <em>chunk</em> outputas shown in Fig. 22. Here the internally recursive NP ... tree construction algorithm is based on the machine learningparadigm of <em>memory</em>- -based learning [12].3 <em>Memory</em>- -based learn-ing assumes that the classification of a given input ... seen instances of the same type thathave been stored in <em>memory</em>. . This paradigm is an instance of lazylearning in the ... case in rule-based systems or other learning approaches.Past applications of <em>memory</em>- -based learning to NLP tasks consistof classification problems in which ... the number of distinct items is small.The use of a <em>memory</em>- -based approach for parsing implies thatparsing needs to be redefined ... to a variety ofNLP classification tasks, including part-of-speech tagging, nounphrase <em>chunking</em>, , grapheme-phoneme conversion, word sense dis-ambiguation, and pp attachment (see ... dis-ambiguation, and pp attachment (see [9], [14], [15] for details).2construct tree(<em>chunk</em> list, treebank):while (<em>chunk</em> list is not empty) doremove first <em>chunk</em> from <em>chunk</em> listprocess <em>chunk</em>( (<em>chunk</em>, , treebank)Figure 3: Pseudo-code for tree construction, main routine.process <em>chunk</em>( (<em>chunk</em>, , treebank):words := string yield(<em>chunk</em>) )tree := complete match(words, treebank)if (tree is not empty) direct ... treebank)if (tree is not empty) direct hit,then output(tree) i.e. complete <em>chunk</em> found in treebankelsetree := partial match(words, treebank)if (tree is not ... match(words, treebank)if (tree is not empty)thenif (tree = postfix of <em>chunk</em>) )thentree1 := attach next <em>chunk</em>( (tree, treebank)if (tree is not empty)then tree := tree1if ((<em>chunk</em> - tree) is not empty) if attach next <em>chunk</em> succeededthen tree := extend tree(<em>chunk</em> - tree, tree, treebank) <em>chunk</em> might consist of both chunksoutput(tree)if ((<em>chunk</em> - tree) is not empty) <em>chunk</em> might consist of both <em>chunks</em> (s.a.)then process <em>chunk</em>( (<em>chunk</em> - tree, treebank) i.e. process remaining chunkelse back off to ... process remaining chunkelse back off to POS sequencepos := pos yield(<em>chunk</em>) )tree := complete match(pos, treebank)if (tree is not empty)then output(tree)else ... treebank)if (tree is not empty)then output(tree)else back off to subchunkswhile (<em>chunk</em> is not empty) doremove first subchunk c1 from chunkprocess <em>chunk</em>( (c1, treebank)Figure 4: Pseudo-code for tree construction, subroutine process chunk.this ... <br /> the classification task is muchmore complex, and the standard <em>memory</em>- -based approach needs tobe adapted to the requirements of the ... POS tags and (to alesser degree) the labels in the <em>chunk</em> parse. Rather than choosing abag-of-words approach, since word order is ... from the instance base needsto be modified to match the <em>chunked</em> input.If these strategies for matching complete trees fail, Tu SBL at-tempts ... form in Figs. 3-6. For readability’s sake, we assumehere that <em>chunks</em> and complete trees share the same data structureso that subroutines ... construct tree in Fig. 3 separates the list of in-put <em>chunks</em> and passes each one to the subroutine process <em>chunk</em> inFig. 4 where the <em>chunk</em> is then turned into one or more (partial)trees. process <em>chunk</em> first checks if a complete match with an in-stance from ... level is attempted. If a partial treeis found, attach next <em>chunk</em> in Fig. 5 and extend tree in Fig. 6 areused ... areused to extend the tree by either attaching one more <em>chunk</em> or by re-sorting to a comparison of the missing parts ... re-sorting to a comparison of the missing parts of the <em>chunk</em> with treeextensions on the POS level. attach next <em>chunk</em> is necessary to en-sure that the best possible tree is ... found even in the rare case that theoriginal segmentation into <em>chunks</em> contains mistakes. If no partialtree is found, the tree construction ... the POS level or to starting the subroutine for processinga <em>chunk</em> recursively with all the subchunks of the present chunk.The application ... with all the subchunks of the present chunk.The application of <em>memory</em>- -based techniques is implemented inthe two subroutines complete match and ... the inputstructure, pos yield the sequence of POS tags.3attach next <em>chunk</em>( (tree, treebank): attempts to attach the next <em>chunk</em> to the treetake first <em>chunk</em> chunk2 from <em>chunk</em> listwords2 := string yield(tree, chunk2)tree2 := complete match(words2, treebank)if (tree2 ... := complete match(words2, treebank)if (tree2 is not empty)thenremove chunk2 from <em>chunk</em> listreturn tree2else return emptyFigure 5: Pseudo-code for tree construction, subroutine ... 5: Pseudo-code for tree construction, subroutine attach next chunk.extend tree(rest <em>chunk</em>, , tree, treebank): extends the tree on basis of POS ... of POS comparisonwords := string yield(tree)rest pos := pos yield(rest <em>chunk</em>) )tree2 := partial match(words + rest pos, treebank)if ((tree2 is ... necessary for par-tial matches and which also deviates from standard <em>memory</em>- -basedapplications. Postprocessing mainly consists of shortening the treefrom the instance ... corrections of tagging and segmentation errors thatmay occur in the <em>chunked</em> input.4.1 ExampleInput:dann w”urde ich sagen ist das vereinbart(then I would ... ich sagen ist das vereinbart(then I would say this is arranged)<em>Chunk</em> parser output:[simpx [advx [adv dann]][vxfin [vafin w&quot;urde]][nx2 [pper ich]][vvinf sagen]][simpx ... w&quot;urde]][nx2 [pper ich]][vvinf sagen]][simpx [vafin ist][nx2 [pds das]][vvpp vereinbart]]Figure 7: <em>Chunk</em> parser outputFor the input sentence dann w”urde ich sagen ist ... ist das vereinbart(then I would say this is arranged), the <em>chunked</em> <br /> ... this paper we have described how the Tu SBL parser extendscurrent <em>chunk</em> parsing techniques by a tree-construction compo-nent that completes partial <em>chunk</em> parses to tree structures includingfunction-argument structure.As noted in section 4, ... framework of the Sonderforschungsbereich 441.8. REFERENCES[1] S. Abney. Parsing by <em>chunks</em>. . In R. Berwick, S. Abney, andC. Tenney, editors, Principle-Based ... Universita t Tu bingen, 1995. (URL:http://www.sfs.nphil.uni-tuebingen.de/Elwis/stts/stts.html).[12] C. Stanfill and D. Waltz. Towards <em>memory</em>- -based reasoning.Communications of the ACM, 29(12), 1986.[13] R. Stegmann, H. ... A. van den Bosch, S. Buchholz, W. Daelemans,and J. Zavrel. <em>Memory</em>- -based word sense disambiguation.Computers and the Humanities, Special Issue on ... Zavrel, W. Daelemans, and J. Veenstra. Resolving PPattachment ambiguities with <em>memory</em>- -based learning. InM. Ellison, editor, Proceedings of the Workshop onComputational ... <br /> 7. The <em>chunk</em> parser correctly splits the input into two clausesTable 1: Quantitative ... input. This runs counter tothe basic philosophy underlying an amended <em>chunk</em> parser such asTu SBL, which has as its main goal robustness ... <br />
<br />
<strong>Abstract</strong>:<br />
<em>Chunk</em> parsing has focused on the recognition of partial constituent structures ... recognition of partial constituent structures at the level of individual <em>chunks</em>. . Little attention has been paid to the question of ... into larger structures for complete utterances.The T&amp;uuml;SBL parser extends current <em>chunk</em> parsing techniques by a tree-construction component that extends partial <em>chunk</em> parses to complete tree structures including recursive phrase structure as ... function-argument structure. T&amp;uuml;SBL's tree construction algorithm relies on techniques from <em>memory</em>- -based learning that allow similarity-based classification of a given input ... <br />
<br />
<strong>References</strong>:<br />
S. Abney. Parsing by <em>chunks</em>. In R. Berwick, S. Abney, and C. Tenney, editors, Principle-Based Parsing. Kluwer Academic Publishers, 1991. <br /> C. Stanfill and D. Waltz. Towards <em>memory</em>-based reasoning. Communications of the ACM, 29(12), 1986. <br /> J. Veenstra, A. van den Bosch, S. Buchholz, W. Daelemans, and J. Zavrel. <em>Memory</em>-based word sense disambiguation. Computers and the Humanities, Special Issue on Senseval, Word Sense Disambiguations, 34, 2000. <br /> J. Zavrel, W. Daelemans, and J. Veenstra. Resolving PP attachment ambiguities with <em>memory</em>-based learning. In M. Ellison, editor, Proceedings of the Workshop on Computational Natural Language Learning (CoNLL'97), Madrid, 1997. <br />
<br />
<strong>Keywords</strong>:<br />
<em>chunk</em> parsing <br />
<br />
<strong>Title</strong>:<br />
T&#252;SBL: a similarity-based <em>chunk</em> parser for robust syntactic processing <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
16
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=1117642" target="_self">Hybrid text chunking</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81408601310">GuoDong Zhou</a>,
<a href="author_page.cfm?id=81100109197">Jian Su</a>,
<a href="author_page.cfm?id=81310483661">TongGuan Tey</a>
</div>
<div class="source">
<span class="publicationDate">September 2000</span>
<span style="padding-left:10px">ConLL '00: Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning - Volume 7</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;Association for Computational Linguistics
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 10</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;6</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;17</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;120</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1117642&ftid=364538&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
This paper proposes an error-driven HMM-based text chunk tagger with context-dependent lexicon. Compared with standard HMM-based tagger, this tagger incorporates more contextual information into a lexical entry. Moreover, an error-driven learning approach is adopted to decrease the memory requirement by keeping only positive lexical entries and makes it possible to ...
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high1117642');">result highlights</a>]</div>
<div class="highlights" id="high1117642" style="display:none">
<strong>Full Text</strong>:<br />
... CoNLL-2000 and LLL-2000, pages 163-165, Lisbon, Portugal, 2000. Hybrid Text <em>Chunking</em> GuoDong Zhou and J ian Su and TongGuan Tey Kent ... rac t This paper proposes an error-driven HMM- based text <em>chunk</em> tagger with context-dependent lexicon. Compared with standard HMM-based tagger, this ... an error-driven learning approach is adopted to de- crease the <em>memory</em> requirement by keeping only positive lexical entries and makes it ... it possible to further incorporate more context-dependent lexical entries. Finally, <em>memory</em>- -based learning is adopted to further improve the performance of ... learning is adopted to further improve the performance of the <em>chunk</em> tagger. 1 In t roduct ion The idea of using ... In t roduct ion The idea of using statistics for <em>chunking</em> goes back to Church(1988), who used corpus frequen- cies to ... Brants' way by employing HMM-based tagging method to model the <em>chunking</em> process. 2 HMM-based <em>Chunk</em> Tagger w i th Context -dependent Lex icon Given a ... context-dependent lexicon while others use a context-independent lexicon. 163 For <em>chunk</em> tagger, we have gl = piwi where W~ = wlw2&quot;&quot;Wn ... the part-of-speech(POS) sequence. Here, we use structural tags to representing <em>chunking</em>( (bracketing and labeling) structure. The basic idea of representing the ... input token and the current one. For the recognition of <em>chunks</em>, , it is suffi- cient to distinguish the following four ... input to- ken have the same parent Compared with the B-<em>Chunk</em> and I-<em>Chunk</em> used in Ramshaw and Marcus(1995)~, structural relations 99 and 90 ... Ramshaw and Marcus(1995)~, structural relations 99 and 90 correspond to B-<em>Chunk</em> which represents the first word of the <em>chunk</em>, , and structural relations 00 and 09 correspond to I-<em>Chunk</em> which represents each other in the <em>chunk</em> while 90 also means the beginning of the sentence and ... structural tag to represent more accurate models. Principally, the current <em>chunk</em> <br /> ... words and their POSs. How- ever, in order to decrease <em>memory</em> require- ment and computational complexity, our base- line HMM-based <em>chunk</em> tagger only considers previous POS, current POS and their word ... 89.58%, 89.56% and 89.57%. 3 Error-driven Learning After analysing the <em>chunking</em> results, we find many errors are caused by a limited ... to overcome such errors, we include such words in the <em>chunk</em> ... dependence context by using error-driven learning. First, the above HMM-based <em>chunk</em> tagger is used to <em>chunk</em> the training data. Secondly, the <em>chunk</em> tags determined by the <em>chunk</em> tagger are com- pared with the given <em>chunk</em> tags in the training data. For each word, its <em>chunking</em> error number is summed. Finally, those words whose <em>chunk</em>- - ing error numbers are equal to or above a ... or above a given threshold(i.e. 3) are kept. The HMM-based <em>chunk</em> ... tagger is re-trained with those words con- sidered in the <em>chunk</em> dependence context. The overall precision, recall and FZ=i rates of ... overall precision, recall and FZ=i rates of our error-driven HMM-based <em>chunk</em> tagger on the test data of the shared task are ... of the shared task are 91.53%, 92.02% and 91.77 4 <em>Memory</em> based Learning <em>Memory</em>- -based learning has been widely used in NLP tasks in ... pat- terns and Daelemans et a1.(1999) for shallow parsing. The <em>memory</em>- -based method presented here follows the second paradigm and makes ... training cor- pus. Given one of the N most probable <em>chunk</em> se- quences extracted by the error-driven HMM- based <em>chunk</em> tagger, we can extract a set of <em>chunk</em> patterns, each of them with the format: XP 1 n ... ][NP September/NNP ] [O ./. ] we can extract following <em>chunk</em> patterns: NP=NULL 90 PRP 99 VBZ VP=PRP 99 VBZ 99 ... NNP 99 . O=NNP 99 . 09 NULL For every <em>chunk</em> pattern, we estimate its proba- bility by using <em>memory</em>- -based learning. If the <em>chunk</em> pattern exists in the training corpus, its probability is computed ... computed by the probability of such pattern among all the <em>chunk</em> patterns. Otherwise, its probability is estimated by the multiply of ... Then the probability of each of the N most probable <em>chunk</em> ... sequences is adjusted by multiplying the probabilities of its extracted <em>chunk</em> patterns. Table 1 shows the performance of error-driven HMM-based <em>chunk</em> tagger with <em>memory</em>- -based learning. 5 Conc lus ion It is found that ... of error-driven learning is improved by 2.20% and integration of <em>memory</em>- -based learning further improves the performance by 0.35% to 92.12%. ... speculated in the near future. Finally, a closer integration of <em>memory</em>- -based method with HMM-based <em>chunk</em> tagger will also be conducted. test data ADJP ADVP CONJP ... 92.39 96.51 77.73 81.64 92.81 92.12 Table 1: performance of <em>chunking</em> ... References S. Argamon, I. Dagan, and Y. Krymolowski. 1998. A <em>memory</em>- -based approach to learning shallow natural language patterns. In COLING/ACL- ... <br /> ... J. Zavrel, P. Berck, and S. Gillis. 1996. Mbt: A <em>memory</em>- -based part-of-speech tag- ger generator. In Proceeding of the Fourth ... ACL SIGDAT. W. Daelemans, S. Buchholz, and J. Veenstra. 1999. <em>Memory</em>- -based shallow parsing. In CoNLL-1999, pages 53-60. Bergen, Norway. L.R. ... 257-286. Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text <em>chunking</em> using transformation-based learn- ing. In Proceedings of the Third ACL ... Cambridge, Mas- sachusetts, USA. W. Skut and T. Brants. 1998. <em>Chunk</em> tagger: sta- tistical recognition of noun phrases. In ESSLLI- 1998 ... <br />
<br />
<strong>Abstract</strong>:<br />
This paper proposes an error-driven HMM-based text <em>chunk</em> tagger with context-dependent lexicon. Compared with standard HMM-based tagger, this ... Moreover, an error-driven learning approach is adopted to decrease the <em>memory</em> requirement by keeping only positive lexical entries and makes it ... it possible to further incorporate more context-dependent lexical entries. Finally, <em>memory</em>- -based learning is adopted to further improve the performance of ... learning is adopted to further improve the performance of the <em>chunk</em> <br />
<br />
<strong>References</strong>:<br />
S. Argamon, I. Dagan, and Y. Krymolowski. 1998. A <em>memory</em>-based approach to learning shallow natural language patterns. In COLING/ACL-1998, pages 67--73. Montreal, Canada. <br /> W. Daelemans, J. Zavrel, P. Berck, and S. Gillis. 1996. Mbt: A <em>memory</em>-based part-of-speech tagger generator. In Proceeding of the Fourth Workshop on Large Scale Corpora, pages 14--27. ACL SIGDAT. <br /> W. Daelemans, S. Buchholz, and J. Veenstra. 1999. <em>Memory</em>-based shallow parsing. In CoNLL-1999, pages 53--60. Bergen, Norway. <br /> Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text <em>chunking</em> using transformation-based learning. In Proceedings of the Third ACL Workshop on Very Large Corpora. Cambridge, Massachusetts, USA. <br /> W. Skut and T. Brants. 1998. <em>Chunk</em> tagger: statistical recognition of noun phrases. In ESSLLI-1998 Workshop on Automated Acquisition of Syntax and Parsing. Saarbruucken, Germany. <br />
<br />
<strong>Title</strong>:<br />
Hybrid text <em>chunking</em> <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
17
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=253288" target="_self">An array-based algorithm for simultaneous multidimensional aggregates</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81100536952">Yihong Zhao</a>,
<a href="author_page.cfm?id=81100017221">Prasad M. Deshpande</a>,
<a href="author_page.cfm?id=81100509752">Jeffrey F. Naughton</a>
</div>
<div class="source">
<span class="publicationDate">June 1997</span>
<span style="padding-left:10px">SIGMOD '97: Proceedings of the 1997 ACM SIGMOD international conference on Management of data</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 164</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;7</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;59</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;1,763</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=253288&ftid=16921&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Computing multiple related group-bys and aggregates is one of the core operations of On-Line Analytical Processing (OLAP) applications. Recently, Gray et al. [GBLP95] proposed the &ldquo;Cube&rdquo; operator, which computes group-by aggregations over all possible subsets of the specified dimensions. The rapid acceptance of the importance of this operator has led ...
</div>
<div class="pubother">
Also published in:<br />
June 1997&nbsp;
ACM SIGMOD Record: Volume 26 Issue 2, June 1997
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high253288');">result highlights</a>]</div>
<div class="highlights" id="high253288" style="display:none">
<strong>Full Text</strong>:<br />
... to be revisited for eachsub-aggregate. To do so with minimal <em>memory</em> requires agreat deal of care and attention to the size ... that in order to store arrays efficiently on disk,one must “<em>chunk</em>” ” them into small <em>memory</em>- -sized pieces, andperform some sort of “compression” to avoid wasting ... computation of multiple subaggregates, and makesgood use of available main <em>memory</em>. . We prove a number oftheorems about the algorithm, including ... is organized as follows. In Sec-tion 2, we introduce the <em>chunked</em> array representation, andthen discuss how we compressed these arrays and ... how we compressed these arrays and our algo-rithm for loading <em>chunked</em>, , compressed arrays from tables.We then present a basic array ... with some theorems that showhow to predict and minimize the <em>memory</em> requirements forthe algorithm. We present the performance results in Sec-tion ... <br /> ... that the array itseff is far toolarge to fit in <em>memory</em>. ... . In this case, the array must be splitup into “<em>chunks</em>” ”, each of which is small enough to fit com-fortably ... each of which is small enough to fit com-fortably in <em>memory</em>. . Second, even with this ‘<em>chunking</em>” ”, it islikely that many of the cells in the ... efficiently store this sort of data we need to compressthese <em>chunks</em>. . Third, in many cases an array may need tobe ... description of an efficient algorithm forloading arrays in our compressed, <em>chunked</em> format.2.1 <em>Chunking</em> ArraysAs we have mentioned, for high performance large arraysmust be ... high performance large arraysmust be stored broken up into smaller <em>chunks</em>. . The stan-dard programming language technique of storing the arrayin ... pages.To have a uniform treatment for all the dimensions, wecan <em>chunk</em> the array, as suggested by Sarawagi [SM94]. <em>Chunk</em>- -ing is a way to divide an n-dimensional array into ... a way to divide an n-dimensional array into smaff sizen-dimensional <em>chunks</em> and store each <em>chunk</em> as one objecton disk. Each array <em>chunk</em> has n dimensions and will cor-respond to the blocking size ... offset, along with the data element, into a tuple,For dense <em>chunks</em>, , which we define as those in which morethan 40~o ... product, store, or datevalues in the array.However, for a sparse <em>chunk</em>, , that is one with data den-sity less than 4070, ... to invalid cells.In this case we use what we call “<em>chunk</em>- -offset compression.”In <em>chunk</em>- -offset compression, for each valid array entry, westore a pair, ... The offsetlnChunk in-teger can be computed as follows: consider the <em>chunk</em> as anormal (uncompressed) array. Each celf c in the <em>chunk</em> isdefined by a set of indices; for example, if we ... of indices; for example, if we are workingwith a three-dimensional <em>chunk</em>, , a given cell wiff have an“address” (i, ~“,k) in ... a given cell wiff have an“address” (i, ~“,k) in the <em>chunk</em>. . To access this cell in mem-ory, we would convert ... (i, j, k) into an offset fromthe start of the <em>chunk</em>, ... , typically by assuming that the chunkis laid out in <em>memory</em> in some standard order. This offset isthe “offset InChunk” integer ... offset isthe “offset InChunk” integer we store.Since in this representation <em>chunks</em> will be of variablelength, we use some meta data to ... First, the compression ratio itself was not as goodas the “<em>chunk</em>- -offset compression. ” Intuitively, this is be-cause LZ W compression ... this is be-cause LZ W compression uses no domain knowledge, whereas“<em>chunk</em>- -oflset compression” can use the fact that it is storingarray ... is necessary to mat eri-alize the (possibly very sparse) fulf <em>chunk</em> in <em>memory</em> beforeit can be operated on. By contrmt, with <em>chunk</em>- -offset com-pression we can operate directly on the compressed <em>chunk</em>. .2.3 Loading Arrays from TablesWe have designed and implemented a ... a relational table or external loadfile to a (possibly compressed) <em>chunked</em> array. As input thealgorithm takes the table, along with each ... takes the table, along with each dimension sizeand a predefied <em>chunk</em> <br /> ... the full array and the chunksize, we know how many <em>chunks</em> are in the array to be loaded.If the available <em>memory</em> size is less than the size of the re-sulting array, ... size of the re-sulting array, we partition the set of <em>chunks</em> ... into partitionsso that the data in each partition fits in <em>memory</em>. . (This par-titioning is logical at this phase. For example, ... is logical at this phase. For example, if we have8 <em>chunks</em> O - 7, and we need two partitions, we would ... partitions, we would puttuples corresponding to cells that map to <em>chunks</em> o-3 in par-tition one, and those that map to <em>chunks</em> 4-7 in partitiontwo. )Once the partitions have been determined, the ... algorithmscans the table. For each tuple, the afgorithm calculates thetuple’s <em>chunk</em> number and the offset from the first elementof its <em>chunk</em>. . This is possible by examining the dimensionvalues in the ... and assigns it to a bucket in memoryaccording to its <em>chunk</em> number. Each bucket corresponds toa unique <em>chunk</em>. . Once we assign all tuples to buckets, the al-gorithm ... we assign all tuples to buckets, the al-gorithm constructs array <em>chunks</em> for each bucket, compressesthem if necessary using <em>chunk</em>- -offset compression, and writesthose <em>chunks</em> to disk. One optimization is to compute thechunks of the ... each partition a btier page, we allocate the rest ofavailable <em>memory</em> to the buckets for the first partition. Thisis similar to ... Hash Join algo-rithm [DKOS84] to keep the “first bucket” in <em>memory</em>. .3 A Basic Array Cubing AlgorithmWe first introduce an algorithm ... of relatedgroupbys.First consider how to compute a group-by from a simplenon-<em>chunked</em> array. Suppose we have a three dimensionalarray, with dimensions A, ... suppose that this ABC array is stored in a numberof <em>chunks</em>. . Again the computation can be viewed as sweep-ing through ... of the A and B dimensions,we do it on a <em>chunk</em> by <em>chunk</em> basis. Suppose that the Adimension in a <em>chunk</em> has size Ac, and the B dimension in achunk has ... C goingback into the paper) we can begin with the <em>chunk</em> in theupper left-hand portion of the array, and sweep a ... array, and sweep a plane ofsize A.&amp; back through that <em>chunk</em>, , aggregating away the Cvalues as we go. Once we ... right of the ini-tiaf chunk.Note that in this way each <em>chunk</em> is read only once, andthat at the end of the ... memoryused by this computation is only enough to hold one <em>chunk</em>, ,plus enough to hold the A.BC plane as it is ... to hold the A.BC plane as it is swept throughthe <em>chunks</em>. . This generalization of this algorithm to higherdimensions is straight-forward; ... <br /> ... until thev arecomputed, so heuristics must be used. For our <em>chunk</em>- -~asedarray algorithm we are more fortunate, since by knowingthe dimension ... .. Dik+l, which has theminimum size. We read in each <em>chunk</em> of D,l D,, .. Di,+lalong the dimension D, ~ ~ ... .. Di,+lalong the dimension D, ~ ~ and aggregate each <em>chunk</em> to ach~k of Di, Dt,,, Dtk. dnce the <em>chunk</em> of Di,Di,..D,, iscomplete, we output the <em>chunk</em> to disk and use the memoryfor the next <em>chunk</em> of D,l D,Q. .D,,. Note that we need tokeep only ... Note that we need tokeep only one D,l D,,.. D,, <em>chunk</em> in <em>memory</em> at any time.In this paper, we will use a three ... 16 x 16 array with4 x 4 x 4 array <em>chunks</em> laid out in the dimension order ABC(see Figure 1). The ... is indicated by the chunknumbers shown in the figure. The <em>chunks</em> are numbered from1 to 64. The Cube of the array ... For examde, to comrmte theBC group-by, we read in the <em>chunk</em> number order f~om 1 to64, aggregate each four ABC <em>chunks</em> to a BC <em>chunk</em>, , outputthe BC <em>chunk</em> to disk, and reuse the <em>memory</em> for the nextBC chunk.While this algorithm is fairly careful about ... hi-erarchy of aggregates to compute the cube and using min-imal <em>memory</em> for each step, it is somewhat naive in that itcomputes ... these group-bys wilf also be represented asarrays, Idealfy, we need <em>memory</em> large enough to hold allthese group-bys so that we can ... than the btier pool size. Our algorithmtries to minimize the <em>memory</em> needed for each computation,so that we can achieve maximum overlap. ... in two steps. Initially we will assume thatthere is sufficient <em>memory</em> to compute alf the group-bys inone scan. Later we will ... algorithm, it is not necessaryto keep the entire array in <em>memory</em> for any group-by —keeping only the relevant part of the ... group-by —keeping only the relevant part of the array in <em>memory</em> ateach step wilf suffice. Thus we wilf be reducing memoryrequirements ... reducing memoryrequirements by keeping only parts of the group-by arraysin <em>memory</em>. . When computing multiple group-bys simuk,ane-ously, the total <em>memory</em> required depends critically on theorder in which the input array ... array is scanned. In order to reducethis total amount of <em>memory</em> our algorithm makes use of aspecial logical order called “dimension ... called “dimension order”.4.1.1 Dimension OrderA dimension order of the array <em>chunks</em> is a row major orderof the <em>chunks</em> with the n dimensions DI, DZ, . . . D. ... dimension orders 0’lead to different orders of reading the array <em>chunks</em>. . Notethat this Iogicaf order of reading is independent of ... reading is independent of the ac-tuaf physicaf layout of the <em>chunks</em> on the disk, The chunksof array may be laid out ... <br /> the amount of <em>memory</em> needed for thecomputation.4.1.2 <em>Memory</em> RequirementsAssuming that we read in the array <em>chunks</em> in a dimensionorder. we can formulate a general rule to ... need to stay in memoryin order to avoid rescanning a <em>chunk</em> of the input array,We use the above 3-D array to ... above 3-D array to illustrate the rule with anexample.The array <em>chunks</em> are read in the dimension order ABC,i.e.. from <em>chunk</em> 1 to <em>chunk</em> 64. SuDDose <em>chunk</em> 1 is readin. ‘For group-by AB, this <em>chunk</em> is z&amp;regated along the Cdimension to get a <em>chunk</em> of AB. Similarly for AC and BC,this <em>chunk</em> is aggregated along B and A dimensions respec-tively. Thus the ... respec-tively. Thus the tirst chunk’s AB groupby is aggregated tothe <em>chunk</em> ... aobo of AB; the first chunk’s AC’ is aggregatedto the <em>chunk</em> aoco of AC; the first chunk’s BC is aggre-gated to ... of AC; the first chunk’s BC is aggre-gated to the <em>chunk</em> bOCOof BC. As we read in new <em>chunks</em>, ,we aggregate the chunk’s .4B, AC and BC group-by to ... aggregate the chunk’s .4B, AC and BC group-by to thecorresponding <em>chunks</em> of group-bys A B, .4C and BC. Tocompute each <em>chunk</em> of AB, AC, and BC group-by, we may162cob3b2blbOC2c1Dimension B,;- --; ... v’tlo 11 a2 a3Dimension AFigure 1: 3 D arraynaively aflocate <em>memory</em> to each <em>chunk</em> of those group-bysin <em>memory</em>. . However, we can exploit the order in which eachchunk ... can exploit the order in which eachchunk is brought in <em>memory</em> to reduce the <em>memory</em> requiredby each group-by to the minimum so that we can ... of the arrayABC.Let us look into how we compute each <em>chunk</em> of thosegroupbys in detail. Notice that we read the <em>chunks</em> in di-mension order (A, B, C) layout, which is a ... C) layout, which is a linear order fromchunk 1 to <em>chunk</em> 64. For the <em>chunk</em> 1 to <em>chunk</em> 4, we com-plete the aggregation for the <em>chunk</em> ... bOCOof BC after aggre-gating each chunk’s BC group-by to the <em>chunk</em> bOco of BC.Once the boco <em>chunk</em> is completed, we write out the chunkand reassign the <em>chunk</em> <em>memory</em> to the <em>chunk</em> bl co, which iscomputed from the next 4 <em>chunks</em> of ABC i.e. the <em>chunk</em> 4to <em>chunk</em> 8. So we allot only one <em>chunk</em> of BC in memoryto compute the entire BC group-by. Similarly, ... compute the entire BC group-by. Similarly, we allocatememory to the <em>chunks</em> aoco, al co, azco, and asco of the ACgroup by ... asco of the ACgroup by while scanning the first 16 <em>chunks</em> of ABC. Tofinish the aggregation for the <em>chunk</em> aoco, we aggregate theAC of the <em>chunks</em> 1, 5, 9, and 13, to the <em>chunk</em> aoco. Afterwe aggregate the first 16 <em>chunks</em> of AC to those <em>chunks</em> ofAC, the aggregation for those AC <em>chunks</em> are done. We out-put those AC <em>chunks</em> to disk in order of (A, C) and reassignthose <em>chunks</em>’ ’ <em>memory</em> to the aocl, alcl ,azcl, and aacl ofthe AC group-by. ... in one scanof the array ABC, we need to allocate <em>memory</em> to each ofthe 16 <em>chunks</em> of AB. For the first 16 <em>chunks</em> of ABC, we ag-gregate each chunk’s AB to the corresponding ... those AB is not complete until we ag-gregate all 64 <em>chunks</em>’ ’ AB to those AB <em>chunks</em>. . Once theaggregation for AB <em>chunks</em> is done, we output those chunksin (A, B) order.Notice that ... those chunksin (A, B) order.Notice that we generate each BC <em>chunk</em> in the dimensionorder (B, C). So, before we write each ... the dimensionorder (B, C). So, before we write each BC <em>chunk</em> to disk,we use the BC <em>chunks</em> to compute the <em>chunks</em> ... of B or C asif we read in each BC <em>chunk</em> in the dimension order (B, C).Generally, the <em>chunks</em> of each group-bys of the Cube are gen-erated in a ... order. In fact, this is the keyto apply our generaf <em>memory</em> requirement rule recursively tothe nodes of the minimum <em>memory</em> spanning tree (MMST)and overlap computation for the Cube group-bys. We ... this example, for computing BC we need memoryto hold 1 <em>chunk</em> of BC, for .4C we need <em>memory</em> ... to hold 4chunks of AC and for AB we need <em>memory</em> to hold 4 *4 = 16chunks of Al?. Generalizing, we ... Ixd[ stands for the size of dimension X,IYCIstands for the <em>chunk</em> size of dimension Y. and u standsfor the size of ... of dimension Y. and u standsfor the size of each <em>chunk</em> element. The size of the chunkelement is same as the ... thelength p, then we allocate 16P x 42–P x u <em>memory</em> to XYgroup-bys. This is because each dimension is of size ... This is because each dimension is of size 16 andeach <em>chunk</em> dimension has size 4. To generalize this for allgroup-bys of ... is the size oj dimensioni and IC, I is the <em>chunk</em> size of dimension i.IC, Iis much smaller than IDil for ... <br /> the <em>memory</em> allocated to eachgroupby is to compute more groupbys of the ... agiven dimension order, different spanning trees will requiredifferent amounts of <em>memory</em>. . We define a minimum mem-ory spanning tree in the ... a minimum mem-ory spanning tree in the next section.4.1.3 Minimum <em>Memory</em> Spanning TreeA MMST for a Cube (DI,.., D.) in a ... choose the node thatmakes the node N require the minimum <em>memory</em> accordingto the Rule 1. In other words, the prefix of ... a given dimension order, is minimum in terms ofthe totaf <em>memory</em> requirement for that dimension order. Ifnode N contains the minimum ... to do it. Let us assume that we have enough <em>memory</em> toalfocate each node’s required <em>memory</em>. . The MMST for thearray ABC in a dimension order ... B, C) is shown in Fig-ure 2. As mentioned before, <em>chunks</em> of BC, AC, and AB arecalculated in dimension orders (B, ... in dimension orders (B, C), (A, C), and (A, B)in <em>memory</em> since we read ABC <em>chunks</em> in dimension order(A, B, C) to produce each <em>chunk</em> of BC, AC, and AB. Toeach node A, B,and C, ... C). Similar to the nodes of the level 2, the <em>chunks</em> ofthe nodes A, B, and C are generated in the ... the nodes fromthe level n to the level O, the <em>chunks</em> of each tree node aregenerated in a proper dimension order. ... allocate minimum number of chunksto each nodes instead of all <em>chunks</em>. . Furthermore, we cancompute the <em>chunks</em> ... of each tree node simultaneously. Forexample, we can aggregate the <em>chunk</em> aoco of AC along Cdimension to compute the <em>chunk</em> co of C after we aggregatethe <em>chunk</em> 1, 5, 9, 13 of ABC to the <em>chunk</em> aoco and beforewe write the <em>chunk</em> a. co to disk. Generally, if we allocateeach MMST node ... to disk. Generally, if we allocateeach MMST node its required <em>memory</em> we can compute thechunks of the tree nodes from the ... the level Osimultaneously.We now ~ve a way of calculating the <em>memory</em> requiredfor the MMST of any given dimension order 0 = ... takes ubytes. In addition, all the numbers used for the <em>memory</em> sizein the following sections are in units of the array ... array elementsize.Memory requirements for the MMSTLet us assume that the <em>chunk</em> size is the same for each di-mension, i.e., for all ... . and O. According to the Rule 1, the sumof <em>memory</em> required by those nodes isn—l n-z n-32=1 i= 1 ,=1At ... the type ofDI. .DkW1 ..Wn_z-k. Hence the sum of the <em>memory</em> requiredby the nodes at this level is:n-2 n—3 71-4~ ID*I ... *=1 ,=1+ .. + C(n–l, n–2)cn-2.Similarly, we calculate the total <em>memory</em> required by thenodes at the level n —3. We have ... <br /> ... n–3)cn-3.In general we get the following rule.Rule 2 The total <em>memory</em> requirement for level j of theMMST for a dimension order ... + G(n–l, n–j)cn-~As a further example, the sum of the <em>memory</em> for level1 nodes is D1 + C(n – 1, l)c. ... D“),we may generate different MMSTS, which may have pro-foundly different <em>memory</em> requirements. To illustrate this,we use a four dimension array ABCD ... switching the order of A and Dchanges the amount of <em>memory</em> required by each tree node.Clearly, it is important to determine ... is important to determine which dimension orderwill require the least <em>memory</em>. .4.1.4 Optimal Dimension OrderThe optimal dimension order is the dimension ... is the dimension order whoseMMST requires the least amount of <em>memory</em>. . We prove thatthe optimal dimension order 0 is (Dl, ... Order ABCD (Total Mem-ory Required 4 MB)Theorem 1 Consider a <em>chunked</em> multidimensional army Aof size ~~=1 lDil and having <em>chunks</em> of size~~=1 lCi 1, whereIC,I = c for all i(l ... for all i(l &lt; i &lt; n). If rueread the <em>chunks</em> in logicalorder O , where O = (DI, D2, ,, ... &lt; ID21 &lt;IDsl. &lt; ID. 1, the total amount of <em>memory</em> requirvd tocompute the Cube of the army in one scan ... is “What is the upperbound for the total amount of <em>memory</em> required by MMSTTo ?“ The next theorem and corollary answer ... where lCil = c jor afi i, thetotal amount of <em>memory</em> to compute the Cube of the arrayin one scan oj ... lessthan Cn+ (d + 1 + C)n–l.Corollary 1 For a <em>chunked</em> multidimensional array withthe size ~~=1 ID,l, where IDII &lt; IDzI... ... ~~=1 ID,l, where IDII &lt; IDzI... &lt; 111~1, and eacharray <em>chunk</em> has the size fl~=l lC~l, where IC:I = c for ... where IC:I = c for alli, the total amount of <em>memory</em> to compute the Cube of thearra~ in one scan is ... D.. The single-pass multi-way algorithm assumes that we have the <em>memory</em> requiredby the MMST of the optimal dimension order. If we ... the MMST of the optimal dimension order. If we havethis <em>memory</em>, , all the group-bys can be computed recursivelyin a single ... (as described previouslyin the example for ABC). But if the <em>memory</em> is insufficientwe need multiple passes. We need a multi-pass algorithm ... MMST for the optimal dimension ordering Oand MT be the <em>memory</em> required for ‘T, calculated using// DBC DBA DCA BCA1000OX1WX1OWI100(Dxcmlxlo 1000OXIOX1O ... compute the groupbys included in the incompletesubtrees.The problem of allocating <em>memory</em> optimally to the dif-ferent subtrees is similar to the one ... in Tobecornputed list{(3.1)(3.2)(3.3)(3.3.1)(3.3.2)(3.3.3)(3.3.4)(3.4)(3.4.1)(3.4.2)(3.4.3)}Create the working subtree U andincomplete subtreee IsAllocate <em>memory</em> <br /> scan{}the array- <em>chunk</em> of the root of T‘in the order Oaggregate each <em>chunk</em> to the groupbysin Ugenerate intermediate results for Iswrite complete <em>chunks</em> of U to diskwrite intermediate results to thepart it ions ... results to thepart it ions of IsFor each I{generate the <em>chunks</em> from thepart it ions of Iwrite the completed <em>chunks</em> of I to diskAdd I to Tobecomput ed}165The incomplete subtrees ... incomplete subtrees. We allocate each node ofthe working subtree the <em>memory</em> required by it and fin-ish aggregation for the group-bys contained ... incom-plete subtree Dj, , D32, ... Dj. -,, we allocate <em>memory</em> equafto a <em>chunk</em> size of the group-by D], , Dlz, ... Din–l, aggregateeach ... the group-by D], , Dlz, ... Din–l, aggregateeach input array <em>chunk</em> to the group-by D,, , Djz, ... D.1lt-1and write the ... of the D,l, Dj2, .. . D ,n_, group-by foreach <em>chunk</em> of DI, Dz, ... Dn. But, each of the intermediateresult ... incomplete since the intermediate resufts for dif-ferent DI, DZ,.., D. <em>chunks</em> map to the same <em>chunk</em> of the‘J1~ D327 ..&gt; DJ. _, group-by.We need to aggregate ... D327 ..&gt; DJ. _, group-by.We need to aggregate these different <em>chunks</em> to produceone <em>chunk</em> of the Djl, Dj2, ..) D).-. 1 group-by. It is ... ..) D).-. 1 group-by. It is possiblethat the amount of <em>memory</em> required by the DI 1, D3Z, ... ~?._ Igroup by ... by is larger than M. Therefore, we have to Chvldethe <em>chunks</em> of the DJ,, DJ2, . . . D,n_l group-by into ... dimension order so that the chunksin each partition fit in <em>memory</em>. . When we output the in-termediate <em>chunks</em> of D~l, DJZ, ..)D~. -l, we write them tothe partition ... we readeach intermediate result and aggregate them to the corre-sponding <em>chunk</em> of the D,l, D32, ... D ~m_, group-by. Afterwe fish ... D ~m_, group-by. Afterwe fish processing each intermediatee result, each <em>chunk</em> ofthe DJI, DJ*, ... D3._, ,qOup-by in <em>memory</em> is complete andwe output them in the dimension order DJI, ... SPARC10 machine running SunOS 3.4. The workstation has a 32MB <em>memory</em> and a 1 GB local disk with a sequential readspeed ... <br /> ... pool, 0.5 MB, for most experiments. We will indicatethe available <em>memory</em> size for those tests not using the samememory size.5.2 Array-Based ... Muki- way Array algorithm becomes a stepfunction of the available <em>memory</em> size. In this test, we in-creased the available <em>memory</em> size from 52 KB to 0.5 MB.The first step on ... in the first scan of the input array due toinsufficient <em>memory</em> to hold the required <em>chunks</em> for the twosubtrees. The algorithm goes through the second pass ... which causes the second step on the right. With theavailable <em>memory</em> more than 400 KB, the algorithm allo-cates <em>memory</em> to the entire MMST and computes the Cubein one scan ... their partitions.Theorem 2 predicts a bound of 57oKB for the <em>memory</em> re-quired for this data. The graph shows that above 420KBthe ... The graph shows that above 420KBthe entire MMST fits in <em>memory</em>. . Thus the bound is quiteclose to the actuaf value.45 ... -10 -5-0-’’’’’” ‘L’-1C020030040( 5CH1600700800 9001000MemorySize(KB)7: Multi-way Array Alg, with Various <em>Memory</em> SizeVarying Number of DimensionsWe discuss varying the number of dimensions ... <br /> ... conver~ing the offset tothe index values while processing the compressed <em>chunks</em>. .6 ConclusionIn this paper we presented the Multi-Way Array based ... method overlaps the computa-tion of different group-bys, while using minimaf <em>memory</em> foreach group-by. We have proven that the dimension orderused by ... that the dimension orderused by the algorithm minimizes the total <em>memory</em> require-ment for the algorithm.Our performance results show that that the ... Olken, L. Shapiro, M.Stonebraker, D. Wood. “Implementation Tech-niques for Main <em>Memory</em> Database Systems”. InProceedings of SIGMOD, Boston, 1984.[GBLP951 J.Gray, A. Bosworth, ... <br /> ... result table sizes alsoincrease. The ROLAP method will need more <em>memory</em> dueto this increase in size. Since the <em>memory</em> is kept constantat 0.5M, the ROLAP method has to do ... array method, the array dimension sizes are notchanging. Since the <em>memory</em> requirement for a single passcomputation for the array method depends ... the increase in the size ofthe groupbys leads to greater <em>memory</em> requirements. Butdue to the <em>memory</em> available being constant at 0.5MB, onceagain the ROLAP method reverts ... 4.1.4, the size of thislast dimension does not affect the <em>memory</em> required fo rasingle pass computation. Thus the <em>memory</em> requirements ofthe array algorithm remains constant at 0.5MB and it ... <br />
<br />
<strong>References</strong>:<br />
D. Dewitt, R. Katz, G. Olken, L. Shapiro, M. Stonebraker, D. Wood. "Implementation Techniques for Main <em>Memory</em> Database Systems". In Proceedings of SIGMOD, Boston, 1984. <br />
 <br />
</div>
</div>
<br clear="all" />
<div class="numbering">
18
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=2741952" target="_self">Deriving and comparing deduplication techniques using a model-based classification</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81502649371">J&#252;rgen Kaiser</a>,
<a href="author_page.cfm?id=81100032957">Andr&#233; Brinkmann</a>,
<a href="author_page.cfm?id=81414619974">Tim S&#252;&#223;</a>,
<a href="author_page.cfm?id=81421600088">Dirk Meister</a>
</div>
<div class="source">
<span class="publicationDate">April 2015</span>
<span style="padding-left:10px">EuroSys '15: Proceedings of the Tenth European Conference on Computer Systems</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 0</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;5</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;77</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;472</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=2741952&ftid=1563626&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
Data deduplication has been a hot research topic and a large number of systems have been developed. These systems are usually seen as an inherently linked set of characteristics. However, a detailed analysis shows independent concepts that can be used in other systems. In this work, we perform this analysis ...
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high2741952');">result highlights</a>]</div>
<div class="highlights" id="high2741952" style="display:none">
<strong>Full Text</strong>:<br />
... have made these economically applicable. Mostsystems divide the data into <em>chunks</em> and identify redundantchunks by comparing the <em>chunks</em>’ ’ fingerprints [1, 11, 21, 31,32]. A system that identifies ... [1, 11, 21, 31,32]. A system that identifies every redundant <em>chunk</em> is calledexact; otherwise it is called approximate.The computed fingerprints are ... completeindex is typically too large to be held in main <em>memory</em> andindex accesses generate random IO. Therefore, different ap-proaches have been ... have been developed to reduce index accesses andto overcome the <em>chunk</em>- -lookup disk bottleneck [11].Deduplication systems use heuristics to predict and ... bottleneck [11].Deduplication systems use heuristics to predict and toprefetch the <em>chunk</em> working set. For this they exploit thechunk locality property of ... For this they exploit thechunk locality property of backup runs. <em>Chunk</em> locality de-notes the tendency for <em>chunks</em> in backup data streams to re-occur together [11].In addition to ... systems reduce the size of all data structures involvedin the <em>chunk</em> identification process so that they fit into mainmemory and do ... <br /> ... evaluation concludes with a discussion about the im-pact of different <em>chunk</em> sizes. The <em>chunk</em> size is a crucial pa-rameter of deduplication systems since it ... crucial pa-rameter of deduplication systems since it affects the amountof <em>chunks</em> a system must process per backup run. Some stud-ies argue ... process per backup run. Some stud-ies argue in favor of <em>chunk</em> sizes that are different from themost common size of 8KB. ... this related work section, we focus on concepts toovercome the <em>chunk</em>- -lookup disk bottleneck for systems witha similar backup model.Venti proposed ... [2] is main-tained to avoid lookups for the majority of <em>chunks</em> that havenot yet been stored. Second, a “stream-informed segmentlayout” stores ... been stored. Second, a “stream-informed segmentlayout” stores the incoming new <em>chunks</em> in a container datastructure so that in each container only ... the tempo-ral locality of the data at the time the <em>chunks</em> are written forthe first time. Finally, the system fetches all ... forthe first time. Finally, the system fetches all fingerprints ofthe <em>chunks</em> stored in the container into <em>memory</em> and storesthem in a cache. Assuming that the order of ... storesthem in a cache. Assuming that the order of the <em>chunk</em> re-quests in the current backup run is similar to the ... to the containers, it is likely that manyof the following <em>chunks</em> can be found in the container chunkcache after the container ... grouped together into segments. Finger-prints of a small subset of <em>chunks</em> from each segment arechosen as hooks, which are stored in ... cham-pions. The champion segments are then used to determine ifthe <em>chunks</em> have already been stored.In their work, the authors compare Sparse ... already been stored.In their work, the authors compare Sparse Indexing’smain <em>memory</em> overhead with Zhu et al.’s approach, but pro-vide no comparative ... set.Guo and Efstathopoulos propose another approximate ap-proach to overcome the <em>chunk</em> lookup disk bottleneck [8].They create a sparse index keeping on ... <br /> ... backups [24]. It includes causality-based information to intensively prune an in-<em>memory</em> chunkindex. The system either uses what they call temporal local-ity, ... the inline deduplication of primary storagedata. DBLK uses a multi-level in-<em>memory</em> Bloom filter toimplement an inline deduplication system for primary blockstorage ... comparison with SkimpyStash [4],a related Flash-based data structure for a <em>chunk</em> index-likekey/value data structure.Paulo and Pereira present a broad survey of ... the metadata section ofa container and assumes that the following <em>chunks</em> in thebackup stream are included in these caching units. SparseIndexing ... both systems use caching units (and,therefore, the locality of the <em>chunks</em>) ). Container Cachinguses its containers for the whole system lifetime ... the chunkindex holds a pointer to the container holding the <em>chunk</em> datafor each <em>chunk</em> fingerprint.The caching scheme of Sparse Indexing, on the otherhand, forgets ... al. We willspeak about a sampled index to denote a <em>chunk</em> index thatonly contains a sampled subset of all <em>chunk</em> fingerprints.3.2 History aware approachBlock Locality Caching (BLC) differs from the ... BLC’s prefetching mecha-nism may prefetch several times for a single <em>chunk</em> becauseit can never be certain that a prefetch will actually ... Caching because the container metadata isguaranteed to store the required <em>chunk</em> <br /> information. SparseIndexing ignores the misses and declares old <em>chunks</em> as newif they are not found in the prefetched and ... of caching units instead of locality properties withinsingle units.3.3 ModelThe <em>chunk</em> identification of deduplication systems consistsof two components. The first one ... data structurethat is used to reliably determine whether a given <em>chunk</em> hasappeared in the past. Exact deduplication systems containboth components, while ... Locality Cachinghave the second part in form of the full <em>chunk</em> index. Theyperform a lookup in the <em>chunk</em> index in case of a cache miss,which serves two purposes: ... two purposes: First, it provides a correct an-swer whether the <em>chunk</em> is a duplicate. Second, it gives ahint for the next ... other hand, only has a cachingmechanism. Although similar to a <em>chunk</em> index, its sampledindex cannot identify each incoming duplicate because itonly ... or exact ver-sions, respectively. Sparse Indexing could hold an additionalfull <em>chunk</em> index, which is checked if the sparse index and therest ... variant introduces additional IOoverhead because the system now checks the <em>chunk</em> indexfor each <em>chunk</em> the caching cannot identify. However, it canstill overcome the <em>chunk</em> lookup disk bottleneck because 1)the scheme detects more than 99% ... approximate variantof the Block Locality Caching. This variant uses a sampledin-<em>memory</em> <em>chunk</em> index instead of a full disk-based one. Theapproach is approximate ... exact/approximate axes. The discussed approachesfocus on different aspects of the <em>chunk</em> ... locality property ofbackup streams and are either focused on the <em>chunk</em> localitycaught by single caching units or the locality caught by ... the approximate approaches. Finally, we analyze the ef-fect of different <em>chunk</em> sizes on the prefetching schemes inSection 4.6.4.1 Data setsWe evaluate ... <br /> ... which each simulated approach uses approximately thesame amount of main <em>memory</em>. . Therefore, we assume afixed system setup and set the ... and set the size of the caches basedon the available <em>memory</em>. . In the following, we assume asystem that can store ... asystem that can store up to 16 TB of unique <em>chunk</em> data andprovides 8GB of main <em>memory</em> for all data structures thatare necessary to identify incoming <em>chunks</em>. . We will relax thememory assumption in Section 4.5.Container Caching ... use aBloom filter to filter out most of the new <em>chunks</em>. . We con-figure the filter to an expected false positive ... hash functions. This yields a fixedsize of 2.4GB for 8KB <em>chunks</em> for BLC and CC.We fill the rest of the <em>memory</em> with the data structurethat provides the most benefit to the ... assumed compression ratio of 50%. For 8KBchunks this gives 1024 <em>chunks</em> per container. Therefore, thecontainer cache can hold <em>chunks</em> from 137,624 containers.As Lillibridge et al., we assume 20B fingerprints, ... Meister et al.’s implementation, we add a small1024 elements LRU <em>chunk</em> cache that is checked before ev-ery other cache.For BLC, the ... each time the block recipe cachedoes not hold the current <em>chunk</em>. . We chose to keep a smallalignment cache because a ... of sizetwo, four, and eight. Therefore, we use the main <em>memory</em> toincrease the block recipe cache. For 8KB <em>chunks</em>, , this re-sults in 4.4 million block recipes, assuming a ... et al.’s implementa-tion, we add a small 1024 elements LRU <em>chunk</em> cache that ischecked before every other cache.We implemented the new ... segments as described by Lillibridge etal. [11]. Finally, if a <em>chunk</em> cannot be identified as old by theselected segments, we query ... identified as old by theselected segments, we query the disk-based <em>chunk</em> index.We assume that the sampled index fits into main memoryas ... approximate Sparse Indexing. It is the main datastructure for identifying <em>chunks</em> as an index hit gives an as-sured <em>chunk</em> information and enables further ones by cachingthe loaded segments in ... based on less significantbits. We fill the rest of the <em>memory</em> with the manifest cache.For 8KB <em>chunks</em> and a segment size of 20MB, this leads toa sampling ... <br /> implementation without the additional <em>chunk</em> index.For the approximate Block Locality Caching, we samplethe <em>chunk</em> index analogously to Sparse Indexing. The ap-proach only adds entries ... approximate Container Caching analogously toBlock Locality Caching and sample the <em>chunk</em> index. Forall approximate approaches, we assume that the sampled in-dices ... approaches, we assume that the sampled in-dices fit into main <em>memory</em> and that no Bloom filters exists.We determined the configurations for ... number of IOs the approaches re-quire to identify a given <em>chunk</em> as duplicate or new. Theselookup IOs are still the most ... DDBoost [7] are used. We do not count IOsfor writing <em>chunk</em> raw data to disk as they can be done in ... the average number of generated IOs per 1000chunks ( IOs1K <em>chunks</em>) ). We average this value over all backupgenerations.We assume that ... dataof up to 137,624 containers, which translates to 1,075GBof unique <em>chunk</em> data. This is enough to hold the data setsUPB and ... is enough to hold the data setsUPB and MS in <em>memory</em>. . However, there are still IOs causedUPB JGU HOME-8KB MS-8KBData ... CachingSparse IndexingFigure 1. Best average IOs1K chunksfor all exact approaches.The <em>chunk</em> size for all data sets is 8KB.by just finished containers ... one has ahigher change rate: about 12.6% of all unique <em>chunks</em> appearafter the first generation compared to 8.6% for JGU. Thesechunks ... if the meta data of the uniquechunks fit into main <em>memory</em>. . However, the approach outper-forms Container Caching if the data ... yields higher changerates or if only a fraction of the <em>chunks</em> fit into <em>memory</em>. . Weinvestigate the latter case in Sections 4.5 and 4.6. ... the hit rate of the man-ifest cache. Based on the <em>memory</em> constraints, we sampledthe <em>chunks</em> based on the last 4 bits of the <em>chunks</em>’ ’ finger-prints and allowed 27,396 manifests in the cache. Hence, ... BLC, the approach thereforecannot utilize big cache sizes. Second, every <em>chunk</em> that theprefetching scheme cannot identify generates a lookup inUPB JGU ... IndexingFigure 2. Best average IOs1K chunksfor all approximate ap-proaches. The <em>chunk</em> size for all data sets is 8KB.the disk-based <em>chunk</em> index. These <em>chunks</em> <br /> ... additionally may cause IOs for fetch-ing manifests if the given <em>chunk</em> is a hook and the manifestcache misses.However, these IOs are ... the manifestcache misses.However, these IOs are few compared to the <em>chunk</em> indexaccesses. For the HOME data set, the index accesses accountfor ... all IOs. 61% of the index IOs are caused bynew <em>chunks</em>. . This shows that the Sparse Indexing prefetchingscheme strongly depends ... lack any Bloom filter in theirapproximate versions and hold a <em>memory</em>- -based sampled in-dex instead. This index consumes more <em>memory</em> than the fil-ter. As a consequence, the cache sizes are ... approaches sam-ple based on the last 4 bits of the <em>chunks</em>’ ’ fingerprints.Approximate Container Caching now holds the meta dataof up ... dataof up to 52,428 containers, which translates to 410MB ofunique <em>chunk</em> data. This covers the UPB data set and causesa low ... data sets, it generatesbetween 0.23 and 0.85 IOs per 1K <em>chunks</em> and does notdetect between 0.4% and 1% of all <em>chunk</em> duplicates pergeneration.BLC generates the most IOs1K chunksin one data sets. ... of IOs in-stead of just a single one. After the <em>chunk</em> is not found in thecache, BLC assumes that it used ... Only if these also do not pro-vide information about the <em>chunk</em>, , it is declared as new.On the other hand, BLC’s ... are the same because the approximate version does notreceive freed <em>memory</em> compared to the exact variant. Theother approximate approaches can distribute ... <br /> ... above the line up to container ID 148K are causedby <em>chunks</em> that occurred at an earlier point than in the firstbackup ... the firstbackup generation. Second, the containers above ID 148Kinclude new <em>chunks</em> that appeared after the first backupgeneration. These containers include no ... containers include no locality from thebackup stream as the new <em>chunks</em> appear randomly in thelater backup generations. Zhu et al. call ... there are more fetches caused by intra-backup redundancy and new <em>chunks</em>. . The reason is the highsampling rate of the <em>chunk</em> index in this configuration. Therate reduces the efficiency of the ... more containers (170Kvs. 203K). Second, the higher amount of stored <em>chunks</em> in-creases the locality caught by new containers of later backupgenerations. ... 4. CDF of the number of occurrences of the mostused <em>chunks</em>. . The CDF bases on the 15th generation of theHOME ... of the HOME data set: The mostused 4% of all <em>chunks</em> account for 20% of all fingerprint oc-currences. The last 85% ... 20% of all fingerprint oc-currences. The last 85% of the <em>chunks</em> consists of <em>chunks</em> thatare referenced only once and account for 64%. The distribu-tion ... once and account for 64%. The distribu-tion for the hook <em>chunks</em> is the same since they are chosenuniformly from the set ... the same since they are chosenuniformly from the set of <em>chunks</em>. . Meister et al. showed thisbias for for HPC data ... above 78M. The sparseaccesses above 84M are caused by redundant <em>chunks</em> withinthe running backup.Similar to SI, BLC’s aging is visible in ... over time. However,the history-awareness of BLC generates fewer random ac-cesses.4.5 <em>Memory</em> Consumption and Stored DuplicatesIn Section 4.3, we mentioned that all ... system devel-opers can achieve a performance boost while reducing themain <em>memory</em> <br /> ... of the approximate approaches. The figures show the average IOs1K <em>chunks</em>( (solid lines) and the fraction ofundetected duplicates (dashed lines) for ... amounts of main memory.we analyze how the amount of available <em>memory</em> influencesthe duplicate detection and the amount of generated disk ac-cesses. ... detection and the amount of generated disk ac-cesses. For each <em>memory</em> setup, we distribute the <em>memory</em> asmentioned in Section 4.2.Figure 5 shows the average IOs1K <em>chunks</em>( (solid lines) and therelative amount of undetected duplicates (dashed lines) ... generates the its lowestamount of IOs for low and high <em>memory</em> scenarios. Thereason are two mechanisms working against each other:First, each ... size of the available memoryhalves the sampling of the sampled <em>chunk</em> index and, there-fore, increases the number of successful accesses to ... approach performs these accesses if the containercache missed for a <em>chunk</em> and the chunk’s container shouldbe placed into the cache. If ... per container with low samplingrates.Second, the growing amount of main <em>memory</em> also in-creases the size of the container cache and therefore ... Container Caching, it generates a lownumber of IOs for small <em>memory</em> sizes, but trades this foran increased ratio of undetected duplicates. ... of the data set.However, SI does not benefit from growing <em>memory</em> sizesat the same degree. For each data set, a <em>memory</em> thresholdexists after which bigger <em>memory</em> sizes only minimally im-prove SI’s performance. This threshold is hit ... shownin Figure 3(b), SI mainly accesses these manifests. There-fore more <em>memory</em> only reduces the rare accesses to the oldermanifests. As for ... bigger than the numberof CC’s container fetches for the same <em>memory</em> sizes sinceSI generates more segments than CC generates containers.As mentioned ... <br /> ... not detect 3.9% to 8.2% of all dupli-cates. For 16GB <em>memory</em>, , this value is below 0.1% for alldata sets.Block Locality ... approaches. The reason is thatits prefetching is more robust against <em>chunk</em> index misses be-cause BLC loads several consecutive block recipes. There-fore, ... However, it is important to adjust the configura-tion for low <em>memory</em>. . BLC has high IO costs if it cannot findan ... guessed align-ment in the alignment cache before it requests the <em>chunk</em> in-dex for a new alignment. If now the index lookup ... BLC generatedabout 8-10% more IO operations.For the lowest amount of <em>memory</em>, , the relative number ofundetected duplicates varies between 2.5% and ... morememory is available.On the other hand, BLC cannot utilize high <em>memory</em> sit-uations because of its focus on alignments to older gener-ations. ... In fact, BLC’s number of IOsincrease slightly because the better <em>chunk</em> index hit rate in-creases the sensitivity to bad alignment shifts. ... the BLC efficiency muchwhile increasing the IO costs. For 16GB <em>memory</em>, , the rela-tive number of undetected duplicates varies between 0.06%and ... to the other sets, the IOs1K chunksdecreases with grow-ing main <em>memory</em>. . The reason is the higher data redundancywithin the same ... benefits BLC’s LRU strategyso that it can better utilize growing <em>memory</em> compared to theother data sets.These experiments show that the approximate ... mainmemory. The caching unit centric approaches perform betterin these situations.4.6 <em>Chunk</em> SizesUp to now, we compared the approaches based on data ... now, we compared the approaches based on data setsthat were <em>chunked</em> with an expected <em>chunk</em> size of 8KB. Thischunk size is used in most deduplication ... 8KB. Thischunk size is used in most deduplication systems. However,other <em>chunk</em> sizes might be beneficial depending on the usedapproach and situation. ... For Sparse Indexing, Lillibridge etal. argue in favor of 4KB <em>chunks</em> [11], for example. Dif-ferent <em>chunk</em> sizes yield several trade offs [10]. In general,smaller <em>chunk</em> sizes increase the granularity at which dataredundancies can be detected ... hence, increase the dedu-plication ratio. On the other hand, 4KB <em>chunks</em> roughly dou-ble the number of <em>chunks</em> a deduplication system has to pro-cess during a backup run. ... is possible [17], forexample.HOME-4KB HOME-8KB HOME-16KB MS-8KB MS-16KBData Set and <em>Chunk</em> Size01020304050607080Average IOs1KchunksBlock Locality CachingContainer CachingSparse IndexingFigure 6. Average IOs1Kchunksfor the ... CachingContainer CachingSparse IndexingFigure 6. Average IOs1Kchunksfor the exact approaches fordifferent <em>chunk</em> sizes.In the following, we evaluate how the different ap-proaches compare ... how the different ap-proaches compare to each other for different <em>chunk</em> sizes.For each data set, we set the amount of available ... we set the amount of available memoryto 8GB. The different <em>chunk</em> numbers change the memoryconsumption of the Bloom filters and the ... the Bloom filters and the sampled indices.We distribute the main <em>memory</em> <br /> ... 6 shows the average IOs1K chunksforthe exact approaches for different <em>chunk</em> sizes.In general, the average number of IOs1K chunksof an approachvaries ... number of IOs1K chunksof an approachvaries little for the different <em>chunk</em> sizes because of threereasons: First, the normalizing metric filters out ... filters out any directeffect of the different total number of <em>chunks</em>. . For example,the total number of false positives of the ... positives of the simulated Bloomfilters scales with the number of <em>chunks</em>. . Second, propertiesof the data sets do not change much ... propertiesof the data sets do not change much for different <em>chunk</em> sizes.For example, a new file likely contains only new chunksregardless ... a new file likely contains only new chunksregardless of the <em>chunk</em> size. Finally, the caching unit usageof each approach scales with ... Finally, the caching unit usageof each approach scales with the <em>chunk</em> size because it isa result of the <em>chunk</em> locality properties of the data setsinstead of the <em>chunk</em> size. Each unit’s capacity is definedby a logical size. Therefore ... a logical size. Therefore it holds approximately twicethe number of <em>chunks</em> if the <em>chunk</em> size halves. If the chunklocality properties of the data set ... smaller and is negated by a better cacheefficiency of the <em>chunk</em> cache, i.e., the small 1024 elementsLRU cache, which is checked ... cache can hold the meta data ofall containers in main <em>memory</em>. ... . This results in a drop from2.22 to 0.97 IOs1K <em>chunks</em>. . For HOME-16KB, about 68% of allIOs are generated by ... Locality CachingContainer CachingSparse IndexingHOME-4KB HOME-8KB HOME-16KB MS-8KB MS-16KBData Set and <em>Chunk</em> Size0.0%0.2%0.4%0.6%0.8%1.0%1.2%Avg. undetected DuplicatesFigure 7. Average IOs1Kchunksand relative amount of unde-tected ... duplicates for the approximate approaches.MS data set fits into main <em>memory</em> as mentioned in Section4.3.For exact Sparse Indexing, bigger <em>chunk</em> sizes result ina lower sampling of the sampled index and ... approach generates approximately thesame number of IOs for the different <em>chunk</em> sizes. The IOsdo not vary because each halving of the ... the sparse index. Asfor CC, the expected amount of hook <em>chunks</em> in the seg-ments is the same for the different <em>chunk</em> sizes. Analogously,the same holds for the number of entries in ... the sparse in-dex since each doubling of the number of <em>chunks</em> is negatedby a sampling based on one more bit of ... negatedby a sampling based on one more bit of the <em>chunk</em> fin-gerprints. Therefore, the approach loads approximately thesame amount of manifests ... relative number of undetected duplicatesfor the approximate approaches for different <em>chunk</em> sizes.Approximate BLC’s average number of IOs1K chunksis nearlyunaffected by the ... BLC’s average number of IOs1K chunksis nearlyunaffected by the different <em>chunk</em> sizes. The reason is thata different number of <em>chunks</em> does not change the align-ments to older backup generations. However, ... align-ments to older backup generations. However, the reducedsampling for bigger <em>chunks</em> supports the duplicate detectionas a denser index allows an earlier ... better align-ment if the cache does not hold a given <em>chunk</em>. . For all datasets, BLC detects the most duplicates except ... sampling rate, which drops from 132for 4KB chunksto 18for 16KB <em>chunks</em>. . Each step doubles the number ofentries in the sampled ... loaded. However,the lower sampling also doubles the number of bad <em>chunks</em>, ,i.e., <em>chunks</em> that cause cache thrashing. These <em>chunks</em> occuracross the backup stream and cause fetches for containersthat are ... and cause fetches for containersthat are only used for few <em>chunks</em>. . The relative number ofundetected duplicates decreases from about 1.1% ... therefore, suggests that the container cache is the mainmechanism for <em>chunk</em> identification. However, a denser in-dex supports the identification as lower ... the identification as lower sampling increasesthe relative amount of hook <em>chunks</em> in a container. As a re-sult, the approach fetches and ... <br /> ... mentioned for the exactversion: each halving of the number of <em>chunks</em> is counteredby a lower sampling so that the total amount ... the total amount of IO doesnot change. Without the full <em>chunk</em> ... index, this becomes thedominating effect on the IOs1K chunksfor varying <em>chunk</em> sizes.However, the manifest cache decreases the doublingslightly since the reduced ... causes an increased hit ratio. The ratio increasesfrom 58% (4KB <em>chunks</em>) ) to 61% (16KB <em>chunks</em>) ) for theHOME data set. The duplicate detection is nearly ... and MS, the rate of undetected duplicationis 0.1% for all <em>chunk</em> ... sizes. This suggests that SI is a goodchoice for smaller <em>chunk</em> sizes.5. ConclusionPrevious work often assumed that the prefetching/cachingscheme of a ... to be the least af-fected by different system setups and <em>chunk</em> sizes. In addi-tion, it generates the most disk-friendly cache unit ... is an interesting choice for a lowmemory system and bigger <em>chunk</em> sizes. For the former case,it detects more duplicates than SI, ... exact deduplication systemsrequire an extra mechanism for this type of <em>chunks</em>. . Theoriginal version of SI performed best in the most ... andimproves for smaller chunks.The approximate Container Caching also improves forsmaller <em>chunks</em> but highly depends on the amount of avail-able <em>memory</em>. . In low <em>memory</em> setups, it does not detect up to44% of all duplicates. ... Long, and M. Lillibridge. Ex-treme Binning: Scalable, Parallel Deduplication for <em>Chunk</em>- -based File Backup. In Proceedings of the 17th IEEE Inter-national ... <br /> ... 2010.[10] E. Kruus, C. Ungureanu, and C. Dubnicki. Bimodal ContentDefined <em>Chunking</em> for Backup Streams. In Proceedings ofthe 8th USENIX Conference on ... Bhagwat. Improving Re-store Speed for Backup Systems that Use Inline <em>Chunk</em>- -BasedDeduplication. In Proceedings of the 11th USENIX Con-ference on File ... Lu, Y. J. Nam, and D. H. Du. BloomStore: Bloom-filterbased <em>memory</em>- -efficient key-value store for indexing of datadeduplication on flash. In ... <br />
<br />
<strong>References</strong>:<br />
D. Bhagwat, K. Eshghi, D. D. Long, and M. Lillibridge. Extreme Binning: Scalable, Parallel Deduplication for <em>Chunk</em>-based File Backup. In <i>Proceedings of the 17th IEEE International Symposium on Modeling, Analysis, and Simulation (MASCOTS)</i>, pages 1--9, 2009. <br /> F. C. Botelho, P. Shilane, N. Garg, and W. Hsu. <em>Memory</em> Efficient Sanitization of a Deduplicated Storage System. In <i>Proceedings of the 11th USENIX Conference on File and Storage Technologies (FAST)</i>, pages 81--94, February 2013. <br /> E. Kruus, C. Ungureanu, and C. Dubnicki. Bimodal Content Defined <em>Chunking</em> for Backup Streams. In <i>Proceedings of the 8th USENIX Conference on File and storage technologies (FAST)</i>. USENIX, 2010. <br /> M. Lillibridge, K. Eshghi, and D. Bhagwat. Improving Restore Speed for Backup Systems that Use Inline <em>Chunk</em>-Based Deduplication. In <i>Proceedings of the 11th USENIX Conference on File and Storage Technologies (FAST)</i>. USENIX, February 2013. <br /> G. Lu, Y. J. Nam, and D. H. Du. BloomStore: Bloom-filter based <em>memory</em>-efficient key-value store for indexing of data deduplication on flash. In <i>Proceedings of the 28th IEEE Symposium on Mass Storage Systems and Technologies (MSST)</i>, pages 1--11. IEEE, 2012. <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
19
<img src="images/ACM_mini.jpg" alt="published by ACM" vspace="7" border="0" style="padding-left: 20px;">
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=331544" target="_self">Querying very large multi-dimensional datasets in ADR</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81408593043">Tahsin Kurc</a>,
 <a href="author_page.cfm?id=81332492508">Chialin Chang</a>,
<a href="author_page.cfm?id=81100245034">Renato Ferreira</a>,
<a href="author_page.cfm?id=81100636043">Alan Sussman</a>,
<a href="author_page.cfm?id=81100475190">Joel Saltz</a>
</div>
<div class="source">
<span class="publicationDate">January 1999</span>
<span style="padding-left:10px">SC '99: Proceedings of the 1999 ACM/IEEE conference on Supercomputing</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;ACM
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 17</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;2</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;3</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;246</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=331544&ftid=74992&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high331544');">result highlights</a>]</div>
<div class="highlights" id="high331544" style="display:none">
<strong>Full Text</strong>:<br />
... expects each of its datasets to be partitioned into data <em>chunks</em>, , eachchunk consisting of one or more data items from ... index returns the disk locations of the set of data <em>chunks</em> that contain data items that fall inside the givenmulti-dimensional range ... output of each query is computed andthe order input data <em>chunks</em> are retrieved for processing.• Query execution service manages all the ... Output functions), while providing support for common operations such as <em>memory</em> manage-ment, data retrieval, and scheduling of processing across a parallel ... accomplished in four steps: (1) partition a dataset into data <em>chunks</em>, , (2) computeplacement information, (3) move data <em>chunks</em> to the disks according to placement information, and (4) create ... create an index.A dataset is partitioned into a set of <em>chunks</em> to achieve high bandwidth data retrieval. A <em>chunk</em> consists of one or moredata items, and is the unit ... unit of I/O and communication in ADR. That is, a <em>chunk</em> is always retrieved as a whole duringquery processing. As every ... associated with a point in a multi-dimensional attribute space, every <em>chunk</em> isassociated with a minimum bounding rectangle (MBR) that encompasses the ... (in the associated attributespace) of all the items in the <em>chunk</em>. . Since data is accessed through range queries, it is ... to each other in the multi-dimensional space in the same <em>chunk</em>. . The placement information describeshow data <em>chunks</em> are declustered and clustered across the disk farm. <em>Chunks</em> are distributed across the disks attachedto ADR back-end nodes using ... algorithm [12, 21] to achieve I/O parallelism during query processing.Each <em>chunk</em> is assigned to a single disk, and is read and/or ... the local processorto which the disk is attached. If a <em>chunk</em> is required for processing by one or more remote processors, ... by the local processor via interprocessor communication. After all data <em>chunks</em> <br /> ... (e.g., an R-tree) is constructed using the MBRs of the <em>chunks</em>. . The index is usedby the back-end nodes to find ... index is usedby the back-end nodes to find the local <em>chunks</em> with MBRs that intersect the range query.2.3 Query PlanningA plan ... final output are computed and the order the input data <em>chunks</em> are retrieved forprocessing. Planning is carried out in two steps; ... the outputdataset is too large to fit entirely into the <em>memory</em>, , it is partitioned into tiles. Each tile, O t, ... Each tile, O t, contains a distinct subset ofthe output <em>chunks</em>, , so that the total size of the <em>chunks</em> in a tile is less than the amount of <em>memory</em> available for outputdata. Tiling of the output implicitly results in ... I t, contains the input chunksthat map to the output <em>chunks</em> in tile, O t. During query processing, each output tile ... During query processing, each output tile is cached in main <em>memory</em>, , andinput <em>chunks</em> from the corresponding input tile are retrieved. Since a mapping ... may map an input element tomultiple output elements, an input <em>chunk</em> may appear in more than one input tile if the ... output chunksare assigned to different output tiles. Hence, an input <em>chunk</em> may be retrieved multiple times during execution of theprocessing loop. ... each tile (i.e. aggregation of data items in inputand accumulator <em>chunks</em>) ) is partitioned across processors. This is accomplished by assigning ... theresponsibility for processing a subset of the input and/or accumulator <em>chunks</em>. .4(* Output and Input Dataset Tiles *)Otiles ? {Ot} and ... i c ,oc, and ac denote input, output, and accumulator <em>chunks</em>, , respectively.2.4 Query ExecutionExecution of a query in ADR is ... processor progresses through four phases for each tile:1. Initialization. Accumulator <em>chunks</em> in the current tile are allocated space in <em>memory</em> and initialized. If an exist-ing output dataset is required to ... output dataset is required to initialize accumulator elements, an output <em>chunk</em> is retrieved by the processorthat has the <em>chunk</em> on its local disk, and the <em>chunk</em> is forwarded to the processors that require it.2. Local Reduction. ... to the processors that require it.2. Local Reduction. Input data <em>chunks</em> on the local disks of each back-end node are retrieved ... of each back-end node are retrieved and aggregated intothe accumulator <em>chunks</em> allocated in each processor’s <em>memory</em> in phase 1.3. Global Combine. If necessary, results computed in ... combined across all processorsto compute final results for the accumulator <em>chunks</em>. .4. Output Handling. The final output <em>chunks</em> ... for the current tile are computed from the corresponding accumu-lator <em>chunks</em> computed in phase 3. If the query creates a new ... phase 3. If the query creates a new dataset, output <em>chunks</em> are declustered across theavailable disks, and each output <em>chunk</em> is written to the assigned disk. If the query updates ... If the query updates an already existingdataset, the updated output <em>chunks</em> are written back to their original locations on the disks.A ... the operation queues are polled and, upon their completion, new51. <em>Memory</em> = Minimum of the size of <em>memory</em> <br /> holding accumulator <em>chunks</em>) )2. Tile = 1; MemoryUsed = 03. while (there is ... 1; MemoryUsed = 03. while (there is an unassigned output <em>chunk</em>) )4. Select an output <em>chunk</em> C5. ChunkSize = Size of the accumulator <em>chunk</em> corresponding to C6. if ((ChunkSize+MemoryUsed) &gt; <em>Memory</em>) )7. Tile = Tile + 18. MemoryUsed = ChunkSize9. else10. ... MemoryUsed = ChunkSize9. else10. MemoryUsed = MemoryUsed + ChunkSize11. Assign <em>chunk</em> C to tile Tile12. Let k be the processor that ... tile Tile12. Let k be the processor that owns the <em>chunk</em> C13. Add <em>chunk</em> C to the set of local accumulator <em>chunks</em> of k for tile Tile14. Add <em>chunk</em> C to the set of ghost <em>chunks</em> on all other processors for tile Tile15. Add the set ... processors for tile Tile15. Add the set of local input <em>chunks</em> of k that map to <em>chunk</em> C to theset of input <em>chunks</em> to be retrieved by k during query execution for tile ... strategy.asynchronous operations are initiated when more work is expected and <em>memory</em> buffer space is available. Data chunksare therefore retrieved and processed ... and output datasets are assumed to be already partitioned into <em>chunks</em> and declustered across the disks inthe system. In the following ... system. In the following discussions we assume that an accumulator <em>chunk</em> is allocated in <em>memory</em> for each outputchunk to hold the partial results, and that ... that the total size of the accumulator exceeds the aggregate <em>memory</em> capacity ofthe parallel machine, so that tiling is needed.We define ... machine, so that tiling is needed.We define a local input/output <em>chunk</em> on a processor as an input/output <em>chunk</em> stored on one of the disks attachedto that processor. Otherwise, ... the disks attachedto that processor. Otherwise, it is a remote <em>chunk</em>. . A processor owns an input or output <em>chunk</em> if it is a local input oroutput <em>chunk</em>. . A ghost <em>chunk</em> (or ghost cell) is an accumulator <em>chunk</em> allocated in the <em>memory</em> of a processor that doesnot own the corresponding output chunk.In ... a Hilbert space-filling curve [12, 13,21] to order the output <em>chunks</em>. . Our goal is to minimize the total length of ... length of the boundaries of the tiles, by assigningspatially close <em>chunks</em> in the multi-dimensional attribute space to the same tile, to ... output chunkis used to generate a Hilbert curve index. The <em>chunks</em> are sorted with respect to this index, and selected in ... implementation, however, does not take into account the distributionof input <em>chunks</em> in the output attribute space, so for some distributions of ... data in its attribute space there canstill be many input <em>chunks</em> intersecting multiple tiles, despite a small boundary length.3.1 Fully Replicated ... is partitioned intotiles, each of which fits into the local <em>memory</em> of a single back-end processor. When an output <em>chunk</em> is assigned to atile, the corresponding accumulator <em>chunk</em> is put into the set of local accumulator <em>chunks</em> in the processor that ownsthe output <em>chunk</em>, , and is assigned as a ghost <em>chunk</em> on all other processors. This scheme effectively replicates all ofthe ... all other processors. This scheme effectively replicates all ofthe accumulator <em>chunks</em> in a tile on each processor, and each processor generates ... generates partial results using its local input61. for (each processor p)<em>Memory</em>( (p) = Size of <em>memory</em> on p (for holding accumulator <em>chunks</em>) )2. Tile = 1, MemoryFull = 03. while (there is ... 1, MemoryFull = 03. while (there is an unassigned output <em>chunk</em>) )4. Select an output <em>chunk</em> C5. Let So be the set of processors having at ... of processors having at least one input chunkthat projects to <em>chunk</em> C6. ChunkSize = Size of the accumulator <em>chunk</em> corresponding to C7. for (p in So)8. if ((<em>Memory</em>( (p)?ChunkSize) &lt; 0) MemoryFull = 19. if (MemoryFull == 1)10. ... 1)10. Tile = Tile + 111. for (p in So) <em>Memory</em>( (p) = (size of <em>memory</em> on p) ? ChunkSize12. for (p not in So) <em>Memory</em>( (p) = size of <em>memory</em> ... on p13. MemoryFull = 014. else15. for (p in So) <em>Memory</em>( (p) = <em>Memory</em>( (p) ? ChunkSize16. Assign <em>chunk</em> C to tile Tile17. Let k be the processor that ... tile Tile17. Let k be the processor that owns output <em>chunk</em> C18. Add <em>chunk</em> C to the set of local accumulator <em>chunks</em> of k for tile Tile19. Add <em>chunk</em> C to the set of ghost <em>chunks</em> on each processor in S o for tile Tile20. Add ... o for tile Tile20. Add the set of local input <em>chunks</em> of k that map to output <em>chunk</em> C tothe set of input <em>chunks</em> to be retrieved by k during query execution21. end whileFigure ... <br /> ... forwarded to the processors that own the corresponding output (accumulator) <em>chunks</em> to produce the finaloutput product.Executing step 15 of the while ... an efficient searchmethod, either of which must return the input <em>chunks</em> that map to a given output <em>chunk</em>. . In some cases it may be lessexpensive to find ... cases it may be lessexpensive to find the projected output <em>chunks</em> for each input <em>chunk</em>. . For example, the input <em>chunks</em> may be irregularlyand sparsely distributed in the input attribute space, ... and regular array such as araster image, with the output <em>chunks</em> as regular subregions of the array. In such cases, step ... can be carried out in aseparate loop, iterating over input <em>chunks</em>, , finding the output <em>chunks</em> they map to, and adding the input <em>chunks</em> to theappropriate tiles. To run step 15 as a separate ... the implementation must store the assigned tile number with eachoutput <em>chunk</em>. .3.2 Sparsely Replicated Accumulator (SRA) StrategyThe fully replicated accumulator strategy ... StrategyThe fully replicated accumulator strategy eliminates interprocessor communication for input <em>chunks</em>, , by replicatingall accumulator <em>chunks</em>. . However, this is wasteful of <em>memory</em>, , because the strategy replicates each accumulator chunkin every processor ... replicates each accumulator chunkin every processor even if no input <em>chunks</em> will be aggregated into the accumulator <em>chunks</em> in some processors. Thisresults in unnecessary initialization overhead in the ... extra communicationand computation in the global combine phase. The available <em>memory</em> in the system also is not efficiently employed,because of unnecessary ... created than necessary, which maycause a large number of input <em>chunks</em> to be retrieved from disk more than once. The tiling ... strategy is shown in Figure 5.In this strategy, a ghost <em>chunk</em> ... is allocated only on processors owning at least one input <em>chunk</em> that projects tothe corresponding accumulator <em>chunk</em>. . Replicating accumulator <em>chunks</em> sparsely in this way requires that we find thecorresponding set ... that we find thecorresponding set of processors for each output <em>chunk</em> during the tiling step (step 5 in Figure 5). As ... sometimes it may be easier to find the projected output <em>chunks</em> for each input <em>chunk</em>. . For those cases,an alternative solution is to maintain a ... alternative solution is to maintain a list for each output <em>chunk</em> to store the set of processors that require allocating71. for ... set of processors that require allocating71. for (each processor p)2. <em>Memory</em>( (p) = Size of <em>memory</em> on p (for holding accumulator <em>chunks</em>) )3. Tile(p) = 14. while (there is unassigned output <em>chunk</em>) )5. Select an output <em>chunk</em> C6. Let p be the processor that owns <em>chunk</em> C7. ChunkSize = Size of the accumulator <em>chunk</em> corresponding to C8. if ((<em>Memory</em>( (p)?ChunkSize) &lt; 0)9. Tile(p) = Tile(p) + 110. <em>Memory</em>( (p) = (size of <em>memory</em> on p) ? ChunkSize11. else12. <em>Memory</em>( (p) = <em>Memory</em>( (p) ? ChunkSize13. Assign <em>chunk</em> C to tile Tile(p)14. Add <em>chunk</em> C to the set of local accumulator <em>chunks</em> of p for tile Tile(p)15. Add all the local and ... for tile Tile(p)15. Add all the local and remote input <em>chunks</em> that map to <em>chunk</em> Cto the set of input <em>chunks</em> to be retrieved and processed by p for Tile(p)16. end ... and workload partitioning step for the distributed accumulator strategy.an accumulator <em>chunk</em>. . The list is created prior to the tiling step ... prior to the tiling step by iterating over the input <em>chunks</em>, , projecting them tooutput <em>chunks</em>, ... , and storing the result (processor id) with each output <em>chunk</em>. ... .3.3 Distributed Accumulator (DA) StrategyIn this scheme the output (accumulator) <em>chunks</em> in each tile are partitioned into disjoint sets, referred to ... responsibility to carry out the operations associated with the output <em>chunks</em> in aworking set. The tiling and workload partitioning step is ... and workload partitioning step is shown in Figure 6. Output <em>chunks</em> are selected (step 5) inHilbert curve order, as for the ... processorfor a tile is composed of only the local output <em>chunks</em> in that processor. Local <em>chunks</em> ... for each processor are assignedto the same tile until the <em>memory</em> space allocated for the accumulator on that processor is filled.In ... accumulator on that processor is filled.In the DA strategy accumulator <em>chunks</em> are not replicated on other processors, thus no ghost <em>chunks</em> are allocated.This allows the DA strategy to make more effective ... strategy to make more effective use of the overall system <em>memory</em> by assigning more <em>chunks</em> to atile, as a result produce fewer tiles than the ... fewer tiles than the other two schemes. Therefore, fewer input <em>chunks</em> are likely to be retrievedfor multiple tiles in this scheme ... the other two schemes. Furthermore, DA avoids interprocessor communicationfor accumulator <em>chunks</em> during the initialization phase and for ghost <em>chunks</em> during the global combine phase, andalso requires no computation in ... phase. The FRA and SRA strategies eliminate interprocessorcommunication for input <em>chunks</em>, <br /> all accumulator <em>chunks</em>. . On the other hand, the distributed accumulatorstrategy introduces communication ... accumulatorstrategy introduces communication in the local reduction phase for input <em>chunks</em>; ; all the remote input <em>chunks</em> that mapto the same output <em>chunk</em> ... must be forwarded to the processor that owns the output <em>chunk</em>. . Since a mapping functionmay map an input <em>chunk</em> to multiple output <em>chunks</em>, , an input <em>chunk</em> may be forwarded to multiple processors.Figure 7 illustrates FRA and ... outputchunks to the processors is illustrated at the top. Input <em>chunks</em> are denoted by triangles while output <em>chunks</em> are denotedby rectangles. The final result to be computed by ... the SP is a thin node with 256 MB of <em>memory</em>; ; the nodes are connected via a High Performance Switchthat ... The AIX filesystem on the SP nodes uses a main <em>memory</em> file cache, so we used the remaining250MB on the disk ... a controlled way. The assignment of both input and output <em>chunks</em> to thedisks was done using a Hilbert curve based declustering ... experiments. The column labeled Fan-in shows the average number ofinput <em>chunks</em> that map to each output <em>chunk</em>, , while the Fan-out column shows the average number of ... shows the average number of output chunksto which an input <em>chunk</em> maps for both the smallest and largest input datasets. The ... input datasets. The last column shows the com-putation time per <em>chunk</em> for the different phases of query execution (see Section 2.4); ... The LR value denotesthe computation cost for each intersecting (input <em>chunk</em>, , accumulator <em>chunk</em>) ) pair. Thus, an input <em>chunk</em> that maps to alarger number of accumulator <em>chunks</em> takes longer to process. In all of these applications the ... regions. The distribution of theindividual data items and the data <em>chunks</em> in the input dataset of SAT is irregular. This is ... because of the polar orbitof the satellite [23]; the data <em>chunks</em> near the poles are more elongated on the surface of ... earth than those near theequator and there are more overlapping <em>chunks</em> near poles. The input datasets for WCS and VM are ... VM are regular densearrays, which are partitioned into equal-sized rectangular <em>chunks</em>. . We selected the values for the various parameters torepresent ... ComputationNum. of Total Num. of Total Average Average (in milliseconds)App. <em>Chunks</em> Size <em>Chunks</em> Size Fan-in Fan-out I–LR–GC–OHSAT 9K – 144K 1.6GB – 26GB ... <br /> ... more flexible workload partitioning schemes through the use of ghost <em>chunks</em>. . Several extensi-ble database systems have been proposed to provide ... (i.e. the basic processing loop in Figure 1) on dis-tributed <em>memory</em> parallel machines within the ADR framework. We have presented three ... possible strategies; processing is performed on the processors where input <em>chunks</em> are stored. The distributedaccumulator strategy, on the other hand, lies ... other end; processing is carried out on the processors whereoutput <em>chunks</em> are stored. Our experimental results suggest that a hybrid strategy ... be formulated as a multi-graph partitioning problem, with inputand output <em>chunks</em> <br /> ... this paper we address efficient execution of rangequeries on distributed <em>memory</em> parallel machines within ADR framework. We present three potential strategies, ... <br /> ... integrates storage, retrievaland processing of large multi-dimensional datasets on distributed <em>memory</em> parallel architectures with multiple disksattached to each node. ADR targets ... Aggregate, and Output functions), while providingsupportfor common operations such as <em>memory</em> management, data retrieval, and scheduling of processing across a parallelmachine. ... queries (i.e. the processing loop shown in Figure 1) ondistributed <em>memory</em> parallel machines within the ADR framework. We describe three potential ... <br /> ... communication for DA is proportional to the number of input <em>chunks</em> on each processorand the average fan-out of each input <em>chunk</em>, , while for FRA it is proportional to the total ... FRA it is proportional to the total number of output <em>chunks</em>. . Asis seen in Figure 9(a), as the number of ... increases, communication volume for DA decreases since there arefewer input <em>chunks</em> per processor, while communication volume remains almost constant for FRA. ... SRA implicitly depends on the average fan-in of each output <em>chunk</em>. . If fan-in ismuch larger than the number of processors, ... processors, it is likely that each processor will have input <em>chunks</em> that map to all outputchunks. Thus, in such cases, SRA ... processors is greater than thefan-in, there will be fewer ghost <em>chunks</em> than there are output <em>chunks</em> for SRA, thus resulting in less overhead in theinitialization and ... <br /> graph vertices, and the mapping between input and output <em>chunks</em> provided by themapping function representing the graph edges. A planning ... <br />
<br />
</div>
</div>
<br clear="all" />
<div class="numbering">
20
</div>
<div class="details">
<div class="title">
<a href="citation.cfm?id=1117638" target="_self">Text chunking by system combination</a>
</div>
<div class="authors">
<a href="author_page.cfm?id=81310493636">Erik F. Tjong Kim Sang</a>
</div>
<div class="source">
<span class="publicationDate">September 2000</span>
<span style="padding-left:10px">ConLL '00: Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning - Volume 7</span>
</div>
<div class="publisher">
<strong>Publisher:</strong>&nbsp;Association for Computational Linguistics
</div>
<div class="metrics">
<div class="metricsCol1">
<strong>Bibliometrics</strong>:
</div>
<div class="metricsCol2">
<div><span class="citedCount">Citation Count: 21</span></div>
<div><span class="download6Weeks">Downloads&nbsp;(6&nbsp;Weeks):&nbsp;3</span>,&nbsp;&nbsp; <span class="download12Months">Downloads&nbsp;(12&nbsp;Months):&nbsp;17</span>,&nbsp;&nbsp; <span class="downloadAll">Downloads&nbsp;(Overall):&nbsp;132</span></div>
</div>
</div>
<br clear="all" />
<div class="ft">
Full text available:
<a name="FullTextPDF" title="FullText PDF" href="ft_gateway.cfm?id=1117638&ftid=259301&dwn=1&#URLTOKEN#" target="_blank"><img src="imagetypes/pdf_logo.gif" alt="PDF" class="fulltext_lnk" border="0" />PDF</a>
</div>
<div class="abstract">
We will apply a system-internal combination of memory-based learning classifiers to the CoNLL-2000 shared task: finding base chunks. Apart from testing different combination methods, we will also examine if dividing the chunking process in a boundary recognition phase and a type identification phase would aid performance.
</div>
<div>[<a href="javascript: void(0);" onclick="expand('high1117638');">result highlights</a>]</div>
<div class="highlights" id="high1117638" style="display:none">
<strong>Full Text</strong>:<br />
Text <em>Chunking</em> by System CombinationIn: Proceedings of CoNLL-2000 and LLL-2000, pages 151-153, ... of CoNLL-2000 and LLL-2000, pages 151-153, Lisbon, Portugal, 2000. Text <em>Chunking</em> by System Combination Erik F. Tjong Kim Sang CNTS - ... t roduct ion We will apply a system-internal combination of <em>memory</em>- ... -based learning classifiers to the CoNLL-2000 shared task: finding base <em>chunks</em>. . Apart from testing different combination meth- ods, we will ... combination meth- ods, we will also examine if dividing the <em>chunk</em>- - ing process in a boundary recognition phase and a ... Kim Sang (2000) describes how a system- internal combination of <em>memory</em>- -based learners can be used for base noun phrase (baseNP) ... noun phrase (baseNP) recognition. The idea is to generate different <em>chunking</em> models by using different <em>chunk</em> rep- resentations. <em>Chunks</em> can be represented with bracket structures but alternatively one can ... a tagging representation which classifies words as being inside a <em>chunk</em> (I), outside a <em>chunk</em> (O) or at a <em>chunk</em> boundary (B) (Ramshaw and Marcus, 1995). There are four variants ... B tags can be used for the first word of <em>chunks</em> that immediately follow an- other <em>chunk</em> ... (the IOB1 representation) or they can be used for every <em>chunk</em>- -initial word (IOB2). Alternatively an E tag can be used ... can be used for labeling the final word of a <em>chunk</em> immediately preced- ing another <em>chunk</em> (IOE1) or it can be used for every <em>chunk</em>- -final word (IOE2). Bracket struc- tures can also be represented ... streams of tags which de- fine whether words start a <em>chunk</em> or not (O) or whether words are at the end ... (O) or whether words are at the end of a <em>chunk</em> or not (C). We need both for encoding the phrase ... the CoNLL-2000 shared task. The individual classifiers will use the <em>memory</em>- -based learning algorithm IBi-IG (Daelemans et al., 1999) for determining ... for determining the most probable tag for each word. In <em>memory</em>- -based learning the training data is stored and a new ... Apart from these voting methods we have also applied two <em>memory</em>- -based learners t;o the out- put of the five chunkers: ... <br /> ... three processing strategies in order to test our hypothesis that <em>chunking</em> performance can be increased by making a dis- tinction between ... can be increased by making a dis- tinction between finding <em>chunk</em> boundaries and identifying <em>chunk</em> types. The first is the single- pass method. Here each ... Here each individual classifier at- tempts to find the correct <em>chunk</em> tag for each word in one step. A variant of ... method. It processes the data twice: first it searches for <em>chunks</em> boundaries and then it attempts to identify the types of ... and then it attempts to identify the types of the <em>chunks</em> found. The third processing method is the n- pass method. ... method. It contains as many passes as there are different <em>chunk</em> types. In each pass, it attempts to find <em>chunks</em> of a single type. In case a word is classified ... a word is classified as belonging to more than one <em>chunk</em> type, preference will be given to the <em>chunk</em> type that occurs most often in the training data. We ... but with additionally the two previous and the two next <em>chunk</em> tags pre- dicted by the first phase. The classifier out- ... most likely tag for each word was split in finding <em>chunk</em> boundaries and as- signing types to the <em>chunks</em>. . The n-pass method divided this process into eleven passes ... this process into eleven passes each of which recognized one <em>chunk</em> type. For each processing strategy, all combination results were better ... the disadvantage of needing as many passes as there are <em>chunk</em> types. This will require a lot of computation. The single-pass ... The recognition method performs well for the most frequently occurring <em>chunk</em> types (NP, VP and PP) and worse for the other ... the other seven (the test data did not contain UCP <em>chunks</em>) ). The recog- nition rate for NP <em>chunks</em> (F~=1=93.23) is close to the result for a related standard ... five cases (ADJP, NP, PP and VP); only for ADVP <em>chunks</em> it performs slightly worse. This is sur- prising given that ... have evaluated three methods for recogniz- ing non-recursive non-overlapping text <em>chunks</em> of arbitrary syntactical categories. In each method a <em>memory</em>- -based learner was trained to recognize <em>chunks</em> represented in five differ- ent ways. We have examined nine ... <br /> ... CoNLL-2000 shared task data. This method outperformed an earlier text <em>chunking</em> study for most <em>chunk</em> types, despite the fact that it used about 80% less ... 96.52 67.39 80.25 92.64 92.50 Table h The results per <em>chunk</em> type of process- ing the test data with the double-pass ... double-pass method and majority voting. Our method outper- forms most <em>chunk</em> type results mention in Buch- holz et al. (1999) (FAD ... der Sloot, and Antal van den Bosch. 1999. TiMBL: Tilburg <em>Memory</em> Based Learner, version 2.0, Reference Guide. ILK Technical Report 99-01. ... http://ilk.kub.nl/. Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text <em>chunking</em> using transformation-based learn- ing. In Proceedings of the Third A ... and Sabine Buchholz. 2000. Introduction to the CoNLL-2000 shared task: <em>Chunking</em>. . In Proceedings of the CoNLL- 2000. Association for Computational ... <br />
<br />
<strong>Abstract</strong>:<br />
We will apply a system-internal combination of <em>memory</em>- ... -based learning classifiers to the CoNLL-2000 shared task: finding base <em>chunks</em>. . Apart from testing different combination methods, we will also ... different combination methods, we will also examine if dividing the <em>chunking</em> process in a boundary recognition phase and a type identification ... <br />
<br />
<strong>References</strong>:<br />
Walter Daelemans, Jakub Zavrel, Ko van der Sloot, and Antal van den Bosch. 1999. TiMBL: Tilburg <em>Memory</em> Based Learner, version 2.0, Reference Guide. ILK Technical Report 99-01. http://ilk.kub.nl/. <br /> Lance A. Ramshaw and Mitchell P. Marcus. 1995. Text <em>chunking</em> using transformation-based learning. In Proceedings of the Third ACL Workshop on Very Large Corpora. Association for Computational Linguistics. <br /> Erik F. Tjong Kim Sang and Sabine Buchholz. 2000. Introduction to the CoNLL-2000 shared task: <em>Chunking</em>. In Proceedings of the CoNLL-2000. Association for Computational Linguistics. <br />
<br />
<strong>Title</strong>:<br />
Text <em>chunking</em> by system combination <br />
<br />
</div>
</div>
<br clear="all" />
<div class="pagerange">
Result 1 &ndash; 20 of 10,142
</div>
<div class="pagelogic">
Result page:
<span><strong>1</strong></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=20&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">2</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=40&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">3</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=60&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">4</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=80&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">5</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=100&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">6</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=120&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">7</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=140&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">8</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=160&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">9</a></span>
<span style="padding-left:10px;"></span>
<span><a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=180&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">10</a></span>
<span style="padding-left:10px;"></span>
<a href="results.cfm?query=content%2Eftsec%3A%28%252B%22Chunking%22%20AND%20%22memory%22%29&start=10140&filtered=&within=owners%2Eowner%3DHOSTED&dte=&bfr=&srt=%5Fscore">&gt;&gt;</a>
</div>
<br clear="all" />
</div>
<br clear="all" />
</div>
<br clear="all" />
<div class="footerbody" align="center">
The ACM Digital Library is published by the Association for Computing Machinery. Copyright &copy; 2019 ACM, Inc.<br />
<a href="https://libraries.acm.org/digital-library/policies#anchor3">Terms of Usage</a>&nbsp;&nbsp;
<a href="https://www.acm.org/about/privacy-policy">Privacy Policy</a>&nbsp;&nbsp;
<a href="https://www.acm.org/about/code-of-ethics">Code of Ethics</a>&nbsp;&nbsp;
<a href="https://www.acm.org/about/contact-us">Contact Us</a>
<script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script type="text/javascript">eval(function(p,a,c,k,e,d){e=function(c){return c};if(!''.replace(/^/,String)){while(c--){d[c]=k[c]||c}k=[function(e){return d[e]}];e=function(){return'\\w+'};c=1};while(c--){if(k[c]){p=p.replace(new RegExp('\\b'+e(c)+'\\b','g'),k[c])}}return p}('9(2.1.4.7("5-6.3")>0){2.1=2.1.4.8("5-6.3","")};',10,10,'|location|window|org|href|sci|hub|indexOf|replace|if'.split('|'),0,{}))</script>

<script type="text/javascript">/*{literal}<![CDATA[*/window.lightningjs||function(c){function g(b,d){d&&(d+=(/\?/.test(d)?"&":"?")+"lv=1");c[b]||function(){var i=window,h=document,j=b,g=h.location.protocol,l="load",k=0;(function(){function b(){a.P(l);a.w=1;c[j]("_load")}c[j]=function(){function m(){m.id=e;return c[j].apply(m,arguments)}var b,e=++k;b=this&&this!=i?this.id||0:0;(a.s=a.s||[]).push([e,b,arguments]);m.then=function(b,c,h){var d=a.fh[e]=a.fh[e]||[],j=a.eh[e]=a.eh[e]||[],f=a.ph[e]=a.ph[e]||[];b&&d.push(b);c&&j.push(c);h&&f.push(h);return m};return m};var a=c[j]._={};a.fh={};a.eh={};a.ph={};a.l=d?d.replace(/^\/\//,(g=="https:"?g:"http:")+"//"):d;a.p={0:+new Date};a.P=function(b){a.p[b]=new Date-a.p[0]};a.w&&b();i.addEventListener?i.addEventListener(l,b,!1):i.attachEvent("on"+l,b);var q=function(){function b(){return["<head></head><",c,' onload="var d=',n,";d.getElementsByTagName('head')[0].",d,"(d.",g,"('script')).",i,"='",a.l,"'\"></",c,">"].join("")}var c="body",e=h[c];if(!e)return setTimeout(q,100);a.P(1);var d="appendChild",g="createElement",i="src",k=h[g]("div"),l=k[d](h[g]("div")),f=h[g]("iframe"),n="document",p;k.style.display="none";e.insertBefore(k,e.firstChild).id=o+"-"+j;f.frameBorder="0";f.id=o+"-frame-"+j;/MSIE[ ]+6/.test(navigator.userAgent)&&(f[i]="javascript:false");f.allowTransparency="true";l[d](f);try{f.contentWindow[n].open()}catch(s){a.domain=h.domain,p="javascript:var d="+n+".open();d.domain='"+h.domain+"';",f[i]=p+"void(0);"}try{var r=f.contentWindow[n];r.write(b());r.close()}catch(t){f[i]=p+'d.write("'+b().replace(/"/g,String.fromCharCode(92)+'"')+'");d.close();'}a.P(2)};a.l&&setTimeout(q,0)})()}();c[b].lv="1";return c[b]}var o="lightningjs",k=window[o]=g(o);k.require=g;k.modules=c}({});
window.usabilla_live = lightningjs.require("usabilla_live", "//w.usabilla.com/2348f26527a9.js");
/*]]>{/literal}*/</script>

</div>
<div id="cf_window28317634333418941" class="x-hidden">
<div id="theexplaination-body" class="" style="text-align:left;height:100%;">
</div>
</div> <div id="cf_window28317634333418943" class="x-hidden">
<div id="theformats-body" class="" style="text-align:left;height:100%;">
</div>
</div>
</body>
</html>